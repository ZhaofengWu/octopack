{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0OHg2BmHyl7"
      },
      "source": [
        "#### Eval existing generations on HumanEval-X-Bugs\n",
        "\n",
        "We recommend generating locally & then using this colab to run the scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd12bBT2Jnex"
      },
      "outputs": [],
      "source": [
        "!git clone -b parity https://github.com/bigcode-project/bigcode-evaluation-harness\n",
        "%cd bigcode-evaluation-harness\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# You can just upload your generation files or clone the evaluation repo & eval generations uploaded there\n",
        "!git clone https://huggingface.co/datasets/bigcode/evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KstF0CMd_RH"
      },
      "source": [
        "##### Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2gOketd3NzH"
      },
      "outputs": [],
      "source": [
        "### Python ###\n",
        "\n",
        "GENPATH = \"evaluation/santacoder-git-commits-python-java-javascript/generations_humanevalxbugspy_santacoderpjj_temp02.json\"\n",
        "GENPATH = \"/content/completions_python_n20.json\"\n",
        "\n",
        "METRICPATH = GENPATH.replace(\"completions\", \"evaluation\").split(\"/\")[-1]\n",
        "\n",
        "\n",
        "!python main.py \\\n",
        "--tasks humaneval-x-generate-python \\\n",
        "--do_sample True \\\n",
        "--n_samples 1 \\\n",
        "--temperature 0.2 \\\n",
        "--allow_code_execution \\\n",
        "--trust_remote_code \\\n",
        "--prompt instruct \\\n",
        "--load_generations_path {GENPATH} \\\n",
        "--metric_output_path {METRICPATH}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfHS9sSnUlFi"
      },
      "outputs": [],
      "source": [
        "### Running multiple generations ###\n",
        "import json\n",
        "import os\n",
        "dir = \"/content/bigcode-evaluation-harness/evaluation/santacoder-verb-filter-2048\"\n",
        "\n",
        "for path in os.listdir(dir):\n",
        "    if not(\"generations\" in path): continue\n",
        "    if not(\"humanevalxbugspy\" in path): continue\n",
        "    evalpath = path.replace(\"generations\", \"evaluation\")\n",
        "    if os.path.exists(os.path.join(dir, evalpath)): continue\n",
        "    print(\"Running: \", path)\n",
        "    cmd = f\"python main.py --tasks humaneval-x-bugs-python --allow_code_execution --trust_remote_code --mutate_method edit --generations_path {os.path.join(dir, path)} --output_path {os.path.join(dir, evalpath)}\"\n",
        "    !{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ytpm-3WIrLv"
      },
      "outputs": [],
      "source": [
        "### Manual checking if needed ###\n",
        "import datasets\n",
        "ds = datasets.load_dataset(\"bigcode/humaneval-x-bugs\", \"python\")[\"test\"]\n",
        "\n",
        "import json\n",
        "with open(GENPATH, \"r\") as f:\n",
        "    d = json.load(f)\n",
        "\n",
        "IDX = 0\n",
        "\n",
        "print(\"-\"*50)\n",
        "print(\"Buggy input\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"buggy_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Solution\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"canonical_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Generation\")\n",
        "print(d[IDX][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vHV9WxBd89I"
      },
      "source": [
        "##### C++"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocixn89TZGtN"
      },
      "outputs": [],
      "source": [
        "### C++ ###\n",
        "\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoderguanaco/humaneval_x_generate/generations_humanevalxgeneratecpp_starcoderguanaco_temp02.json\"\n",
        "GENPATH = \"evaluation/starcodergx/humaneval_x_generate/generations_humanevalxgeneratecpp_starcodergx_temp02.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoderall/humaneval_x_generate/generations_humanevalxgeneratecpp_starcoderall_temp02.json\"\n",
        "GENPATH = \"/content/completions_cpp_humanevalsynthesize.json\"\n",
        "GENPATH = \"evaluation/starcoder/humaneval_x_bugs_docs/generations_humanevalfixdocscpp_starcoder_temp02.json\"\n",
        "\n",
        "METRICPATH = GENPATH.replace(\"generations\", \"evaluation\").split(\"/\")[-1]\n",
        "\n",
        "!python main.py \\\n",
        "--tasks humanevalsynthesize-cpp \\\n",
        "--do_sample True \\\n",
        "--n_samples 20 \\\n",
        "--temperature 0.2 \\\n",
        "--allow_code_execution \\\n",
        "--trust_remote_code \\\n",
        "--prompt instruct \\\n",
        "--load_generations_path {GENPATH} \\\n",
        "--metric_output_path {METRICPATH}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRAnGrukItgq"
      },
      "outputs": [],
      "source": [
        "### Manual checking if needed ###\n",
        "import datasets\n",
        "ds = datasets.load_dataset(\"bigcode/humaneval-x-bugs\", \"cpp\")[\"test\"]\n",
        "\n",
        "import json\n",
        "with open(GENPATH, \"r\") as f:\n",
        "    d = json.load(f)\n",
        "\n",
        "IDX = 1\n",
        "\n",
        "print(\"-\"*50)\n",
        "print(\"Buggy input\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"buggy_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Solution\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"canonical_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Generation\")\n",
        "print(d[IDX][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4ksawk5VWW9"
      },
      "source": [
        "##### JS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssbZ7vUUVGzE",
        "outputId": "768baa06-6ad5-4c86-e308-48685e885eff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 31.2M  100 31.2M    0     0  46.7M      0 --:--:-- --:--:-- --:--:-- 46.7M\n",
            "\u001b[K\u001b[?25h+ js-md5@0.7.3\n",
            "added 1 package from 1 contributor in 0.403s\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/bigcode-evaluation-harness/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/bigcode-evaluation-harness/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m bigcode-evaluation-harness No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m bigcode-evaluation-harness No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m bigcode-evaluation-harness No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m bigcode-evaluation-harness No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ js-md5@0.7.3\n",
            "added 1 package from 1 contributor and audited 1 package in 0.249s\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[33m   ╭───────────────────────────────────────────────────────────────╮\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                               \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m      New \u001b[31mmajor\u001b[39m version of npm available! \u001b[31m6.14.8\u001b[39m → \u001b[32m9.8.1\u001b[39m       \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m   \u001b[33mChangelog:\u001b[39m \u001b[36mhttps://github.com/npm/cli/releases/tag/v9.8.1\u001b[39m   \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m               Run \u001b[32mnpm install -g npm\u001b[39m to update!               \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                               \u001b[33m│\u001b[39m\n",
            "\u001b[33m   ╰───────────────────────────────────────────────────────────────╯\u001b[39m\n",
            "\u001b[33m\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/THUDM/CodeGeeX/blob/61529ba61de8e51c520dc67a3ce4bd62278770df/codegeex/docker/Dockerfile#L15\n",
        "!mkdir -p /workspace/download/\n",
        "!curl -o /workspace/download/node.tar.gz -SL https://nodejs.org/download/release/v16.14.0/node-v16.14.0-linux-x64.tar.gz \\\n",
        "    && mkdir -p /usr/local/lib/nodejs && tar -zxf /workspace/download/node.tar.gz -C /usr/local/lib/nodejs && mv /usr/local/lib/nodejs/node-v16.14.0-linux-x64 /usr/local/lib/nodejs/node \\\n",
        "    && rm /workspace/download/node.tar.gz && npm install -g js-md5@0.7.3\n",
        "# The above npm install of js-md5 does not work as its global\n",
        "# Reinstall locally & move to right location\n",
        "!npm install js-md5@0.7.3\n",
        "!mkdir /usr/local/lib/node_modules\n",
        "!mv node_modules/* /usr/local/lib/node_modules/\n",
        "\n",
        "import os\n",
        "os.environ['PATH'] = '/usr/local/lib/nodejs/node/bin:' + os.environ['PATH']\n",
        "os.environ['NODE_PATH'] = '/usr/local/lib/node_modules'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmQBh2Hl-dGs"
      },
      "outputs": [],
      "source": [
        "### JS ###\n",
        "\n",
        "GENPATH = \"evaluation/starcoderbase/humaneval_x_bugs/generations_humanevalxbugsjs_starcoderbase_temp02.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoder/humaneval_x_explain/generations_hexexplaingenjs_starcoder.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoder/humaneval_x_bugs_docs/generations_humanevalfixdocsjs_starcoder_temp02.json\"\n",
        "\n",
        "OUTPATH = GENPATH.replace(\"generations_\", \"evaluation_\")\n",
        "\n",
        "!python main.py \\\n",
        "--tasks humanevalfixdocs-js \\\n",
        "--do_sample True \\\n",
        "--n_samples 20 \\\n",
        "--temperature 0.2 \\\n",
        "--allow_code_execution \\\n",
        "--trust_remote_code \\\n",
        "--prompt edit \\\n",
        "--load_generations_path {GENPATH} \\\n",
        "--metric_output_path {OUTPATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vtgKIJD6Bpp"
      },
      "outputs": [],
      "source": [
        "### Running over multiple checkpoints ###\n",
        "import json\n",
        "import os\n",
        "\n",
        "%cd /content/bigcode-evaluation-harness\n",
        "\n",
        "dir = \"/content/bigcode-evaluation-harness/evaluation/santacoder-strict-filter-v2-input-loss/\"\n",
        "dir = \"/content/bigcode-evaluation-harness/evaluation/santacoder-verb-filter-2048/\"\n",
        "\n",
        "for path in os.listdir(dir):\n",
        "    if not(\"generations\" in path): continue\n",
        "    if not(\"humanevalxbugsjs\" in path): continue\n",
        "    evalpath = path.replace(\"generations\", \"evaluation\")\n",
        "    if os.path.exists(os.path.join(dir, evalpath)): continue\n",
        "    print(\"Running: \", path)\n",
        "    cmd = f\"python main.py --tasks humaneval-x-bugs-js --allow_code_execution --trust_remote_code --mutate_method edit --generations_path {os.path.join(dir, path)} --output_path {os.path.join(dir, evalpath)}\"\n",
        "    !{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp5VYmalIowY"
      },
      "outputs": [],
      "source": [
        "### Manual checking if needed ###\n",
        "import datasets\n",
        "ds = datasets.load_dataset(\"bigcode/humaneval-x-bugs\", \"js\")[\"test\"]\n",
        "\n",
        "import json\n",
        "with open(GENPATH, \"r\") as f:\n",
        "    d = json.load(f)\n",
        "\n",
        "IDX = 0\n",
        "\n",
        "print(\"Buggy input\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"buggy_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Solution\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"canonical_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Generation\")\n",
        "print(d[IDX][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P8XUxM9VX1k"
      },
      "source": [
        "##### Java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95_ne4YtBJ9y",
        "outputId": "54a2fc31-f144-4636-ee9e-e14fd8d351f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  173M  100  173M    0     0   109M      0  0:00:01  0:00:01 --:--:--  109M\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/THUDM/CodeGeeX/blob/61529ba61de8e51c520dc67a3ce4bd62278770df/codegeex/docker/Dockerfile#L31\n",
        "!mkdir -p /workspace/download/\n",
        "!curl -o /workspace/download/jdk.tar.gz -SL https://download.oracle.com/java/18/archive/jdk-18_linux-x64_bin.tar.gz \\\n",
        "    && mkdir /usr/java && tar -zxf /workspace/download/jdk.tar.gz -C /usr/java && rm /workspace/download/jdk.tar.gz \\\n",
        "    && java_path=`ls /usr/java/${path}` && echo \"export JAVA_HOME=/usr/java/${java_path}\" >> ~/.profile\n",
        "\n",
        "import os\n",
        "os.environ['PATH'] = '/usr/java/jdk-18/bin:' + os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgSEkvLS7eWa"
      },
      "outputs": [],
      "source": [
        "### Java ###\n",
        "\n",
        "GENPATH = \"evaluation/santacoder-verb-filter-2048/generations_humanevalxbugsjava_greedy[checkpoint-108000].json\"\n",
        "GENPATH = \"evaluation/starcoderbase/humaneval_x_bugs/generations_humanevalxbugsjava_starcoderbase_temp02.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/codegen-16B-multi/humaneval_x_bugs/generations_humanevalxbugsjava_codegen16b_temp02.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoder/humaneval_x_bugs/instruct_format/generations_humanevalxbugsjava_starcoder_temp02_instruct.json\"\n",
        "GENPATH = \"evaluation/starcoder/humaneval_x_explain/generations_hexexplaingenjava_starcoder.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/WizardCoder-15B-V1.0/humaneval_x_bugs/generations_hexbugsjava_wizardcoder.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoderguanacocommits/humaneval_x_bugs_docs/generations_humanevalfixdocsjava_octocoder_temp02_fixed.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoder/humaneval_x_bugs_docs/generations_humanevalfixdocsjava_starcoder_temp02_fixed.json\"\n",
        "\n",
        "OUTPATH = GENPATH.replace(\"generations_\", \"evaluation_\")\n",
        "\n",
        "!python main.py \\\n",
        "--tasks humanevalfixdocs-java \\\n",
        "--do_sample True \\\n",
        "--n_samples 10 \\\n",
        "--temperature 0.2 \\\n",
        "--allow_code_execution \\\n",
        "--trust_remote_code \\\n",
        "--prompt edit \\\n",
        "--load_generations_path {GENPATH} \\\n",
        "--metric_output_path {OUTPATH}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dOVPeFOODH6"
      },
      "outputs": [],
      "source": [
        "### If missing brackets at the end ###\n",
        "\n",
        "import json\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoderguanacocommits/humaneval_x_bugs_docs/generations_humanevalfixdocsjava_octocoder_temp02.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoder/humaneval_x_bugs_docs/generations_humanevalfixdocsjava_starcoder_temp02.json\"\n",
        "\n",
        "with open(GENPATH, \"r\") as f:\n",
        "    d = json.load(f)\n",
        "\n",
        "for i, g in enumerate(d):\n",
        "    for j, code in enumerate(g):\n",
        "        if code.count('{') - 1 == code.count('}'):\n",
        "            print(\"X\")\n",
        "            code += \"\\n}\"\n",
        "            d[i][j] = code\n",
        "\n",
        "with open(GENPATH.replace(\".json\", \"_fixed.json\"), \"w\") as f:\n",
        "    json.dump(d, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYNiZQ3AazZa"
      },
      "outputs": [],
      "source": [
        "### Running multiple ckpts ###\n",
        "\n",
        "import json\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "%cd /content/bigcode-evaluation-harness\n",
        "\n",
        "# path = \"evaluation/santacoder-strict-filter-with-input-loss/generations_humanevalxbugspy_greedy[checkpoint-12000].json\"\n",
        "# dir = \"/content/bigcode-evaluation-harness/evaluation/santacoder-soft-filter/\"\n",
        "# dir = \"evaluation/santacoder-strict-filter-with-input-loss/\"\n",
        "dir = \"/content/bigcode-evaluation-harness/evaluation/santacoder-strict-filter-flan-input-loss\"\n",
        "\n",
        "for path in os.listdir(dir):\n",
        "    if not(\"generations\" in path): continue\n",
        "    if not(\"humanevalxbugsjava\" in path): continue\n",
        "    evalpath = path.replace(\"generations\", \"evaluation\")\n",
        "    if os.path.exists(os.path.join(dir, evalpath)): continue\n",
        "    print(\"Running: \", path)\n",
        "    cmd = f\"python main.py --tasks humaneval-x-bugs-java --allow_code_execution --trust_remote_code --mutate_method edit --generations_path {os.path.join(dir, path)} --output_path {os.path.join(dir, evalpath)}\"\n",
        "    #!{cmd}\n",
        "    try:\n",
        "        # Takes ~15min\n",
        "        subprocess.run(cmd, shell=True, check=True, timeout=60*16)\n",
        "        print(\"Process completed successfully\")\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"Process timed out and was terminated\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Process terminated with error code {e.returncode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WrTtBxxwYxI"
      },
      "outputs": [],
      "source": [
        "### Manual checking if needed ###\n",
        "import datasets\n",
        "ds = datasets.load_dataset(\"bigcode/humaneval-x-bugs\", \"java\")[\"test\"]\n",
        "\n",
        "import json\n",
        "with open(GENPATH, \"r\") as f:\n",
        "    d = json.load(f)\n",
        "\n",
        "IDX = 0\n",
        "\n",
        "print(\"-\"*50)\n",
        "print(\"Buggy input\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"buggy_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Solution\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"canonical_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Generation\")\n",
        "print(d[IDX][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGIJ2alLVZie"
      },
      "source": [
        "##### Go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6B1cQa5VdvB",
        "outputId": "0796ee41-cd7d-4562-8745-2d8d0a507eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    75  100    75    0     0    676      0 --:--:-- --:--:-- --:--:--   681\n",
            "100  135M  100  135M    0     0  64.4M      0  0:00:02  0:00:02 --:--:-- 87.6M\n",
            "--2023-07-26 19:21:41--  https://github.com/THUDM/CodeGeeX/raw/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/THUDM/CodeGeeX/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz [following]\n",
            "--2023-07-26 19:21:41--  https://raw.githubusercontent.com/THUDM/CodeGeeX/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118261 (115K) [application/octet-stream]\n",
            "Saving to: ‘vendor.tar.gz’\n",
            "\n",
            "vendor.tar.gz       100%[===================>] 115.49K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-07-26 19:21:41 (4.94 MB/s) - ‘vendor.tar.gz’ saved [118261/118261]\n",
            "\n",
            "go: go.mod file not found in current directory or any parent directory.\n",
            "\t'go get' is no longer supported outside a module.\n",
            "\tTo build and install a command, use 'go install' with a version,\n",
            "\tlike 'go install example.com/cmd@latest'\n",
            "\tFor more information, see https://golang.org/doc/go-get-install-deprecation\n",
            "\tor run 'go help get' or 'go help install'.\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /workspace/download\n",
        "!curl -o /workspace/download/go.tar.gz -SL https://go.dev/dl/go1.18.4.linux-amd64.tar.gz \\\n",
        "    && tar -zxf /workspace/download/go.tar.gz -C /usr/local && rm /workspace/download/go.tar.gz\n",
        "\n",
        "# Not required, but makes it faster I think\n",
        "!wget https://github.com/THUDM/CodeGeeX/raw/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz\n",
        "!tar -zxf vendor.tar.gz -C ./\n",
        "\n",
        "import os\n",
        "os.environ['PATH'] = '/bin:/usr/local/go/bin:' + os.environ['PATH']\n",
        "os.environ['GOFLAGS'] = '-mod=mod'\n",
        "\n",
        "# Sometimes test No 98 or so fails with the below error\n",
        "# \"failed: go: finding module for package github.com/stretchr/testify/assert\"\n",
        "# In that case run the below & then rerun tests\n",
        "!go get github.com/stretchr/testify/assert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSU2GPlzVdry",
        "outputId": "f3964c20-307f-4b02-ddc3-45492c7e16bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing go.mod\n"
          ]
        }
      ],
      "source": [
        "%%writefile go.mod\n",
        "module humanEval\n",
        "\n",
        "go 1.18\n",
        "\n",
        "require (\n",
        "\tgithub.com/go-openapi/inflect v0.19.0\n",
        "\tgithub.com/stretchr/testify v1.8.0\n",
        ")\n",
        "\n",
        "require (\n",
        "\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n",
        "\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n",
        "\tgopkg.in/yaml.v3 v3.0.1 // indirect\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBv8PVRvU1-i"
      },
      "outputs": [],
      "source": [
        "### Go ###\n",
        "GENPATH = \"evaluation/starcoderbase/humaneval_x_bugs/generations_humanevalxbugsgo_starcoderbase_temp02.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/bloomz/humaneval_x_bugs_tests/generations_humanevalxbugsgo_bloomz_temp02.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoderguanacocommits/humaneval_x_bugs_docs/generations_humanevalfixdocsgo_octocoder_temp02.json\"\n",
        "GENPATH = \"evaluation/starcoder/humaneval_x_bugs_docs/generations_humanevalfixdocsgo_starcoder_temp02.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoder/humaneval_x_bugs_docs/instruct_format/generations_humanevalfixdocsgo_starcoder_temp02.json\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoder/humaneval_x_bugs_docs/instruct_format/generations_humanevalfixdocsgo_starcoder_temp02_instruct.json\"\n",
        "\n",
        "OUTPATH = GENPATH.replace(\"generations_\", \"evaluation_\")\n",
        "\n",
        "!python main.py \\\n",
        "  --tasks humanevalfixdocs-go \\\n",
        "  --allow_code_execution \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 20 \\\n",
        "  --temperature 0.2 \\\n",
        "  --trust_remote_code \\\n",
        "  --prompt instruct \\\n",
        "  --load_generations_path {GENPATH} \\\n",
        "  --metric_output_path {OUTPATH}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdNykD4cI0Gz"
      },
      "outputs": [],
      "source": [
        "### Manual checking if needed ###\n",
        "import datasets\n",
        "ds = datasets.load_dataset(\"bigcode/humanevalpack\", \"go\")[\"test\"]\n",
        "\n",
        "import json\n",
        "with open(GENPATH, \"r\") as f:\n",
        "    d = json.load(f)\n",
        "\n",
        "IDX = 0\n",
        "\n",
        "print(\"-\"*50)\n",
        "print(\"Buggy input\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"buggy_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Solution\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"canonical_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Generation\")\n",
        "print(d[IDX][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seGAn7anVbSA"
      },
      "source": [
        "##### Rust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypdV4jiLVLJQ",
        "outputId": "bf54fe01-9d91-4fd7-c177-1c4fd1b0748e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1minfo:\u001b[0m downloading installer\n",
            "\u001b[1minfo: \u001b[mprofile set to 'minimal'\n",
            "\u001b[1minfo: \u001b[mdefault host triple is x86_64-unknown-linux-gnu\n",
            "\u001b[1minfo: \u001b[msyncing channel updates for 'stable-x86_64-unknown-linux-gnu'\n",
            "\u001b[1minfo: \u001b[mlatest update on 2023-07-13, rust version 1.71.0 (8ede3aae2 2023-07-12)\n",
            "\u001b[1minfo: \u001b[mdownloading component 'cargo'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rust-std'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rustc'\n",
            " 64.0 MiB /  64.0 MiB (100 %)  44.0 MiB/s in  1s ETA:  0s\n",
            "\u001b[1minfo: \u001b[minstalling component 'cargo'\n",
            "\u001b[1minfo: \u001b[minstalling component 'rust-std'\n",
            " 25.4 MiB /  25.4 MiB (100 %)   5.4 MiB/s in  4s ETA:  0s\n",
            "\u001b[1minfo: \u001b[minstalling component 'rustc'\n",
            " 64.0 MiB /  64.0 MiB (100 %)  14.9 MiB/s in  4s ETA:  0s\n",
            "\u001b[1minfo: \u001b[mdefault toolchain set to 'stable-x86_64-unknown-linux-gnu'\n",
            "\n",
            "  \u001b[1m\u001b[32mstable-x86_64-unknown-linux-gnu installed\u001b[m - rustc 1.71.0 (8ede3aae2 2023-07-12)\n",
            "\n",
            "\u001b[1m\n",
            "Rust is installed now. Great!\n",
            "\u001b[m\n",
            "To get started you may need to restart your current shell.\n",
            "This would reload your \u001b[1mPATH\u001b[m environment variable to include\n",
            "Cargo's bin directory ($HOME/.cargo/bin).\n",
            "\n",
            "To configure your current shell, run:\n",
            "source \"$HOME/.cargo/env\"\n"
          ]
        }
      ],
      "source": [
        "!curl https://sh.rustup.rs -sSf | sh -s -- --profile minimal --default-toolchain stable -y\n",
        "import os\n",
        "os.environ['PATH'] = '/root/.cargo/bin:' + os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGLSafPC9Qfc"
      },
      "outputs": [],
      "source": [
        "### Rust ###\n",
        "\n",
        "GENPATH = \"generations_humanevalxbugsrust_santacoderpjj_greedy.json\"\n",
        "GENPATH = \"evaluation/santacoder-git-commits-python-java-javascript/generations_humanevalxbugsrust_santacoderpjj_greedy.json\"\n",
        "GENPATH = \"evaluation/santacoder/generations_humanevalxbugsrust_santacoder_greedy.json\"\n",
        "GENPATH = \"gpt4_completions_rust.jsonl\"\n",
        "GENPATH = \"/content/bigcode-evaluation-harness/evaluation/starcoder/humaneval_x_bugs_docs/commit_format/generations_humanevalfixdocsrust_starcoder_temp02.json\"\n",
        "\n",
        "OUTPATH = GENPATH.replace(\"generations_\", \"evaluation_\")\n",
        "OUTPATH = OUTPATH.replace(\"completions_\", \"evaluation_\")\n",
        "\n",
        "!python main.py \\\n",
        "--tasks humanevalsynthesize-rust \\\n",
        "--allow_code_execution \\\n",
        "--do_sample True \\\n",
        "--n_samples 10 \\\n",
        "--temperature 0.2 \\\n",
        "--trust_remote_code \\\n",
        "--prompt instruct \\\n",
        "--load_generations_path {GENPATH} \\\n",
        "--metric_output_path {OUTPATH}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_Xf22wRI6dL"
      },
      "outputs": [],
      "source": [
        "### Manual checking if needed ###\n",
        "import datasets\n",
        "ds = datasets.load_dataset(\"bigcode/humaneval-x-bugs\", \"rust\")[\"test\"]\n",
        "\n",
        "import json\n",
        "with open(GENPATH, \"r\") as f:\n",
        "    d = json.load(f)\n",
        "\n",
        "IDX = 0\n",
        "\n",
        "print(\"-\"*50)\n",
        "print(\"Buggy input\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"buggy_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Solution\")\n",
        "print(ds[IDX][\"prompt\"] + ds[IDX][\"canonical_solution\"])\n",
        "print(\"-\"*50)\n",
        "print(\"Generation\")\n",
        "print(d[IDX][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsGUfTthEwdc"
      },
      "source": [
        "#### Check Ground Truth is indeed correct / incorrect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT6f4e32EyE8",
        "outputId": "eca5fc85-d429-497b-d607-9183bba264f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'bigcode-evaluation-harness'...\n",
            "remote: Enumerating objects: 2935, done.\u001b[K\n",
            "remote: Counting objects: 100% (2930/2930), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1025/1025), done.\u001b[K\n",
            "remote: Total 2935 (delta 1964), reused 2804 (delta 1878), pack-reused 5\u001b[K\n",
            "Receiving objects: 100% (2935/2935), 575.36 KiB | 6.32 MiB/s, done.\n",
            "Resolving deltas: 100% (1964/1964), done.\n",
            "/content/bigcode-evaluation-harness\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!git clone -b parity https://github.com/bigcode-project/bigcode-evaluation-harness\n",
        "%cd bigcode-evaluation-harness\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c01wL_UkQ1Qo"
      },
      "source": [
        "###### Prepare repo\n",
        "\n",
        "If you'd like to check that buggy solutions are indeed all incorrect make sure get_reference returns the buggy solution & you only print out if pass@1 is not 0 in the process_results function.\n",
        "\n",
        "\n",
        "To check that all canonical solutions are indeed all correct get_reference should return the solution & check for pass@1 not being 1 instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSoI0FDSQzrm",
        "outputId": "e1a889d4-46d6-4b42-96b8-11e4ce06f6d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/bigcode-evaluation-harness/lm_eval/tasks/humaneval_x_bugs.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/bigcode-evaluation-harness/lm_eval/tasks/humaneval_x_bugs.py\n",
        "\"\"\"WIP\n",
        "\n",
        "Homepage: https://github.com/bigcode-project/commits\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "from evaluate import load\n",
        "from lm_eval.base import Task\n",
        "\n",
        "\n",
        "_CITATION = \"\"\"\n",
        "\"\"\"\n",
        "\n",
        "# TODO: Possibly check for gen finished via brackets\n",
        "# https://github.com/THUDM/CodeGeeX/blob/23ee51505a2bcd34d59d2e271b22e5bd91475462/codegeex/benchmark/utils.py#L115\n",
        "\n",
        "LANGUAGES = [\"python\", \"cpp\", \"js\", \"java\", \"go\", \"rust\"]\n",
        "\n",
        "\n",
        "# Taken from https://huggingface.co/datasets/nuprl/MultiPL-E/ & https://github.com/THUDM/CodeGeeX\n",
        "LANGUAGE_TO_STOP_WORDS = {\n",
        "    # https://github.com/THUDM/CodeGeeX/blob/23ee51505a2bcd34d59d2e271b22e5bd91475462/codegeex/benchmark/utils.py#L164\n",
        "    \"python\": [\"\\nclass\", \"\\ndef\", \"\\n#\", \"\\n@\", \"\\nprint\", \"\\nif\", \"\\nassert\"],\n",
        "    # https://github.com/THUDM/CodeGeeX/blob/23ee51505a2bcd34d59d2e271b22e5bd91475462/codegeex/benchmark/utils.py#L185\n",
        "    \"cpp\": [\"\\n}\"],\n",
        "    # https://github.com/THUDM/CodeGeeX/blob/23ee51505a2bcd34d59d2e271b22e5bd91475462/codegeex/benchmark/utils.py#L188\n",
        "    \"js\": [\"\\n}\"],\n",
        "    # https://github.com/THUDM/CodeGeeX/blob/23ee51505a2bcd34d59d2e271b22e5bd91475462/codegeex/benchmark/utils.py#L177\n",
        "    \"go\": [\"\\n//\", \"\\nfunc main(\", \"struct\", \"\\nfunc\"],\n",
        "    # https://github.com/THUDM/CodeGeeX/blob/23ee51505a2bcd34d59d2e271b22e5bd91475462/codegeex/benchmark/utils.py#L169\n",
        "    \"java\": [\"\\n }\\n\"],\n",
        "    \"rust\": [\"\\n}\"],\n",
        "}\n",
        "\n",
        "LANGUAGE_TO_TIMEOUT = {\n",
        "    \"python\": 10,\n",
        "    \"cpp\": 10,\n",
        "    \"js\": 10,\n",
        "    \"java\": 10,\n",
        "    \"go\": 10,\n",
        "    \"rust\": 300, # Necessary for first-time compilation of cargo\n",
        "}\n",
        "\n",
        "# https://github.com/THUDM/CodeGeeX/blob/23ee51505a2bcd34d59d2e271b22e5bd91475462/codegeex/benchmark/utils.py#L6\n",
        "IMPORT_HELPER = {\n",
        "    \"python\": [\n",
        "        \"import math\",\n",
        "        \"import re\",\n",
        "        \"import sys\",\n",
        "        \"import copy\",\n",
        "        \"import datetime\",\n",
        "        \"import itertools\",\n",
        "        \"import collections\",\n",
        "        \"import heapq\",\n",
        "        \"import statistics\",\n",
        "        \"import functools\",\n",
        "        \"import hashlib\",\n",
        "        \"import numpy\",\n",
        "        \"import numpy as np\",\n",
        "        \"import string\",\n",
        "        \"from typing import *\",\n",
        "        \"from collections import *\",\n",
        "    ],\n",
        "    \"go\": [\n",
        "        \"math\",\n",
        "        \"strings\",\n",
        "        \"fmt\",\n",
        "        \"strconv\",\n",
        "        \"time\",\n",
        "        \"bytes\",\n",
        "        \"regexp\",\n",
        "        \"sort\",\n",
        "        \"math/rand\",\n",
        "        \"crypto/md5\",\n",
        "    ],\n",
        "    \"cpp\": [\n",
        "        \"#include<stdlib.h>\",\n",
        "        \"#include<algorithm>\",\n",
        "        \"#include<math.h>\",\n",
        "        \"#include<stdio.h>\",\n",
        "        \"#include<vector>\",\n",
        "        \"#include<string>\",\n",
        "        \"#include<climits>\",\n",
        "        \"#include<cstring>\",\n",
        "        \"#include<iostream>\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "def create_all_tasks():\n",
        "    \"\"\"Creates a dictionary of tasks from a list of levels\n",
        "    :return: {task_name: task}\n",
        "        e.g. {apps-interview: Task, apps-competitoon: Task}\n",
        "    \"\"\"\n",
        "    return {f\"humaneval-x-bugs-{language}\": create_task(language) for language in LANGUAGES}\n",
        "\n",
        "\n",
        "def create_task(language):\n",
        "    class HumanEvalXBugs(GeneralHumanEvalXBugs):\n",
        "        def __init__(self, mutate_method=\"prompt\", language=language):\n",
        "            super().__init__(mutate_method=mutate_method, language=language)\n",
        "\n",
        "    return HumanEvalXBugs\n",
        "\n",
        "\n",
        "class GeneralHumanEvalXBugs(Task):\n",
        "    \"\"\"A task represents an entire benchmark including its dataset, problems,\n",
        "    answers, generation settings and evaluation methods.\n",
        "    \"\"\"\n",
        "\n",
        "    DATASET_PATH = \"bigcode/humaneval-x-bugs\"\n",
        "    DATASET_NAME = None\n",
        "\n",
        "    def __init__(self, mutate_method=\"prompt\", language=\"python\"):\n",
        "\n",
        "        self.DATASET_NAME = language\n",
        "        stop_words = LANGUAGE_TO_STOP_WORDS[language]\n",
        "        self.mutate_method = mutate_method\n",
        "        if self.mutate_method == \"edit\":\n",
        "            stop_words += [\n",
        "                \"<commit_before>\",\n",
        "                \"<commit_msg>\",\n",
        "                \"<commit_after>\",\n",
        "                \"<|endoftext|>\",\n",
        "            ]\n",
        "\n",
        "        super().__init__(\n",
        "            stop_words=stop_words,\n",
        "            requires_execution=True,\n",
        "        )\n",
        "\n",
        "    def get_dataset(self):\n",
        "        \"\"\"Returns dataset for the task or an iterable of any object, that get_prompt can handle\"\"\"\n",
        "        return self.dataset[\"test\"]\n",
        "\n",
        "    def get_prompt(self, doc):\n",
        "        \"\"\"Builds the prompt for the LM to generate from.\"\"\"\n",
        "        if self.mutate_method == \"edit\":\n",
        "            prompt = \"<commit_before>\" + doc[\"prompt\"] + doc[\"buggy_solution\"]\n",
        "            prompt += \"<commit_msg>\" + \"Fix bug in \" + doc[\"entry_point\"]\n",
        "            prompt += \"<commit_after>\" + doc[\"prompt\"]\n",
        "        elif self.mutate_method == \"edit-type\":\n",
        "            prompt = \"<commit_before>\" + doc[\"prompt\"] + doc[\"buggy_solution\"]\n",
        "            prompt += \"<commit_msg>\" + \"Fix \" + doc[\"bug_type\"] + \" in \" + doc[\"entry_point\"]\n",
        "            prompt += \"<commit_after>\" + doc[\"prompt\"]\n",
        "        elif self.mutate_method == \"prompt\":\n",
        "            prompt = \"# Buggy function\"\n",
        "            prompt += \"\\n\" + doc[\"prompt\"] + doc[\"buggy_solution\"] + \"\\n\"\n",
        "            prompt += \"# Fixed function\\n\" + doc[\"prompt\"]\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mutate_method: {mutate_method}\")\n",
        "\n",
        "        # Strip off the final \\n as it seems like its easier for small models to generate\n",
        "        # \\n\\t than \\t based on experiments from @lvwerra\n",
        "        return prompt.strip()\n",
        "\n",
        "    def get_reference(self, doc, get_solution=False):\n",
        "        \"\"\"Builds the reference solution for the doc (sample from the test dataset).\"\"\"\n",
        "        if get_solution:\n",
        "            return doc[\"prompt\"] + doc[\"canonical_solution\"]\n",
        "            # To check that all buggy solutions result in a 0 score:\n",
        "            # return doc[\"prompt\"] + doc[\"buggy_solution\"]\n",
        "        else:\n",
        "            test_func = doc[\"test\"]\n",
        "            # check(func_name) is already included\n",
        "            return \"\\n\" + test_func\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_last_block(string, stop_words):\n",
        "        stop_words = [re.escape(word) for word in stop_words] # Escape e.g. | in <|endoftext|>\n",
        "        # Remove the last block of the code containing stop_words for HumanEval\n",
        "        string_list = re.split(\"(%s)\" % \"|\".join(stop_words), string)\n",
        "        # last string should be \"\"\n",
        "        return \"\".join(string_list[:-2])\n",
        "\n",
        "    def postprocess_generation(self, generation, idx):\n",
        "        \"\"\"Defines the postprocessing for a LM generation.\n",
        "        :param generation: str\n",
        "            code generation from LM\n",
        "        :param idx: int\n",
        "            index of doc in the dataset to which the generation belongs\n",
        "            (not used for Humaneval-Task)\n",
        "        \"\"\"\n",
        "        doc = self.get_dataset()[idx]\n",
        "        prompt = self.get_prompt(doc)\n",
        "        # Keep the defining part of the function; Strip on the right to maintain same\n",
        "        # behavior as with get_prompt\n",
        "        generation = doc[\"prompt\"].rstrip() + generation[len(prompt):]\n",
        "        return self.remove_last_block(generation, self.stop_words).strip()\n",
        "\n",
        "    def process_results(self, generations, references):\n",
        "        \"\"\"Takes the list of LM generations and evaluates them against ground truth references,\n",
        "        returning the metric for the generations.\n",
        "        :param generations: list(list(str))\n",
        "            list of lists containing generations\n",
        "        :param references: list(str)\n",
        "            list of str containing refrences\n",
        "        \"\"\"\n",
        "        code_metric = load(\"Muennighoff/code_eval\")\n",
        "        timeout = LANGUAGE_TO_TIMEOUT[self.DATASET_NAME]\n",
        "        language = self.DATASET_NAME if self.DATASET_NAME != \"js\" else \"javascript\"\n",
        "\n",
        "        # See https://github.com/THUDM/CodeGeeX/blob/ebeb850f227a90c79de39f7e26b1302f374f3240/codegeex/benchmark/evaluate_humaneval_x.py\n",
        "        if language == \"python\":\n",
        "            python_imports = \"\\n\".join(IMPORT_HELPER[\"python\"])\n",
        "            generations = [\n",
        "                [(python_imports + \"\\n\" + g).strip() for g in gen] for gen in generations\n",
        "            ]\n",
        "        elif language == \"cpp\":\n",
        "            for gen in generations:\n",
        "                for i, g in enumerate(gen):\n",
        "                    for s in IMPORT_HELPER[\"cpp\"]:\n",
        "                        if s not in g:\n",
        "                            gen[i] = s + \"\\n\" + g\n",
        "        elif language == \"go\":\n",
        "            ds = self.get_dataset().select(range(len(generations)))\n",
        "            for gen, doc in zip(generations, ds):\n",
        "                import_string = doc[\"import\"]\n",
        "                test_setup = doc[\"test_setup\"]\n",
        "                for i, g in enumerate(gen):\n",
        "                    other_pkgs = []\n",
        "                    for pkg in IMPORT_HELPER[\"go\"]:\n",
        "                        if pkg not in test_setup:\n",
        "                            p = pkg.split(\"/\")[-1]\n",
        "                            if p + \".\" in g:\n",
        "                                # The problem is that it could appear in a comment\n",
        "                                # For example in problem 158, the docstring is:\n",
        "                                # // ... a list of strings.\n",
        "                                # but the \"strings\" package is never used\n",
        "                                # Golang throws an error if the package is not used\n",
        "                                # Hence search for the package & make sure it's not in a commented line\n",
        "                                #other_pkgs.append(f\"\\\"{pkg}\\\"\")\n",
        "                                lines = g.split(\"\\n\")\n",
        "                                for line in lines:\n",
        "                                    if p + \".\" in line and not line.startswith(\"//\"):\n",
        "                                        other_pkgs.append(f\"\\\"{pkg}\\\"\")\n",
        "                                        break\n",
        "\n",
        "                    gen[i] = g.replace(import_string, \"\")\n",
        "                    if other_pkgs:\n",
        "                        import_other_pkgs = \"import (\\n\" + \"    \".join([p + \"\\n\" for p in other_pkgs]) + \")\"\n",
        "                        gen[i] = test_setup + \"\\n\" + import_other_pkgs + \"\\n\" + gen[i]\n",
        "                    else:\n",
        "                        gen[i] = test_setup + \"\\n\" + gen[i]\n",
        "        elif language == \"rust\":\n",
        "            ds = self.get_dataset().select(range(len(generations)))\n",
        "            main = \"\\nfn main(){ \\n } \\n\"\n",
        "            for gen, doc in zip(generations, ds):\n",
        "                declaration = doc[\"declaration\"]\n",
        "                for i, g in enumerate(gen):\n",
        "                    gen[i] = main + declaration + g\n",
        "\n",
        "        #results, _ = code_metric.compute(\n",
        "        #    references=references,\n",
        "        #    predictions=generations,\n",
        "        #    language=language,\n",
        "        #    timeout=timeout,\n",
        "        #)\n",
        "        #return results\n",
        "\n",
        "        for i, (gen, ref) in enumerate(zip(generations, references)):\n",
        "            import time\n",
        "            starttime = time.time()\n",
        "            results, log = code_metric.compute(\n",
        "                references=[ref],\n",
        "                predictions=[gen],\n",
        "                language=language,\n",
        "                timeout=timeout*10,\n",
        "            )\n",
        "            print(\"TOOK: \", time.time() - starttime)\n",
        "            with open(\"errors.txt\", \"a\") as f:\n",
        "                f.write(log[0][0][1][\"result\"] + \"\\n\")\n",
        "            if (\"compilation error\" in log[0][0][1][\"result\"]) or (results[\"pass@1\"] != 1):\n",
        "                print(\"XXXXX\")\n",
        "                print(results)\n",
        "                print(log)\n",
        "                print(i)\n",
        "                print(gen[0])\n",
        "                print(ref)\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx_GboyTwmml"
      },
      "source": [
        "##### Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITdUltxuE5My",
        "outputId": "ccb2e0c2-0cf6-4a79-d473-d8affe09155d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 11:47:41.032621: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-python']\n",
            "Loading the model and tokenizer\n",
            "Downloading and preparing dataset humaneval-x-bugs/python to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/python/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8...\n",
            "Downloading data: 100% 394k/394k [00:00<00:00, 5.10MB/s]\n",
            "Dataset humaneval-x-bugs downloaded and prepared to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/python/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 544.93it/s]\n",
            "100% 1/1 [00:00<00:00, 375.06it/s]\n",
            "TOOK:  0.15112805366516113\n",
            "TOOK:  0.12736272811889648\n",
            "TOOK:  0.12888145446777344\n",
            "TOOK:  0.12872076034545898\n",
            "TOOK:  0.13180184364318848\n",
            "TOOK:  0.13054728507995605\n",
            "TOOK:  0.12799739837646484\n",
            "TOOK:  0.13460946083068848\n",
            "TOOK:  0.13700628280639648\n",
            "TOOK:  0.1289048194885254\n",
            "TOOK:  0.12740373611450195\n",
            "TOOK:  0.13068866729736328\n",
            "TOOK:  0.12725520133972168\n",
            "TOOK:  0.13077950477600098\n",
            "TOOK:  0.12452435493469238\n",
            "TOOK:  0.147721529006958\n",
            "TOOK:  0.13271284103393555\n",
            "TOOK:  0.12392807006835938\n",
            "TOOK:  0.14052796363830566\n",
            "TOOK:  0.13665032386779785\n",
            "TOOK:  0.13892745971679688\n",
            "TOOK:  0.1324295997619629\n",
            "TOOK:  0.13329029083251953\n",
            "TOOK:  0.12801480293273926\n",
            "TOOK:  0.13591527938842773\n",
            "TOOK:  0.12926602363586426\n",
            "TOOK:  0.13556599617004395\n",
            "TOOK:  0.13509798049926758\n",
            "TOOK:  0.13129663467407227\n",
            "TOOK:  0.12905216217041016\n",
            "TOOK:  0.12735962867736816\n",
            "TOOK:  0.13022899627685547\n",
            "TOOK:  0.14973211288452148\n",
            "TOOK:  0.12743544578552246\n",
            "TOOK:  0.1302802562713623\n",
            "TOOK:  0.12674641609191895\n",
            "TOOK:  0.15622806549072266\n",
            "TOOK:  0.12458562850952148\n",
            "TOOK:  0.12839055061340332\n",
            "TOOK:  0.13543105125427246\n",
            "TOOK:  0.12828826904296875\n",
            "TOOK:  0.11997485160827637\n",
            "TOOK:  0.13043618202209473\n",
            "TOOK:  0.14064645767211914\n",
            "TOOK:  0.13585400581359863\n",
            "TOOK:  0.12148547172546387\n",
            "TOOK:  0.12040400505065918\n",
            "TOOK:  0.13640308380126953\n",
            "TOOK:  0.12394261360168457\n",
            "TOOK:  0.12812352180480957\n",
            "TOOK:  0.12998270988464355\n",
            "TOOK:  0.12803196907043457\n",
            "TOOK:  0.12483048439025879\n",
            "TOOK:  0.12309861183166504\n",
            "TOOK:  0.13169360160827637\n",
            "TOOK:  0.1286911964416504\n",
            "TOOK:  0.16081547737121582\n",
            "TOOK:  0.1730353832244873\n",
            "TOOK:  0.17864251136779785\n",
            "TOOK:  0.17873740196228027\n",
            "TOOK:  0.17563152313232422\n",
            "TOOK:  0.17414283752441406\n",
            "TOOK:  0.17343378067016602\n",
            "TOOK:  0.1751422882080078\n",
            "TOOK:  0.1699509620666504\n",
            "TOOK:  0.16740083694458008\n",
            "TOOK:  0.17527389526367188\n",
            "TOOK:  0.18322086334228516\n",
            "TOOK:  0.18580961227416992\n",
            "TOOK:  0.18018269538879395\n",
            "TOOK:  0.17145442962646484\n",
            "TOOK:  0.1728670597076416\n",
            "TOOK:  0.1759786605834961\n",
            "TOOK:  0.17344450950622559\n",
            "TOOK:  0.17503571510314941\n",
            "TOOK:  0.6207494735717773\n",
            "TOOK:  0.11977291107177734\n",
            "TOOK:  0.12995553016662598\n",
            "TOOK:  0.12160038948059082\n",
            "TOOK:  0.1215507984161377\n",
            "TOOK:  0.12393975257873535\n",
            "TOOK:  0.12521576881408691\n",
            "TOOK:  0.12329840660095215\n",
            "TOOK:  0.12450599670410156\n",
            "TOOK:  0.1207878589630127\n",
            "TOOK:  0.1387176513671875\n",
            "TOOK:  0.12848591804504395\n",
            "TOOK:  0.13457012176513672\n",
            "TOOK:  0.12967324256896973\n",
            "TOOK:  0.13412880897521973\n",
            "TOOK:  0.12678790092468262\n",
            "TOOK:  0.1250622272491455\n",
            "TOOK:  0.12299561500549316\n",
            "TOOK:  0.12958002090454102\n",
            "TOOK:  0.12124204635620117\n",
            "TOOK:  0.12804627418518066\n",
            "TOOK:  0.12532806396484375\n",
            "TOOK:  0.12575984001159668\n",
            "TOOK:  0.12636804580688477\n",
            "TOOK:  0.12114357948303223\n",
            "TOOK:  0.12746787071228027\n",
            "TOOK:  0.13385748863220215\n",
            "TOOK:  0.13195323944091797\n",
            "TOOK:  0.1254727840423584\n",
            "TOOK:  0.12367868423461914\n",
            "TOOK:  0.1294693946838379\n",
            "TOOK:  0.12476420402526855\n",
            "TOOK:  0.127394437789917\n",
            "TOOK:  0.12546968460083008\n",
            "TOOK:  0.14069819450378418\n",
            "TOOK:  0.12653207778930664\n",
            "TOOK:  0.12688946723937988\n",
            "TOOK:  0.13402938842773438\n",
            "TOOK:  0.12588000297546387\n",
            "TOOK:  0.1312263011932373\n",
            "TOOK:  0.14090752601623535\n",
            "TOOK:  0.13866233825683594\n",
            "TOOK:  0.13448476791381836\n",
            "TOOK:  0.145233154296875\n",
            "TOOK:  0.12748456001281738\n",
            "TOOK:  0.1371917724609375\n",
            "TOOK:  0.12658071517944336\n",
            "TOOK:  0.12950801849365234\n",
            "TOOK:  0.12836146354675293\n",
            "TOOK:  0.13785791397094727\n",
            "TOOK:  0.13362407684326172\n",
            "TOOK:  0.12725567817687988\n",
            "TOOK:  0.13445711135864258\n",
            "TOOK:  0.1302788257598877\n",
            "TOOK:  0.12833142280578613\n",
            "TOOK:  0.13513445854187012\n",
            "TOOK:  0.12908005714416504\n",
            "TOOK:  0.14316415786743164\n",
            "TOOK:  0.12833452224731445\n",
            "TOOK:  0.1299138069152832\n",
            "TOOK:  0.12946629524230957\n",
            "TOOK:  0.1300802230834961\n",
            "TOOK:  0.1246957778930664\n",
            "TOOK:  0.13393259048461914\n",
            "TOOK:  0.13140606880187988\n",
            "TOOK:  0.1332409381866455\n",
            "TOOK:  0.13387584686279297\n",
            "TOOK:  0.1281116008758545\n",
            "TOOK:  0.12888073921203613\n",
            "TOOK:  0.12922883033752441\n",
            "TOOK:  0.13100910186767578\n",
            "TOOK:  0.13501787185668945\n",
            "TOOK:  0.17137932777404785\n",
            "TOOK:  0.13408613204956055\n",
            "TOOK:  0.1314234733581543\n",
            "TOOK:  0.1318340301513672\n",
            "TOOK:  0.14189457893371582\n",
            "TOOK:  0.1636216640472412\n",
            "TOOK:  0.18754148483276367\n",
            "TOOK:  0.1819474697113037\n",
            "TOOK:  0.2079176902770996\n",
            "TOOK:  0.1841585636138916\n",
            "TOOK:  0.21230816841125488\n",
            "TOOK:  0.18430685997009277\n",
            "TOOK:  0.17404508590698242\n",
            "TOOK:  0.19150733947753906\n",
            "TOOK:  0.17274165153503418\n",
            "TOOK:  0.18000364303588867\n",
            "TOOK:  0.17241311073303223\n",
            "{\n",
            "  \"humaneval-x-bugs-python\": {\n",
            "    \"pass@1\": 1.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-python\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check canonical solutions are indeed all right ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-python \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5YzcfartucW",
        "outputId": "de381df8-c38a-40f6-fbd7-17112b0a4b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-01 11:08:11.458138: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-01 11:08:12.513718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-python']\n",
            "Loading the model and tokenizer\n",
            "Downloading: 100% 903/903 [00:00<00:00, 809kB/s]\n",
            "Downloading: 100% 457M/457M [00:11<00:00, 40.1MB/s]\n",
            "Downloading: 100% 259/259 [00:00<00:00, 268kB/s]\n",
            "Downloading: 100% 497k/497k [00:00<00:00, 1.43MB/s]\n",
            "Downloading: 100% 277k/277k [00:00<00:00, 806kB/s]\n",
            "Downloading: 100% 840k/840k [00:00<00:00, 1.93MB/s]\n",
            "Downloading: 100% 90.0/90.0 [00:00<00:00, 82.9kB/s]\n",
            "Downloading builder script: 100% 5.86k/5.86k [00:00<00:00, 4.86MB/s]\n",
            "Downloading readme: 100% 6.00/6.00 [00:00<00:00, 5.44kB/s]\n",
            "Downloading and preparing dataset humaneval-x-bugs/python to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/python/1.0.0/af7a71881b1fc378edefa4b2c3ddc510933ed90c46b7081ea1843bab250d706b...\n",
            "Downloading data: 100% 394k/394k [00:00<00:00, 1.14MB/s]\n",
            "Dataset humaneval-x-bugs downloaded and prepared to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/python/1.0.0/af7a71881b1fc378edefa4b2c3ddc510933ed90c46b7081ea1843bab250d706b. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 674.87it/s]\n",
            "100% 1/1 [00:00<00:00, 739.08it/s]\n",
            "Downloading builder script: 100% 9.21k/9.21k [00:00<00:00, 6.95MB/s]\n",
            "Downloading extra modules: 100% 12.2k/12.2k [00:00<00:00, 10.1MB/s]\n",
            "{\n",
            "  \"humaneval-x-bugs-python\": {\n",
            "    \"pass@1\": 0.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-python\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check buggy solutions are indeed all wrong ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-python \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FancJ8MuCVA"
      },
      "source": [
        "##### JavaScript\n",
        "\n",
        "We need to update JavaScript as there are some things only available in later versions, such as .at on an array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmiBZhLKsBbC",
        "outputId": "1e2fa20a-4a22-4649-8967-990de260ac44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "v14.16.0\n"
          ]
        }
      ],
      "source": [
        "!node -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLKfakG9smgl",
        "outputId": "2ccafe45-df1c-46d1-a21b-bb8406f5e0e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 31.2M  100 31.2M    0     0   161M      0 --:--:-- --:--:-- --:--:--  161M\n",
            "\u001b[K\u001b[?25h+ js-md5@0.7.3\n",
            "added 1 package from 1 contributor in 0.237s\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/bigcode-evaluation-harness/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/bigcode-evaluation-harness/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m bigcode-evaluation-harness No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m bigcode-evaluation-harness No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m bigcode-evaluation-harness No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m bigcode-evaluation-harness No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ js-md5@0.7.3\n",
            "added 1 package from 1 contributor and audited 1 package in 0.27s\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[33m   ╭───────────────────────────────────────────────────────────────╮\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                               \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m      New \u001b[31mmajor\u001b[39m version of npm available! \u001b[31m6.14.8\u001b[39m → \u001b[32m9.6.3\u001b[39m       \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m   \u001b[33mChangelog:\u001b[39m \u001b[36mhttps://github.com/npm/cli/releases/tag/v9.6.3\u001b[39m   \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m               Run \u001b[32mnpm install -g npm\u001b[39m to update!               \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                               \u001b[33m│\u001b[39m\n",
            "\u001b[33m   ╰───────────────────────────────────────────────────────────────╯\u001b[39m\n",
            "\u001b[33m\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/THUDM/CodeGeeX/blob/61529ba61de8e51c520dc67a3ce4bd62278770df/codegeex/docker/Dockerfile#L15\n",
        "!mkdir -p /workspace/download/\n",
        "!curl -o /workspace/download/node.tar.gz -SL https://nodejs.org/download/release/v16.14.0/node-v16.14.0-linux-x64.tar.gz \\\n",
        "    && mkdir -p /usr/local/lib/nodejs && tar -zxf /workspace/download/node.tar.gz -C /usr/local/lib/nodejs && mv /usr/local/lib/nodejs/node-v16.14.0-linux-x64 /usr/local/lib/nodejs/node \\\n",
        "    && rm /workspace/download/node.tar.gz && npm install -g js-md5@0.7.3\n",
        "# The above npm install of js-md5 does not work as its global\n",
        "# Reinstall locally & move to right location\n",
        "!npm install js-md5@0.7.3\n",
        "!mkdir /usr/local/lib/node_modules\n",
        "!mv node_modules/* /usr/local/lib/node_modules/\n",
        "\n",
        "import os\n",
        "os.environ['PATH'] = '/usr/local/lib/nodejs/node/bin:' + os.environ['PATH']\n",
        "os.environ['NODE_PATH'] = '/usr/local/lib/node_modules'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkTrK00FwuIQ",
        "outputId": "ff7538b1-f976-4fbf-d9df-baf661f70e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "v16.14.0\n"
          ]
        }
      ],
      "source": [
        "# Should be v16.14.0\n",
        "!node -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKnFOU2yJaPV",
        "outputId": "77ad45dd-116c-4ca9-a3e7-877f45a28d9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 12:13:11.696511: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-02 12:13:13.300457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-js']\n",
            "Loading the model and tokenizer\n",
            "Downloading: 100% 903/903 [00:00<00:00, 648kB/s]\n",
            "Downloading: 100% 457M/457M [00:07<00:00, 62.8MB/s]\n",
            "Downloading: 100% 259/259 [00:00<00:00, 298kB/s]\n",
            "Downloading: 100% 497k/497k [00:00<00:00, 31.0MB/s]\n",
            "Downloading: 100% 277k/277k [00:00<00:00, 26.9MB/s]\n",
            "Downloading: 100% 840k/840k [00:00<00:00, 26.4MB/s]\n",
            "Downloading: 100% 90.0/90.0 [00:00<00:00, 89.5kB/s]\n",
            "Downloading builder script: 100% 6.30k/6.30k [00:00<00:00, 3.69MB/s]\n",
            "Downloading readme: 100% 6.00/6.00 [00:00<00:00, 5.79kB/s]\n",
            "Downloading and preparing dataset humaneval-x-bugs/js to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/js/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8...\n",
            "Downloading data: 100% 332k/332k [00:00<00:00, 21.5MB/s]\n",
            "Dataset humaneval-x-bugs downloaded and prepared to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/js/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 541.69it/s]\n",
            "100% 1/1 [00:00<00:00, 575.67it/s]\n",
            "Downloading builder script: 100% 9.60k/9.60k [00:00<00:00, 8.52MB/s]\n",
            "Downloading extra modules: 100% 13.4k/13.4k [00:00<00:00, 10.6MB/s]\n",
            "TOOK:  0.1600329875946045\n",
            "TOOK:  0.14080500602722168\n",
            "TOOK:  0.1435408592224121\n",
            "TOOK:  0.14024639129638672\n",
            "TOOK:  0.1458268165588379\n",
            "TOOK:  0.14095807075500488\n",
            "TOOK:  0.14124393463134766\n",
            "TOOK:  0.14911866188049316\n",
            "TOOK:  0.14841079711914062\n",
            "TOOK:  0.14115357398986816\n",
            "TOOK:  0.13828206062316895\n",
            "TOOK:  0.14161014556884766\n",
            "TOOK:  0.1410517692565918\n",
            "TOOK:  0.14774394035339355\n",
            "TOOK:  0.15224671363830566\n",
            "TOOK:  0.16343140602111816\n",
            "TOOK:  0.20345687866210938\n",
            "TOOK:  0.2183845043182373\n",
            "TOOK:  0.21455025672912598\n",
            "TOOK:  0.20567679405212402\n",
            "TOOK:  0.22133708000183105\n",
            "TOOK:  0.2023158073425293\n",
            "TOOK:  0.21294713020324707\n",
            "TOOK:  0.2122642993927002\n",
            "TOOK:  0.20328450202941895\n",
            "TOOK:  0.21538758277893066\n",
            "TOOK:  0.2006690502166748\n",
            "TOOK:  0.21465754508972168\n",
            "TOOK:  0.21848034858703613\n",
            "TOOK:  0.20154881477355957\n",
            "TOOK:  0.20689606666564941\n",
            "TOOK:  0.21384644508361816\n",
            "TOOK:  0.22086191177368164\n",
            "TOOK:  0.20974063873291016\n",
            "TOOK:  0.1997995376586914\n",
            "TOOK:  0.1618199348449707\n",
            "TOOK:  0.16179847717285156\n",
            "TOOK:  0.1426224708557129\n",
            "TOOK:  0.1383836269378662\n",
            "TOOK:  0.14840364456176758\n",
            "TOOK:  0.13805699348449707\n",
            "TOOK:  0.14017343521118164\n",
            "TOOK:  0.1457381248474121\n",
            "TOOK:  0.142869234085083\n",
            "TOOK:  0.14313125610351562\n",
            "TOOK:  0.14621210098266602\n",
            "TOOK:  0.14377999305725098\n",
            "TOOK:  0.15518498420715332\n",
            "TOOK:  0.14258599281311035\n",
            "TOOK:  0.14609456062316895\n",
            "TOOK:  0.14550328254699707\n",
            "TOOK:  0.1397871971130371\n",
            "TOOK:  0.14374828338623047\n",
            "TOOK:  0.1423337459564209\n",
            "TOOK:  0.1443617343902588\n",
            "TOOK:  0.14322280883789062\n",
            "TOOK:  0.1458888053894043\n",
            "TOOK:  0.14679861068725586\n",
            "TOOK:  0.1417078971862793\n",
            "TOOK:  0.14524292945861816\n",
            "TOOK:  0.14653253555297852\n",
            "TOOK:  0.1431572437286377\n",
            "TOOK:  0.14366793632507324\n",
            "TOOK:  0.14593005180358887\n",
            "TOOK:  0.14224910736083984\n",
            "TOOK:  0.13718485832214355\n",
            "TOOK:  0.14823365211486816\n",
            "TOOK:  0.13996434211730957\n",
            "TOOK:  0.14812946319580078\n",
            "TOOK:  0.14700555801391602\n",
            "TOOK:  0.15854763984680176\n",
            "TOOK:  0.14091992378234863\n",
            "TOOK:  0.1438143253326416\n",
            "TOOK:  0.1403670310974121\n",
            "TOOK:  0.14377522468566895\n",
            "TOOK:  0.16989421844482422\n",
            "TOOK:  0.13937902450561523\n",
            "TOOK:  0.15027785301208496\n",
            "TOOK:  0.14078092575073242\n",
            "TOOK:  0.14584064483642578\n",
            "TOOK:  0.137040376663208\n",
            "TOOK:  0.14214611053466797\n",
            "TOOK:  0.14324736595153809\n",
            "TOOK:  0.15018510818481445\n",
            "TOOK:  0.15326428413391113\n",
            "TOOK:  0.14650559425354004\n",
            "TOOK:  0.14478182792663574\n",
            "TOOK:  0.14587855339050293\n",
            "TOOK:  0.14913177490234375\n",
            "TOOK:  0.1473398208618164\n",
            "TOOK:  0.1510937213897705\n",
            "TOOK:  0.15214300155639648\n",
            "TOOK:  0.15223455429077148\n",
            "TOOK:  0.13919806480407715\n",
            "TOOK:  0.1469419002532959\n",
            "TOOK:  0.14080023765563965\n",
            "TOOK:  0.14362597465515137\n",
            "TOOK:  0.14519047737121582\n",
            "TOOK:  0.14991497993469238\n",
            "TOOK:  0.1445763111114502\n",
            "TOOK:  0.14080262184143066\n",
            "TOOK:  0.14805340766906738\n",
            "TOOK:  0.13935232162475586\n",
            "TOOK:  0.15388822555541992\n",
            "TOOK:  0.20847606658935547\n",
            "TOOK:  0.21108293533325195\n",
            "TOOK:  0.20002985000610352\n",
            "TOOK:  0.20509791374206543\n",
            "TOOK:  0.19391536712646484\n",
            "TOOK:  0.2064192295074463\n",
            "TOOK:  0.2050457000732422\n",
            "TOOK:  0.19584441184997559\n",
            "TOOK:  0.2118055820465088\n",
            "TOOK:  0.23396897315979004\n",
            "TOOK:  0.2093973159790039\n",
            "TOOK:  0.21889543533325195\n",
            "TOOK:  0.2085895538330078\n",
            "TOOK:  0.1961839199066162\n",
            "TOOK:  0.2282395362854004\n",
            "TOOK:  0.20424270629882812\n",
            "TOOK:  0.21584129333496094\n",
            "TOOK:  0.20087456703186035\n",
            "TOOK:  0.20969414710998535\n",
            "TOOK:  0.15497279167175293\n",
            "TOOK:  0.13970375061035156\n",
            "TOOK:  0.15169024467468262\n",
            "TOOK:  0.14383721351623535\n",
            "TOOK:  0.14670181274414062\n",
            "TOOK:  0.14631175994873047\n",
            "TOOK:  0.1445779800415039\n",
            "TOOK:  0.1453382968902588\n",
            "TOOK:  0.14260339736938477\n",
            "TOOK:  0.15446257591247559\n",
            "TOOK:  0.13910150527954102\n",
            "TOOK:  0.1428537368774414\n",
            "TOOK:  0.13979244232177734\n",
            "TOOK:  0.1414809226989746\n",
            "TOOK:  0.1521148681640625\n",
            "TOOK:  0.1522376537322998\n",
            "TOOK:  0.1477646827697754\n",
            "TOOK:  0.15046191215515137\n",
            "TOOK:  0.14908289909362793\n",
            "TOOK:  0.13869714736938477\n",
            "TOOK:  0.1436901092529297\n",
            "TOOK:  0.14495325088500977\n",
            "TOOK:  0.13851237297058105\n",
            "TOOK:  0.1521451473236084\n",
            "TOOK:  0.14934444427490234\n",
            "TOOK:  0.1558089256286621\n",
            "TOOK:  0.14763307571411133\n",
            "TOOK:  0.15191197395324707\n",
            "TOOK:  0.14433503150939941\n",
            "TOOK:  0.15542268753051758\n",
            "TOOK:  0.15185189247131348\n",
            "TOOK:  0.14853787422180176\n",
            "TOOK:  0.141204833984375\n",
            "TOOK:  0.1434798240661621\n",
            "TOOK:  0.1429293155670166\n",
            "TOOK:  0.1493854522705078\n",
            "TOOK:  0.14114117622375488\n",
            "TOOK:  0.15110111236572266\n",
            "TOOK:  0.1509556770324707\n",
            "TOOK:  0.1503598690032959\n",
            "TOOK:  0.14363813400268555\n",
            "{\n",
            "  \"humaneval-x-bugs-js\": {\n",
            "    \"pass@1\": 1.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-js\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check canonical solutions are indeed all right ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-js \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yiql40S3KVii",
        "outputId": "a0d13448-7a24-4038-f103-9e34b4937cf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 12:15:38.613584: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-02 12:15:40.240870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-js']\n",
            "Loading the model and tokenizer\n",
            "100% 1/1 [00:00<00:00, 553.85it/s]\n",
            "100% 1/1 [00:00<00:00, 604.11it/s]\n",
            "TOOK:  0.15213990211486816\n",
            "TOOK:  0.17190861701965332\n",
            "TOOK:  0.14653539657592773\n",
            "TOOK:  0.14171981811523438\n",
            "TOOK:  0.155501127243042\n",
            "TOOK:  0.15668940544128418\n",
            "TOOK:  0.15585899353027344\n",
            "TOOK:  0.15316009521484375\n",
            "TOOK:  0.14919400215148926\n",
            "TOOK:  0.1475539207458496\n",
            "TOOK:  100.20964026451111\n",
            "TOOK:  0.14397525787353516\n",
            "TOOK:  0.17661809921264648\n",
            "TOOK:  0.14706730842590332\n",
            "TOOK:  0.14518356323242188\n",
            "TOOK:  0.14809513092041016\n",
            "TOOK:  0.1407020092010498\n",
            "TOOK:  0.1474132537841797\n",
            "TOOK:  0.14711308479309082\n",
            "TOOK:  0.15285325050354004\n",
            "TOOK:  0.15966534614562988\n",
            "TOOK:  0.16812753677368164\n",
            "TOOK:  0.1395263671875\n",
            "TOOK:  0.15041303634643555\n",
            "TOOK:  0.14804577827453613\n",
            "TOOK:  4.166487693786621\n",
            "TOOK:  0.1445777416229248\n",
            "TOOK:  0.1556694507598877\n",
            "TOOK:  0.14473199844360352\n",
            "TOOK:  0.14601349830627441\n",
            "TOOK:  0.1431586742401123\n",
            "TOOK:  0.15256834030151367\n",
            "TOOK:  0.15973591804504395\n",
            "TOOK:  0.1539759635925293\n",
            "TOOK:  0.15030193328857422\n",
            "TOOK:  0.15527105331420898\n",
            "TOOK:  0.2322993278503418\n",
            "TOOK:  0.22158050537109375\n",
            "TOOK:  0.2423405647277832\n",
            "TOOK:  0.21510076522827148\n",
            "TOOK:  0.2154989242553711\n",
            "TOOK:  0.2124030590057373\n",
            "TOOK:  0.22229647636413574\n",
            "TOOK:  0.2197251319885254\n",
            "TOOK:  0.20949864387512207\n",
            "TOOK:  0.21584057807922363\n",
            "TOOK:  0.20631718635559082\n",
            "TOOK:  0.21323204040527344\n",
            "TOOK:  0.20546889305114746\n",
            "TOOK:  0.2121906280517578\n",
            "TOOK:  0.20991969108581543\n",
            "TOOK:  0.20922064781188965\n",
            "TOOK:  0.21283507347106934\n",
            "TOOK:  0.21343517303466797\n",
            "TOOK:  0.2285006046295166\n",
            "TOOK:  0.14881253242492676\n",
            "TOOK:  0.15101218223571777\n",
            "TOOK:  0.14782166481018066\n",
            "TOOK:  0.15867829322814941\n",
            "TOOK:  0.14765071868896484\n",
            "TOOK:  0.14852118492126465\n",
            "TOOK:  0.1413102149963379\n",
            "TOOK:  0.14584636688232422\n",
            "TOOK:  0.1473860740661621\n",
            "TOOK:  0.1531999111175537\n",
            "TOOK:  0.15387368202209473\n",
            "TOOK:  0.14368104934692383\n",
            "TOOK:  0.14083504676818848\n",
            "TOOK:  0.1437511444091797\n",
            "TOOK:  0.14194989204406738\n",
            "TOOK:  0.152618408203125\n",
            "TOOK:  0.1468639373779297\n",
            "TOOK:  0.16086769104003906\n",
            "TOOK:  0.14479565620422363\n",
            "TOOK:  0.1475369930267334\n",
            "TOOK:  0.1434178352355957\n",
            "TOOK:  100.20826244354248\n",
            "TOOK:  0.14977431297302246\n",
            "TOOK:  0.1513974666595459\n",
            "TOOK:  0.1452631950378418\n",
            "TOOK:  0.1459345817565918\n",
            "TOOK:  0.15639162063598633\n",
            "TOOK:  0.1412796974182129\n",
            "TOOK:  0.14846348762512207\n",
            "TOOK:  0.15665578842163086\n",
            "TOOK:  0.1553337574005127\n",
            "TOOK:  0.14601445198059082\n",
            "TOOK:  0.14884734153747559\n",
            "TOOK:  0.1610732078552246\n",
            "TOOK:  0.1523149013519287\n",
            "TOOK:  0.14833617210388184\n",
            "TOOK:  0.1443922519683838\n",
            "TOOK:  0.14843106269836426\n",
            "TOOK:  0.15027809143066406\n",
            "TOOK:  0.14815306663513184\n",
            "TOOK:  0.1477363109588623\n",
            "TOOK:  0.1461191177368164\n",
            "TOOK:  0.15109729766845703\n",
            "TOOK:  0.1571826934814453\n",
            "TOOK:  0.15609383583068848\n",
            "TOOK:  0.15906071662902832\n",
            "TOOK:  0.16146612167358398\n",
            "TOOK:  0.15380263328552246\n",
            "TOOK:  0.15151119232177734\n",
            "TOOK:  0.14911389350891113\n",
            "TOOK:  0.1501927375793457\n",
            "TOOK:  0.14656329154968262\n",
            "TOOK:  0.14833450317382812\n",
            "TOOK:  0.1534435749053955\n",
            "TOOK:  0.14374256134033203\n",
            "TOOK:  0.14925765991210938\n",
            "TOOK:  0.1483445167541504\n",
            "TOOK:  0.14988994598388672\n",
            "TOOK:  0.16158032417297363\n",
            "TOOK:  0.14500999450683594\n",
            "TOOK:  0.15163254737854004\n",
            "TOOK:  0.14621281623840332\n",
            "TOOK:  0.14815759658813477\n",
            "TOOK:  0.15165209770202637\n",
            "TOOK:  0.16527938842773438\n",
            "TOOK:  0.14661741256713867\n",
            "TOOK:  0.15926313400268555\n",
            "TOOK:  0.14389824867248535\n",
            "TOOK:  0.15994620323181152\n",
            "TOOK:  0.14940643310546875\n",
            "TOOK:  0.1500864028930664\n",
            "TOOK:  0.14695215225219727\n",
            "TOOK:  0.219160795211792\n",
            "TOOK:  0.2227473258972168\n",
            "TOOK:  0.20528650283813477\n",
            "TOOK:  0.21127986907958984\n",
            "TOOK:  0.21541309356689453\n",
            "TOOK:  0.21174979209899902\n",
            "TOOK:  0.21833133697509766\n",
            "TOOK:  0.22293782234191895\n",
            "TOOK:  0.2008650302886963\n",
            "TOOK:  0.21383070945739746\n",
            "TOOK:  0.22286558151245117\n",
            "TOOK:  0.21277332305908203\n",
            "TOOK:  0.20554089546203613\n",
            "TOOK:  0.21800708770751953\n",
            "TOOK:  0.21735763549804688\n",
            "TOOK:  0.21050119400024414\n",
            "TOOK:  0.20285344123840332\n",
            "TOOK:  0.23250055313110352\n",
            "TOOK:  0.22031521797180176\n",
            "TOOK:  0.1590745449066162\n",
            "TOOK:  0.1690201759338379\n",
            "TOOK:  0.1534256935119629\n",
            "TOOK:  0.15025568008422852\n",
            "TOOK:  0.15527987480163574\n",
            "TOOK:  0.1482398509979248\n",
            "TOOK:  0.15040206909179688\n",
            "TOOK:  0.1446373462677002\n",
            "TOOK:  0.1611766815185547\n",
            "TOOK:  100.207754611969\n",
            "TOOK:  100.18304181098938\n",
            "TOOK:  0.1557769775390625\n",
            "TOOK:  0.1453559398651123\n",
            "TOOK:  0.14020752906799316\n",
            "TOOK:  0.14496111869812012\n",
            "TOOK:  0.14944863319396973\n",
            "TOOK:  0.1571650505065918\n",
            "TOOK:  0.1430361270904541\n",
            "{\n",
            "  \"humaneval-x-bugs-js\": {\n",
            "    \"pass@1\": 0.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-js\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check buggy solutions are indeed all wrong ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-js \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXlXzNu3w4SD"
      },
      "source": [
        "##### Java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d_xjRk-y7yd",
        "outputId": "bca525da-b34a-4677-8cc9-bb672b4ade7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.18\" 2023-01-17\n",
            "OpenJDK Runtime Environment (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU1vvWr5w8N0",
        "outputId": "1521694f-3314-420c-d562-46a31cb9eb60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  173M  100  173M    0     0  6033k      0  0:00:29  0:00:29 --:--:-- 7019k\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/THUDM/CodeGeeX/blob/61529ba61de8e51c520dc67a3ce4bd62278770df/codegeex/docker/Dockerfile#L31\n",
        "!mkdir -p /workspace/download/\n",
        "!curl -o /workspace/download/jdk.tar.gz -SL https://download.oracle.com/java/18/archive/jdk-18_linux-x64_bin.tar.gz \\\n",
        "    && mkdir /usr/java && tar -zxf /workspace/download/jdk.tar.gz -C /usr/java && rm /workspace/download/jdk.tar.gz \\\n",
        "    && java_path=`ls /usr/java/${path}` && echo \"export JAVA_HOME=/usr/java/${java_path}\" >> ~/.profile\n",
        "\n",
        "import os\n",
        "os.environ['PATH'] = '/usr/java/jdk-18/bin:' + os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3_i6DyQyUyi",
        "outputId": "235fe073-e785-43bd-a148-7c7580dc8b0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "java version \"18\" 2022-03-22\n",
            "Java(TM) SE Runtime Environment (build 18+36-2087)\n",
            "Java HotSpot(TM) 64-Bit Server VM (build 18+36-2087, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "# Should be java version \"18\"\n",
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEzOQcIkw_kK",
        "outputId": "572d4723-df88-4446-c8cf-0b3dd7007c59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 16:33:14.162231: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-02 16:33:15.436885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-java']\n",
            "Loading the model and tokenizer\n",
            "100% 1/1 [00:00<00:00, 443.37it/s]\n",
            "100% 1/1 [00:00<00:00, 512.50it/s]\n",
            "defaultdict(<class 'list'>, {2: [(0, {'task_id': 2, 'passed': True, 'result': 'passed', 'completion_id': 0})], 3: [(0, {'task_id': 3, 'passed': True, 'result': 'passed', 'completion_id': 0})], 1: [(0, {'task_id': 1, 'passed': True, 'result': 'passed', 'completion_id': 0})], 0: [(0, {'task_id': 0, 'passed': True, 'result': 'passed', 'completion_id': 0})], 4: [(0, {'task_id': 4, 'passed': True, 'result': 'passed', 'completion_id': 0})]})\n",
            "{\n",
            "  \"humaneval-x-bugs-java\": {\n",
            "    \"pass@1\": 1.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-java\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": 5,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check canonical solutions are indeed all right ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-java \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references --limit 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdEWLGM-GX2D",
        "outputId": "d54419f4-b068-469c-c4ad-64fbdeab15bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 11:42:10.857477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-java']\n",
            "Loading the model and tokenizer\n",
            "Downloading and preparing dataset humaneval-x-bugs/java to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/java/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8...\n",
            "Downloading data: 100% 554k/554k [00:00<00:00, 5.80MB/s]\n",
            "Dataset humaneval-x-bugs downloaded and prepared to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/java/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 492.93it/s]\n",
            "100% 1/1 [00:00<00:00, 526.39it/s]\n",
            "TOOK:  1.4058260917663574\n",
            "TOOK:  1.3119094371795654\n",
            "TOOK:  1.2963917255401611\n",
            "TOOK:  1.3066115379333496\n",
            "TOOK:  1.2815511226654053\n",
            "TOOK:  1.5124330520629883\n",
            "TOOK:  2.2372400760650635\n",
            "TOOK:  1.9502508640289307\n",
            "TOOK:  1.3960299491882324\n",
            "TOOK:  1.379185438156128\n",
            "TOOK:  1.3058803081512451\n",
            "TOOK:  1.2420742511749268\n",
            "TOOK:  1.3363473415374756\n",
            "TOOK:  1.2169618606567383\n",
            "TOOK:  1.2861177921295166\n",
            "TOOK:  1.8110074996948242\n",
            "TOOK:  2.121060609817505\n",
            "TOOK:  1.6433920860290527\n",
            "TOOK:  1.2801287174224854\n",
            "TOOK:  1.2376868724822998\n",
            "TOOK:  1.4839787483215332\n",
            "TOOK:  1.4129061698913574\n",
            "TOOK:  1.4881925582885742\n",
            "TOOK:  1.2531607151031494\n",
            "TOOK:  1.294111728668213\n",
            "TOOK:  2.3281772136688232\n",
            "TOOK:  2.152665376663208\n",
            "TOOK:  1.2588634490966797\n",
            "TOOK:  1.2898011207580566\n",
            "TOOK:  1.391249656677246\n",
            "TOOK:  1.4675219058990479\n",
            "TOOK:  1.256211280822754\n",
            "TOOK:  1.3316476345062256\n",
            "TOOK:  1.4874510765075684\n",
            "TOOK:  2.3917646408081055\n",
            "TOOK:  2.208146572113037\n",
            "TOOK:  1.2781221866607666\n",
            "TOOK:  1.3520419597625732\n",
            "TOOK:  1.29286527633667\n",
            "TOOK:  1.2727675437927246\n",
            "TOOK:  1.3458316326141357\n",
            "TOOK:  1.2147836685180664\n",
            "TOOK:  1.3792779445648193\n",
            "TOOK:  2.055623769760132\n",
            "TOOK:  2.3969814777374268\n",
            "TOOK:  1.4907517433166504\n",
            "TOOK:  1.2741954326629639\n",
            "TOOK:  1.2693665027618408\n",
            "TOOK:  1.2300195693969727\n",
            "TOOK:  1.1900956630706787\n",
            "TOOK:  1.238642692565918\n",
            "TOOK:  1.2998480796813965\n",
            "TOOK:  1.360037088394165\n",
            "TOOK:  1.9545695781707764\n",
            "TOOK:  2.2465479373931885\n",
            "TOOK:  1.420872449874878\n",
            "TOOK:  1.301727533340454\n",
            "TOOK:  1.3958001136779785\n",
            "TOOK:  1.440659761428833\n",
            "TOOK:  1.248032808303833\n",
            "TOOK:  1.2240478992462158\n",
            "TOOK:  1.194795846939087\n",
            "TOOK:  1.403660535812378\n",
            "TOOK:  2.1293785572052\n",
            "TOOK:  2.096134662628174\n",
            "TOOK:  1.2823832035064697\n",
            "TOOK:  1.2810189723968506\n",
            "TOOK:  1.3158419132232666\n",
            "TOOK:  1.4782390594482422\n",
            "TOOK:  1.6987254619598389\n",
            "TOOK:  1.5547051429748535\n",
            "TOOK:  1.2094073295593262\n",
            "TOOK:  2.3811800479888916\n",
            "TOOK:  2.4334280490875244\n",
            "TOOK:  1.640566110610962\n",
            "TOOK:  1.24407958984375\n",
            "TOOK:  1.216160774230957\n",
            "TOOK:  1.2248060703277588\n",
            "TOOK:  1.2256674766540527\n",
            "TOOK:  1.2703123092651367\n",
            "TOOK:  1.2479817867279053\n",
            "TOOK:  2.002810001373291\n",
            "TOOK:  2.2539234161376953\n",
            "TOOK:  1.6503121852874756\n",
            "TOOK:  1.2068519592285156\n",
            "TOOK:  1.3447582721710205\n",
            "TOOK:  1.2540321350097656\n",
            "TOOK:  1.7237217426300049\n",
            "TOOK:  1.4857723712921143\n",
            "TOOK:  1.243776559829712\n",
            "TOOK:  1.5474278926849365\n",
            "TOOK:  2.2706713676452637\n",
            "TOOK:  2.0396924018859863\n",
            "TOOK:  1.2980787754058838\n",
            "TOOK:  1.3780527114868164\n",
            "TOOK:  1.2918241024017334\n",
            "TOOK:  1.351036548614502\n",
            "TOOK:  1.1747863292694092\n",
            "TOOK:  1.220318078994751\n",
            "TOOK:  1.2556145191192627\n",
            "TOOK:  1.738642692565918\n",
            "TOOK:  2.4177567958831787\n",
            "TOOK:  1.676947832107544\n",
            "TOOK:  1.332043170928955\n",
            "TOOK:  1.3304998874664307\n",
            "TOOK:  1.459303855895996\n",
            "TOOK:  1.2920832633972168\n",
            "TOOK:  1.354870319366455\n",
            "TOOK:  1.4043996334075928\n",
            "TOOK:  1.470059871673584\n",
            "TOOK:  2.500920534133911\n",
            "TOOK:  1.9579238891601562\n",
            "TOOK:  1.4004185199737549\n",
            "TOOK:  1.3535044193267822\n",
            "TOOK:  1.4191195964813232\n",
            "TOOK:  1.5613141059875488\n",
            "TOOK:  1.692756175994873\n",
            "TOOK:  1.314115047454834\n",
            "TOOK:  1.5159544944763184\n",
            "TOOK:  2.5689706802368164\n",
            "TOOK:  1.925856113433838\n",
            "TOOK:  1.3228390216827393\n",
            "TOOK:  1.3436567783355713\n",
            "TOOK:  1.320258617401123\n",
            "TOOK:  1.301724910736084\n",
            "TOOK:  1.317345142364502\n",
            "TOOK:  1.4554946422576904\n",
            "TOOK:  1.6920819282531738\n",
            "TOOK:  2.4684245586395264\n",
            "TOOK:  2.262535572052002\n",
            "TOOK:  1.3541665077209473\n",
            "TOOK:  1.2560837268829346\n",
            "TOOK:  1.3033783435821533\n",
            "TOOK:  1.4283714294433594\n",
            "TOOK:  1.352125883102417\n",
            "TOOK:  1.348327875137329\n",
            "TOOK:  2.5377464294433594\n",
            "TOOK:  2.301138162612915\n",
            "TOOK:  1.4166936874389648\n",
            "TOOK:  1.167388677597046\n",
            "TOOK:  1.2801766395568848\n",
            "TOOK:  1.3995518684387207\n",
            "TOOK:  1.4670896530151367\n",
            "TOOK:  1.2271828651428223\n",
            "TOOK:  1.2402076721191406\n",
            "TOOK:  1.6211533546447754\n",
            "TOOK:  2.405992031097412\n",
            "TOOK:  2.0725414752960205\n",
            "TOOK:  1.2876734733581543\n",
            "TOOK:  1.6630871295928955\n",
            "TOOK:  1.2232346534729004\n",
            "TOOK:  1.5103459358215332\n",
            "TOOK:  1.4258782863616943\n",
            "TOOK:  1.3716695308685303\n",
            "TOOK:  1.2493607997894287\n",
            "TOOK:  2.446279287338257\n",
            "TOOK:  2.2198410034179688\n",
            "TOOK:  1.2548182010650635\n",
            "TOOK:  1.5328500270843506\n",
            "TOOK:  1.315171718597412\n",
            "TOOK:  1.4262378215789795\n",
            "TOOK:  1.2850322723388672\n",
            "TOOK:  1.315178394317627\n",
            "TOOK:  1.3434908390045166\n",
            "{\n",
            "  \"humaneval-x-bugs-java\": {\n",
            "    \"pass@1\": 1.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-java\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check canonical solutions are indeed all right ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-java \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKZt5TGDTo2e",
        "outputId": "7075e1f9-f2b8-41c1-9b17-3157d9b36856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 08:40:40.387913: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-02 08:40:41.609679: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-java']\n",
            "Loading the model and tokenizer\n",
            "Downloading and preparing dataset humaneval-x-bugs/java to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/java/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8...\n",
            "Downloading data: 100% 554k/554k [00:00<00:00, 40.2MB/s]\n",
            "Dataset humaneval-x-bugs downloaded and prepared to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/java/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 503.88it/s]\n",
            "100% 1/1 [00:00<00:00, 539.25it/s]\n",
            "TOOK:  1.3644871711730957\n",
            "TOOK:  1.249884843826294\n",
            "TOOK:  1.2179946899414062\n",
            "TOOK:  1.3283400535583496\n",
            "TOOK:  1.9092457294464111\n",
            "TOOK:  2.400533437728882\n",
            "TOOK:  1.5051558017730713\n",
            "TOOK:  1.2815897464752197\n",
            "TOOK:  1.360595703125\n",
            "TOOK:  1.3112685680389404\n",
            "TOOK:  11.087887525558472\n",
            "TOOK:  1.8741157054901123\n",
            "TOOK:  2.0296032428741455\n",
            "TOOK:  1.9354040622711182\n",
            "TOOK:  1.9089548587799072\n",
            "TOOK:  2.942580223083496\n",
            "TOOK:  2.951416015625\n",
            "TOOK:  2.1441500186920166\n",
            "TOOK:  1.8611094951629639\n",
            "TOOK:  2.0946266651153564\n",
            "TOOK:  2.2798452377319336\n",
            "TOOK:  2.7885560989379883\n",
            "TOOK:  3.8827710151672363\n",
            "TOOK:  2.001674175262451\n",
            "TOOK:  1.8234875202178955\n",
            "TOOK:  2.0545730590820312\n",
            "TOOK:  2.337196111679077\n",
            "TOOK:  1.9854202270507812\n",
            "TOOK:  3.4280195236206055\n",
            "TOOK:  2.6979033946990967\n",
            "TOOK:  2.3196871280670166\n",
            "TOOK:  1.918870449066162\n",
            "TOOK:  1.9762933254241943\n",
            "TOOK:  2.1680965423583984\n",
            "TOOK:  2.9346489906311035\n",
            "TOOK:  3.1452863216400146\n",
            "TOOK:  1.9434103965759277\n",
            "TOOK:  2.155626058578491\n",
            "TOOK:  2.001228094100952\n",
            "TOOK:  11.175024271011353\n",
            "TOOK:  2.78670597076416\n",
            "TOOK:  2.645202398300171\n",
            "TOOK:  3.857130527496338\n",
            "TOOK:  4.472672462463379\n",
            "TOOK:  2.8606250286102295\n",
            "TOOK:  2.6426913738250732\n",
            "TOOK:  2.8061137199401855\n",
            "TOOK:  3.99772047996521\n",
            "TOOK:  3.478708028793335\n",
            "TOOK:  2.681990623474121\n",
            "TOOK:  2.6427204608917236\n",
            "TOOK:  2.9351367950439453\n",
            "TOOK:  4.380258560180664\n",
            "TOOK:  3.2554283142089844\n",
            "TOOK:  3.8380279541015625\n",
            "TOOK:  3.477224111557007\n",
            "TOOK:  3.550684928894043\n",
            "TOOK:  4.223151206970215\n",
            "TOOK:  3.0965657234191895\n",
            "TOOK:  2.6059296131134033\n",
            "TOOK:  2.5389187335968018\n",
            "TOOK:  3.77909255027771\n",
            "TOOK:  4.177316665649414\n",
            "TOOK:  2.6987392902374268\n",
            "TOOK:  2.6417293548583984\n",
            "TOOK:  2.6396193504333496\n",
            "TOOK:  3.519317865371704\n",
            "TOOK:  4.1040260791778564\n",
            "TOOK:  3.2802071571350098\n",
            "TOOK:  3.5554187297821045\n",
            "TOOK:  3.7278549671173096\n",
            "TOOK:  4.187350749969482\n",
            "TOOK:  2.918485641479492\n",
            "TOOK:  2.9677798748016357\n",
            "TOOK:  3.299572229385376\n",
            "TOOK:  3.534346342086792\n",
            "TOOK:  11.267626285552979\n",
            "TOOK:  6.142513990402222\n",
            "TOOK:  8.888108730316162\n",
            "TOOK:  3.2885608673095703\n",
            "TOOK:  4.276876449584961\n",
            "TOOK:  4.944715261459351\n",
            "TOOK:  3.1029629707336426\n",
            "TOOK:  3.0143697261810303\n",
            "TOOK:  3.3999319076538086\n",
            "TOOK:  5.298643112182617\n",
            "TOOK:  2.9858031272888184\n",
            "TOOK:  4.1256325244903564\n",
            "TOOK:  4.811023473739624\n",
            "TOOK:  4.458780527114868\n",
            "TOOK:  3.4363739490509033\n",
            "TOOK:  2.9988551139831543\n",
            "TOOK:  3.270733594894409\n",
            "TOOK:  5.2294981479644775\n",
            "TOOK:  3.5604443550109863\n",
            "TOOK:  3.284266471862793\n",
            "TOOK:  3.783508539199829\n",
            "TOOK:  5.1388514041900635\n",
            "TOOK:  3.1936604976654053\n",
            "TOOK:  5.046188116073608\n",
            "TOOK:  5.462808847427368\n",
            "TOOK:  3.837165355682373\n",
            "TOOK:  3.099862575531006\n",
            "TOOK:  3.199223756790161\n",
            "TOOK:  5.328230142593384\n",
            "TOOK:  4.181774854660034\n",
            "TOOK:  3.4408488273620605\n",
            "TOOK:  3.2838134765625\n",
            "TOOK:  9.000335693359375\n",
            "TOOK:  3.5757241249084473\n",
            "TOOK:  3.331576108932495\n",
            "TOOK:  5.532344102859497\n",
            "TOOK:  3.6147029399871826\n",
            "TOOK:  3.5416007041931152\n",
            "TOOK:  3.4838340282440186\n",
            "TOOK:  8.949581623077393\n",
            "TOOK:  3.9203996658325195\n",
            "TOOK:  4.056955099105835\n",
            "TOOK:  4.916058540344238\n",
            "TOOK:  3.358407497406006\n",
            "TOOK:  3.9094960689544678\n",
            "TOOK:  4.816054582595825\n",
            "TOOK:  4.427603721618652\n",
            "TOOK:  3.0735065937042236\n",
            "TOOK:  3.278839588165283\n",
            "TOOK:  4.694956064224243\n",
            "TOOK:  4.637914657592773\n",
            "TOOK:  3.4208884239196777\n",
            "TOOK:  3.478935718536377\n",
            "TOOK:  9.968728065490723\n",
            "TOOK:  3.455479145050049\n",
            "TOOK:  3.0907318592071533\n",
            "TOOK:  5.12090802192688\n",
            "TOOK:  4.331188917160034\n",
            "TOOK:  3.1541595458984375\n",
            "TOOK:  3.432863712310791\n",
            "TOOK:  9.705795049667358\n",
            "TOOK:  3.2575411796569824\n",
            "TOOK:  4.5693113803863525\n",
            "TOOK:  5.7802698612213135\n",
            "TOOK:  3.518254280090332\n",
            "TOOK:  3.3327550888061523\n",
            "TOOK:  3.780226230621338\n",
            "TOOK:  5.187985420227051\n",
            "TOOK:  3.135713577270508\n",
            "TOOK:  3.685093641281128\n",
            "TOOK:  3.1648645401000977\n",
            "TOOK:  5.206743001937866\n",
            "TOOK:  3.601663112640381\n",
            "TOOK:  3.739976644515991\n",
            "TOOK:  3.1579389572143555\n",
            "TOOK:  9.435513734817505\n",
            "TOOK:  3.6057674884796143\n",
            "TOOK:  3.535526990890503\n",
            "TOOK:  5.097689390182495\n",
            "TOOK:  3.528951644897461\n",
            "TOOK:  3.3855128288269043\n",
            "TOOK:  3.0289766788482666\n",
            "TOOK:  9.652196407318115\n",
            "TOOK:  3.3033218383789062\n",
            "TOOK:  3.5165445804595947\n",
            "TOOK:  5.313411712646484\n",
            "TOOK:  3.6001029014587402\n",
            "TOOK:  3.15889573097229\n",
            "{\n",
            "  \"humaneval-x-bugs-java\": {\n",
            "    \"pass@1\": 0.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-java\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check buggy solutions are indeed all wrong ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-java \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqODYde00yRG"
      },
      "source": [
        "##### CPP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5rN2po-NpuF",
        "outputId": "ea40ee65-b8eb-41a0-b848-b5875a98edc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 18:24:36.921352: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-02 18:24:38.360787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-cpp']\n",
            "Loading the model and tokenizer\n",
            "100% 1/1 [00:00<00:00, 398.81it/s]\n",
            "100% 1/1 [00:00<00:00, 451.44it/s]\n",
            "defaultdict(<class 'list'>, {3: [(0, {'task_id': 3, 'passed': True, 'result': 'passed', 'completion_id': 0})], 2: [(0, {'task_id': 2, 'passed': True, 'result': 'passed', 'completion_id': 0})], 0: [(0, {'task_id': 0, 'passed': True, 'result': 'passed', 'completion_id': 0})], 1: [(0, {'task_id': 1, 'passed': True, 'result': 'passed', 'completion_id': 0})], 4: [(0, {'task_id': 4, 'passed': True, 'result': 'passed', 'completion_id': 0})], 6: [(0, {'task_id': 6, 'passed': True, 'result': 'passed', 'completion_id': 0})], 5: [(0, {'task_id': 5, 'passed': True, 'result': 'passed', 'completion_id': 0})], 7: [(0, {'task_id': 7, 'passed': True, 'result': 'passed', 'completion_id': 0})], 9: [(0, {'task_id': 9, 'passed': True, 'result': 'passed', 'completion_id': 0})], 8: [(0, {'task_id': 8, 'passed': True, 'result': 'passed', 'completion_id': 0})], 11: [(0, {'task_id': 11, 'passed': True, 'result': 'passed', 'completion_id': 0})], 10: [(0, {'task_id': 10, 'passed': True, 'result': 'passed', 'completion_id': 0})], 13: [(0, {'task_id': 13, 'passed': True, 'result': 'passed', 'completion_id': 0})], 15: [(0, {'task_id': 15, 'passed': True, 'result': 'passed', 'completion_id': 0})], 12: [(0, {'task_id': 12, 'passed': True, 'result': 'passed', 'completion_id': 0})], 14: [(0, {'task_id': 14, 'passed': True, 'result': 'passed', 'completion_id': 0})], 16: [(0, {'task_id': 16, 'passed': True, 'result': 'passed', 'completion_id': 0})], 17: [(0, {'task_id': 17, 'passed': True, 'result': 'passed', 'completion_id': 0})], 18: [(0, {'task_id': 18, 'passed': True, 'result': 'passed', 'completion_id': 0})], 19: [(0, {'task_id': 19, 'passed': True, 'result': 'passed', 'completion_id': 0})], 21: [(0, {'task_id': 21, 'passed': True, 'result': 'passed', 'completion_id': 0})], 20: [(0, {'task_id': 20, 'passed': True, 'result': 'passed', 'completion_id': 0})], 23: [(0, {'task_id': 23, 'passed': True, 'result': 'passed', 'completion_id': 0})], 24: [(0, {'task_id': 24, 'passed': True, 'result': 'passed', 'completion_id': 0})], 22: [(0, {'task_id': 22, 'passed': True, 'result': 'passed', 'completion_id': 0})], 25: [(0, {'task_id': 25, 'passed': True, 'result': 'passed', 'completion_id': 0})], 27: [(0, {'task_id': 27, 'passed': True, 'result': 'passed', 'completion_id': 0})], 26: [(0, {'task_id': 26, 'passed': True, 'result': 'passed', 'completion_id': 0})], 28: [(0, {'task_id': 28, 'passed': True, 'result': 'passed', 'completion_id': 0})], 29: [(0, {'task_id': 29, 'passed': True, 'result': 'passed', 'completion_id': 0})], 31: [(0, {'task_id': 31, 'passed': True, 'result': 'passed', 'completion_id': 0})], 30: [(0, {'task_id': 30, 'passed': True, 'result': 'passed', 'completion_id': 0})], 32: [(0, {'task_id': 32, 'passed': True, 'result': 'passed', 'completion_id': 0})], 33: [(0, {'task_id': 33, 'passed': True, 'result': 'passed', 'completion_id': 0})], 34: [(0, {'task_id': 34, 'passed': True, 'result': 'passed', 'completion_id': 0})], 35: [(0, {'task_id': 35, 'passed': True, 'result': 'passed', 'completion_id': 0})], 36: [(0, {'task_id': 36, 'passed': True, 'result': 'passed', 'completion_id': 0})], 37: [(0, {'task_id': 37, 'passed': True, 'result': 'passed', 'completion_id': 0})], 38: [(0, {'task_id': 38, 'passed': True, 'result': 'passed', 'completion_id': 0})], 39: [(0, {'task_id': 39, 'passed': True, 'result': 'passed', 'completion_id': 0})], 40: [(0, {'task_id': 40, 'passed': True, 'result': 'passed', 'completion_id': 0})], 41: [(0, {'task_id': 41, 'passed': True, 'result': 'passed', 'completion_id': 0})], 42: [(0, {'task_id': 42, 'passed': True, 'result': 'passed', 'completion_id': 0})], 44: [(0, {'task_id': 44, 'passed': True, 'result': 'passed', 'completion_id': 0})], 43: [(0, {'task_id': 43, 'passed': True, 'result': 'passed', 'completion_id': 0})], 45: [(0, {'task_id': 45, 'passed': True, 'result': 'passed', 'completion_id': 0})], 46: [(0, {'task_id': 46, 'passed': True, 'result': 'passed', 'completion_id': 0})], 48: [(0, {'task_id': 48, 'passed': True, 'result': 'passed', 'completion_id': 0})], 47: [(0, {'task_id': 47, 'passed': True, 'result': 'passed', 'completion_id': 0})], 49: [(0, {'task_id': 49, 'passed': True, 'result': 'passed', 'completion_id': 0})], 50: [(0, {'task_id': 50, 'passed': True, 'result': 'passed', 'completion_id': 0})], 51: [(0, {'task_id': 51, 'passed': True, 'result': 'passed', 'completion_id': 0})], 52: [(0, {'task_id': 52, 'passed': True, 'result': 'passed', 'completion_id': 0})], 53: [(0, {'task_id': 53, 'passed': True, 'result': 'passed', 'completion_id': 0})], 54: [(0, {'task_id': 54, 'passed': True, 'result': 'passed', 'completion_id': 0})], 55: [(0, {'task_id': 55, 'passed': True, 'result': 'passed', 'completion_id': 0})], 56: [(0, {'task_id': 56, 'passed': True, 'result': 'passed', 'completion_id': 0})], 57: [(0, {'task_id': 57, 'passed': True, 'result': 'passed', 'completion_id': 0})], 59: [(0, {'task_id': 59, 'passed': True, 'result': 'passed', 'completion_id': 0})], 58: [(0, {'task_id': 58, 'passed': True, 'result': 'passed', 'completion_id': 0})], 61: [(0, {'task_id': 61, 'passed': True, 'result': 'passed', 'completion_id': 0})], 60: [(0, {'task_id': 60, 'passed': True, 'result': 'passed', 'completion_id': 0})], 63: [(0, {'task_id': 63, 'passed': True, 'result': 'passed', 'completion_id': 0})], 62: [(0, {'task_id': 62, 'passed': True, 'result': 'passed', 'completion_id': 0})], 65: [(0, {'task_id': 65, 'passed': True, 'result': 'passed', 'completion_id': 0})], 64: [(0, {'task_id': 64, 'passed': True, 'result': 'passed', 'completion_id': 0})], 66: [(0, {'task_id': 66, 'passed': True, 'result': 'passed', 'completion_id': 0})], 67: [(0, {'task_id': 67, 'passed': True, 'result': 'passed', 'completion_id': 0})], 68: [(0, {'task_id': 68, 'passed': True, 'result': 'passed', 'completion_id': 0})], 69: [(0, {'task_id': 69, 'passed': True, 'result': 'passed', 'completion_id': 0})], 71: [(0, {'task_id': 71, 'passed': True, 'result': 'passed', 'completion_id': 0})], 70: [(0, {'task_id': 70, 'passed': True, 'result': 'passed', 'completion_id': 0})], 75: [(0, {'task_id': 75, 'passed': True, 'result': 'passed', 'completion_id': 0})], 73: [(0, {'task_id': 73, 'passed': True, 'result': 'passed', 'completion_id': 0})], 74: [(0, {'task_id': 74, 'passed': True, 'result': 'passed', 'completion_id': 0})], 72: [(0, {'task_id': 72, 'passed': True, 'result': 'passed', 'completion_id': 0})], 76: [(0, {'task_id': 76, 'passed': True, 'result': 'passed', 'completion_id': 0})], 79: [(0, {'task_id': 79, 'passed': True, 'result': 'passed', 'completion_id': 0})], 77: [(0, {'task_id': 77, 'passed': True, 'result': 'passed', 'completion_id': 0})], 78: [(0, {'task_id': 78, 'passed': True, 'result': 'passed', 'completion_id': 0})], 80: [(0, {'task_id': 80, 'passed': True, 'result': 'passed', 'completion_id': 0})], 82: [(0, {'task_id': 82, 'passed': True, 'result': 'passed', 'completion_id': 0})], 83: [(0, {'task_id': 83, 'passed': True, 'result': 'passed', 'completion_id': 0})], 81: [(0, {'task_id': 81, 'passed': True, 'result': 'passed', 'completion_id': 0})], 84: [(0, {'task_id': 84, 'passed': True, 'result': 'passed', 'completion_id': 0})], 85: [(0, {'task_id': 85, 'passed': True, 'result': 'passed', 'completion_id': 0})], 86: [(0, {'task_id': 86, 'passed': True, 'result': 'passed', 'completion_id': 0})], 87: [(0, {'task_id': 87, 'passed': True, 'result': 'passed', 'completion_id': 0})], 89: [(0, {'task_id': 89, 'passed': True, 'result': 'passed', 'completion_id': 0})], 88: [(0, {'task_id': 88, 'passed': True, 'result': 'passed', 'completion_id': 0})], 90: [(0, {'task_id': 90, 'passed': True, 'result': 'passed', 'completion_id': 0})], 91: [(0, {'task_id': 91, 'passed': True, 'result': 'passed', 'completion_id': 0})], 93: [(0, {'task_id': 93, 'passed': True, 'result': 'passed', 'completion_id': 0})], 92: [(0, {'task_id': 92, 'passed': True, 'result': 'passed', 'completion_id': 0})], 94: [(0, {'task_id': 94, 'passed': True, 'result': 'passed', 'completion_id': 0})], 95: [(0, {'task_id': 95, 'passed': True, 'result': 'passed', 'completion_id': 0})], 97: [(0, {'task_id': 97, 'passed': True, 'result': 'passed', 'completion_id': 0})], 96: [(0, {'task_id': 96, 'passed': True, 'result': 'passed', 'completion_id': 0})], 98: [(0, {'task_id': 98, 'passed': True, 'result': 'passed', 'completion_id': 0})], 99: [(0, {'task_id': 99, 'passed': True, 'result': 'passed', 'completion_id': 0})], 100: [(0, {'task_id': 100, 'passed': True, 'result': 'passed', 'completion_id': 0})], 101: [(0, {'task_id': 101, 'passed': True, 'result': 'passed', 'completion_id': 0})], 103: [(0, {'task_id': 103, 'passed': True, 'result': 'passed', 'completion_id': 0})], 102: [(0, {'task_id': 102, 'passed': True, 'result': 'passed', 'completion_id': 0})], 104: [(0, {'task_id': 104, 'passed': True, 'result': 'passed', 'completion_id': 0})], 107: [(0, {'task_id': 107, 'passed': True, 'result': 'passed', 'completion_id': 0})], 106: [(0, {'task_id': 106, 'passed': True, 'result': 'passed', 'completion_id': 0})], 105: [(0, {'task_id': 105, 'passed': True, 'result': 'passed', 'completion_id': 0})], 109: [(0, {'task_id': 109, 'passed': True, 'result': 'passed', 'completion_id': 0})], 108: [(0, {'task_id': 108, 'passed': True, 'result': 'passed', 'completion_id': 0})], 110: [(0, {'task_id': 110, 'passed': True, 'result': 'passed', 'completion_id': 0})], 111: [(0, {'task_id': 111, 'passed': True, 'result': 'passed', 'completion_id': 0})], 114: [(0, {'task_id': 114, 'passed': True, 'result': 'passed', 'completion_id': 0})], 112: [(0, {'task_id': 112, 'passed': True, 'result': 'passed', 'completion_id': 0})], 113: [(0, {'task_id': 113, 'passed': True, 'result': 'passed', 'completion_id': 0})], 115: [(0, {'task_id': 115, 'passed': True, 'result': 'passed', 'completion_id': 0})], 116: [(0, {'task_id': 116, 'passed': True, 'result': 'passed', 'completion_id': 0})], 118: [(0, {'task_id': 118, 'passed': True, 'result': 'passed', 'completion_id': 0})], 117: [(0, {'task_id': 117, 'passed': True, 'result': 'passed', 'completion_id': 0})], 119: [(0, {'task_id': 119, 'passed': True, 'result': 'passed', 'completion_id': 0})], 121: [(0, {'task_id': 121, 'passed': True, 'result': 'passed', 'completion_id': 0})], 120: [(0, {'task_id': 120, 'passed': True, 'result': 'passed', 'completion_id': 0})], 122: [(0, {'task_id': 122, 'passed': True, 'result': 'passed', 'completion_id': 0})], 123: [(0, {'task_id': 123, 'passed': True, 'result': 'passed', 'completion_id': 0})], 124: [(0, {'task_id': 124, 'passed': True, 'result': 'passed', 'completion_id': 0})], 125: [(0, {'task_id': 125, 'passed': True, 'result': 'passed', 'completion_id': 0})], 126: [(0, {'task_id': 126, 'passed': True, 'result': 'passed', 'completion_id': 0})], 127: [(0, {'task_id': 127, 'passed': True, 'result': 'passed', 'completion_id': 0})], 128: [(0, {'task_id': 128, 'passed': True, 'result': 'passed', 'completion_id': 0})], 131: [(0, {'task_id': 131, 'passed': True, 'result': 'passed', 'completion_id': 0})], 130: [(0, {'task_id': 130, 'passed': True, 'result': 'passed', 'completion_id': 0})], 129: [(0, {'task_id': 129, 'passed': True, 'result': 'passed', 'completion_id': 0})], 132: [(0, {'task_id': 132, 'passed': True, 'result': 'passed', 'completion_id': 0})], 134: [(0, {'task_id': 134, 'passed': True, 'result': 'passed', 'completion_id': 0})], 135: [(0, {'task_id': 135, 'passed': True, 'result': 'passed', 'completion_id': 0})], 133: [(0, {'task_id': 133, 'passed': True, 'result': 'passed', 'completion_id': 0})], 136: [(0, {'task_id': 136, 'passed': True, 'result': 'passed', 'completion_id': 0})], 138: [(0, {'task_id': 138, 'passed': True, 'result': 'passed', 'completion_id': 0})], 139: [(0, {'task_id': 139, 'passed': True, 'result': 'passed', 'completion_id': 0})], 137: [(0, {'task_id': 137, 'passed': True, 'result': 'passed', 'completion_id': 0})], 140: [(0, {'task_id': 140, 'passed': True, 'result': 'passed', 'completion_id': 0})], 141: [(0, {'task_id': 141, 'passed': True, 'result': 'passed', 'completion_id': 0})], 143: [(0, {'task_id': 143, 'passed': True, 'result': 'passed', 'completion_id': 0})], 142: [(0, {'task_id': 142, 'passed': True, 'result': 'passed', 'completion_id': 0})], 144: [(0, {'task_id': 144, 'passed': True, 'result': 'passed', 'completion_id': 0})], 145: [(0, {'task_id': 145, 'passed': True, 'result': 'passed', 'completion_id': 0})], 147: [(0, {'task_id': 147, 'passed': True, 'result': 'passed', 'completion_id': 0})], 146: [(0, {'task_id': 146, 'passed': True, 'result': 'passed', 'completion_id': 0})], 148: [(0, {'task_id': 148, 'passed': True, 'result': 'passed', 'completion_id': 0})], 149: [(0, {'task_id': 149, 'passed': True, 'result': 'passed', 'completion_id': 0})], 150: [(0, {'task_id': 150, 'passed': True, 'result': 'passed', 'completion_id': 0})], 151: [(0, {'task_id': 151, 'passed': True, 'result': 'passed', 'completion_id': 0})], 152: [(0, {'task_id': 152, 'passed': True, 'result': 'passed', 'completion_id': 0})], 153: [(0, {'task_id': 153, 'passed': True, 'result': 'passed', 'completion_id': 0})], 154: [(0, {'task_id': 154, 'passed': True, 'result': 'passed', 'completion_id': 0})], 156: [(0, {'task_id': 156, 'passed': True, 'result': 'passed', 'completion_id': 0})], 155: [(0, {'task_id': 155, 'passed': True, 'result': 'passed', 'completion_id': 0})], 158: [(0, {'task_id': 158, 'passed': True, 'result': 'passed', 'completion_id': 0})], 157: [(0, {'task_id': 157, 'passed': True, 'result': 'passed', 'completion_id': 0})], 160: [(0, {'task_id': 160, 'passed': True, 'result': 'passed', 'completion_id': 0})], 159: [(0, {'task_id': 159, 'passed': True, 'result': 'passed', 'completion_id': 0})], 162: [(0, {'task_id': 162, 'passed': True, 'result': 'passed', 'completion_id': 0})], 161: [(0, {'task_id': 161, 'passed': True, 'result': 'passed', 'completion_id': 0})], 163: [(0, {'task_id': 163, 'passed': True, 'result': 'passed', 'completion_id': 0})]})\n",
            "{\n",
            "  \"humaneval-x-bugs-cpp\": {\n",
            "    \"pass@1\": 1.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-cpp\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check canonical solutions are indeed all right ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-cpp \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSVPAEZ2Kc0O",
        "outputId": "b96e62b4-fd98-4b5f-81b6-4e952c13a824"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 11:39:07.741372: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-cpp']\n",
            "Loading the model and tokenizer\n",
            "Downloading and preparing dataset humaneval-x-bugs/cpp to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/cpp/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8...\n",
            "Downloading data: 100% 367k/367k [00:00<00:00, 4.00MB/s]\n",
            "Dataset humaneval-x-bugs downloaded and prepared to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/cpp/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 561.94it/s]\n",
            "100% 1/1 [00:00<00:00, 515.02it/s]\n",
            "TOOK:  1.2492249011993408\n",
            "TOOK:  0.7278468608856201\n",
            "TOOK:  0.6049046516418457\n",
            "TOOK:  0.6499772071838379\n",
            "TOOK:  0.7189040184020996\n",
            "TOOK:  0.6905577182769775\n",
            "TOOK:  0.695950984954834\n",
            "TOOK:  0.6989562511444092\n",
            "TOOK:  0.649904727935791\n",
            "TOOK:  0.7254178524017334\n",
            "TOOK:  0.9539501667022705\n",
            "TOOK:  0.8593292236328125\n",
            "TOOK:  0.9744791984558105\n",
            "TOOK:  0.8819844722747803\n",
            "TOOK:  0.7683217525482178\n",
            "TOOK:  0.5945954322814941\n",
            "TOOK:  0.7155961990356445\n",
            "TOOK:  0.6980757713317871\n",
            "TOOK:  0.5933651924133301\n",
            "TOOK:  0.912184476852417\n",
            "TOOK:  0.7190220355987549\n",
            "TOOK:  0.6873581409454346\n",
            "TOOK:  1.0265002250671387\n",
            "TOOK:  0.5868136882781982\n",
            "TOOK:  0.590118408203125\n",
            "TOOK:  0.7175450325012207\n",
            "TOOK:  0.745659589767456\n",
            "TOOK:  0.6028199195861816\n",
            "TOOK:  0.8565449714660645\n",
            "TOOK:  1.035722255706787\n",
            "TOOK:  1.1708095073699951\n",
            "TOOK:  0.9112527370452881\n",
            "TOOK:  0.9259452819824219\n",
            "TOOK:  0.7644751071929932\n",
            "TOOK:  0.8052675724029541\n",
            "TOOK:  0.7279536724090576\n",
            "TOOK:  0.5885603427886963\n",
            "TOOK:  0.8438405990600586\n",
            "TOOK:  0.6189689636230469\n",
            "TOOK:  0.57798171043396\n",
            "TOOK:  0.6604671478271484\n",
            "TOOK:  0.5904667377471924\n",
            "TOOK:  0.6655266284942627\n",
            "TOOK:  0.7111761569976807\n",
            "TOOK:  0.6476774215698242\n",
            "TOOK:  0.611609697341919\n",
            "TOOK:  0.6013941764831543\n",
            "TOOK:  1.0577147006988525\n",
            "TOOK:  0.9072413444519043\n",
            "TOOK:  0.8589572906494141\n",
            "TOOK:  0.8788635730743408\n",
            "TOOK:  0.8356761932373047\n",
            "TOOK:  0.6615512371063232\n",
            "TOOK:  0.5842161178588867\n",
            "TOOK:  0.650306224822998\n",
            "TOOK:  0.6220996379852295\n",
            "TOOK:  0.6045594215393066\n",
            "TOOK:  0.7201926708221436\n",
            "TOOK:  0.8181331157684326\n",
            "TOOK:  0.6004517078399658\n",
            "TOOK:  0.5996301174163818\n",
            "TOOK:  0.6000211238861084\n",
            "TOOK:  0.7373952865600586\n",
            "TOOK:  0.6033291816711426\n",
            "TOOK:  0.632530689239502\n",
            "TOOK:  0.6164846420288086\n",
            "TOOK:  0.8719515800476074\n",
            "TOOK:  1.0618417263031006\n",
            "TOOK:  1.035451889038086\n",
            "TOOK:  1.1644606590270996\n",
            "TOOK:  1.4669413566589355\n",
            "TOOK:  0.8536224365234375\n",
            "TOOK:  0.7987725734710693\n",
            "TOOK:  0.7411463260650635\n",
            "TOOK:  0.6987183094024658\n",
            "TOOK:  0.5934159755706787\n",
            "TOOK:  0.6087093353271484\n",
            "TOOK:  0.630511999130249\n",
            "TOOK:  0.6357021331787109\n",
            "TOOK:  0.5889828205108643\n",
            "TOOK:  0.5976171493530273\n",
            "TOOK:  0.7728900909423828\n",
            "TOOK:  0.591083288192749\n",
            "TOOK:  0.580981969833374\n",
            "TOOK:  0.6177215576171875\n",
            "TOOK:  0.8314101696014404\n",
            "TOOK:  1.0277798175811768\n",
            "TOOK:  1.1613075733184814\n",
            "TOOK:  1.1804962158203125\n",
            "TOOK:  0.6412563323974609\n",
            "TOOK:  0.7402710914611816\n",
            "TOOK:  0.573967456817627\n",
            "TOOK:  0.6049413681030273\n",
            "TOOK:  0.6042079925537109\n",
            "TOOK:  0.6588218212127686\n",
            "TOOK:  0.7435746192932129\n",
            "TOOK:  0.6570255756378174\n",
            "TOOK:  0.6015458106994629\n",
            "TOOK:  0.6237306594848633\n",
            "TOOK:  0.6009519100189209\n",
            "TOOK:  0.7017128467559814\n",
            "TOOK:  0.7076876163482666\n",
            "TOOK:  0.5763888359069824\n",
            "TOOK:  0.6362009048461914\n",
            "TOOK:  0.9137790203094482\n",
            "TOOK:  1.5719375610351562\n",
            "TOOK:  1.041959285736084\n",
            "TOOK:  1.0749354362487793\n",
            "TOOK:  0.6838293075561523\n",
            "TOOK:  0.6506023406982422\n",
            "TOOK:  0.6709020137786865\n",
            "TOOK:  0.7762157917022705\n",
            "TOOK:  0.7461626529693604\n",
            "TOOK:  0.7589704990386963\n",
            "TOOK:  0.6482200622558594\n",
            "TOOK:  0.7060151100158691\n",
            "TOOK:  0.744927167892456\n",
            "TOOK:  0.7579782009124756\n",
            "TOOK:  0.6407473087310791\n",
            "TOOK:  0.6701722145080566\n",
            "TOOK:  0.7439959049224854\n",
            "TOOK:  0.6369256973266602\n",
            "TOOK:  0.8691763877868652\n",
            "TOOK:  1.1727015972137451\n",
            "TOOK:  0.9137461185455322\n",
            "TOOK:  1.2094621658325195\n",
            "TOOK:  0.6748900413513184\n",
            "TOOK:  1.2939221858978271\n",
            "TOOK:  1.2250208854675293\n",
            "TOOK:  1.2260746955871582\n",
            "TOOK:  1.199601650238037\n",
            "TOOK:  0.9912114143371582\n",
            "TOOK:  0.9387767314910889\n",
            "TOOK:  1.6139922142028809\n",
            "TOOK:  1.3959343433380127\n",
            "TOOK:  1.2472894191741943\n",
            "TOOK:  1.0353477001190186\n",
            "TOOK:  1.2260026931762695\n",
            "TOOK:  0.8684697151184082\n",
            "TOOK:  0.6053073406219482\n",
            "TOOK:  0.6015236377716064\n",
            "TOOK:  0.6173956394195557\n",
            "TOOK:  0.6714646816253662\n",
            "TOOK:  0.6180942058563232\n",
            "TOOK:  0.6051485538482666\n",
            "TOOK:  0.7646291255950928\n",
            "TOOK:  0.6829526424407959\n",
            "TOOK:  0.8428432941436768\n",
            "TOOK:  0.7361950874328613\n",
            "TOOK:  0.8334059715270996\n",
            "TOOK:  0.5943236351013184\n",
            "TOOK:  0.7485671043395996\n",
            "TOOK:  0.7400829792022705\n",
            "TOOK:  0.8613977432250977\n",
            "TOOK:  0.8637020587921143\n",
            "TOOK:  1.0935649871826172\n",
            "TOOK:  1.0374760627746582\n",
            "TOOK:  0.8039908409118652\n",
            "TOOK:  0.714510440826416\n",
            "TOOK:  0.6604013442993164\n",
            "TOOK:  0.83201003074646\n",
            "TOOK:  0.6352279186248779\n",
            "TOOK:  0.6858453750610352\n",
            "TOOK:  0.6924748420715332\n",
            "{\n",
            "  \"humaneval-x-bugs-cpp\": {\n",
            "    \"pass@1\": 1.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-cpp\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check canonical solutions are indeed all right ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-cpp \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dYVhL41huDQ",
        "outputId": "238ca503-a6cf-4967-b878-6abace1820aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 08:36:23.344316: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-02 08:36:25.059578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-cpp']\n",
            "Loading the model and tokenizer\n",
            "Downloading and preparing dataset humaneval-x-bugs/cpp to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/cpp/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8...\n",
            "Downloading data: 100% 367k/367k [00:00<00:00, 25.2MB/s]\n",
            "Dataset humaneval-x-bugs downloaded and prepared to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/cpp/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 360.61it/s]\n",
            "100% 1/1 [00:00<00:00, 374.29it/s]\n",
            "TOOK:  1.359846591949463\n",
            "TOOK:  0.9973483085632324\n",
            "TOOK:  0.6071407794952393\n",
            "TOOK:  0.6095292568206787\n",
            "TOOK:  0.6467103958129883\n",
            "TOOK:  0.6463704109191895\n",
            "TOOK:  0.638695240020752\n",
            "TOOK:  0.6734187602996826\n",
            "TOOK:  0.6259458065032959\n",
            "TOOK:  0.6425607204437256\n",
            "TOOK:  0.5710175037384033\n",
            "TOOK:  0.541949987411499\n",
            "TOOK:  0.6211590766906738\n",
            "TOOK:  0.5605711936950684\n",
            "TOOK:  0.6601028442382812\n",
            "TOOK:  0.5533194541931152\n",
            "TOOK:  0.6779258251190186\n",
            "TOOK:  0.6579468250274658\n",
            "TOOK:  0.7265598773956299\n",
            "TOOK:  1.3975896835327148\n",
            "TOOK:  1.0131967067718506\n",
            "TOOK:  1.002901554107666\n",
            "TOOK:  11.105527400970459\n",
            "TOOK:  0.810936450958252\n",
            "TOOK:  0.8156025409698486\n",
            "TOOK:  1.0361568927764893\n",
            "TOOK:  0.8740394115447998\n",
            "TOOK:  0.5467057228088379\n",
            "TOOK:  0.6119351387023926\n",
            "TOOK:  0.6448919773101807\n",
            "TOOK:  0.6770639419555664\n",
            "TOOK:  0.5329382419586182\n",
            "TOOK:  0.69083571434021\n",
            "TOOK:  0.6881668567657471\n",
            "TOOK:  0.679821252822876\n",
            "TOOK:  0.6425750255584717\n",
            "TOOK:  0.5336248874664307\n",
            "TOOK:  0.7563018798828125\n",
            "TOOK:  0.572390079498291\n",
            "TOOK:  0.5290563106536865\n",
            "TOOK:  0.6379644870758057\n",
            "TOOK:  0.5483791828155518\n",
            "TOOK:  0.732799768447876\n",
            "TOOK:  0.9210295677185059\n",
            "TOOK:  0.8376510143280029\n",
            "TOOK:  0.8828129768371582\n",
            "TOOK:  0.8234272003173828\n",
            "TOOK:  0.7963852882385254\n",
            "TOOK:  0.5686185359954834\n",
            "TOOK:  0.5299727916717529\n",
            "TOOK:  0.5464212894439697\n",
            "TOOK:  0.5929429531097412\n",
            "TOOK:  0.5952410697937012\n",
            "TOOK:  0.5367553234100342\n",
            "TOOK:  0.5931289196014404\n",
            "TOOK:  0.5255842208862305\n",
            "TOOK:  0.5358555316925049\n",
            "TOOK:  0.6035506725311279\n",
            "TOOK:  0.7383060455322266\n",
            "TOOK:  0.5407633781433105\n",
            "TOOK:  0.5466992855072021\n",
            "TOOK:  0.8231942653656006\n",
            "TOOK:  1.0706493854522705\n",
            "TOOK:  0.9445011615753174\n",
            "TOOK:  1.047459363937378\n",
            "TOOK:  1.1915292739868164\n",
            "TOOK:  1.047563076019287\n",
            "TOOK:  0.8378188610076904\n",
            "TOOK:  0.8074617385864258\n",
            "TOOK:  0.6950037479400635\n",
            "TOOK:  0.7281134128570557\n",
            "TOOK:  0.5906496047973633\n",
            "TOOK:  0.6117596626281738\n",
            "TOOK:  0.5956637859344482\n",
            "TOOK:  0.6719439029693604\n",
            "TOOK:  0.5457277297973633\n",
            "TOOK:  6.539010286331177\n",
            "TOOK:  0.8800270557403564\n",
            "TOOK:  0.8904969692230225\n",
            "TOOK:  0.8437502384185791\n",
            "TOOK:  0.6082451343536377\n",
            "TOOK:  0.7216992378234863\n",
            "TOOK:  0.5374970436096191\n",
            "TOOK:  0.5434894561767578\n",
            "TOOK:  0.5473029613494873\n",
            "TOOK:  0.6121997833251953\n",
            "TOOK:  0.628042459487915\n",
            "TOOK:  0.742016077041626\n",
            "TOOK:  0.7353360652923584\n",
            "TOOK:  0.5350658893585205\n",
            "TOOK:  0.7048308849334717\n",
            "TOOK:  0.5346114635467529\n",
            "TOOK:  0.5718164443969727\n",
            "TOOK:  0.5930347442626953\n",
            "TOOK:  0.6238703727722168\n",
            "TOOK:  0.742605447769165\n",
            "TOOK:  0.8899533748626709\n",
            "TOOK:  0.8506319522857666\n",
            "TOOK:  0.8832440376281738\n",
            "TOOK:  0.8758125305175781\n",
            "TOOK:  0.9003674983978271\n",
            "TOOK:  0.6775434017181396\n",
            "TOOK:  0.5290942192077637\n",
            "TOOK:  0.591538667678833\n",
            "TOOK:  0.7338294982910156\n",
            "TOOK:  0.9412643909454346\n",
            "TOOK:  0.6503798961639404\n",
            "TOOK:  0.6539764404296875\n",
            "TOOK:  0.6734879016876221\n",
            "TOOK:  0.6236283779144287\n",
            "TOOK:  0.6104271411895752\n",
            "TOOK:  0.7504386901855469\n",
            "TOOK:  0.7154428958892822\n",
            "TOOK:  0.754387617111206\n",
            "TOOK:  0.6100118160247803\n",
            "TOOK:  0.8139333724975586\n",
            "TOOK:  1.1131665706634521\n",
            "TOOK:  1.105931043624878\n",
            "TOOK:  0.9564063549041748\n",
            "TOOK:  0.8255946636199951\n",
            "TOOK:  0.7415969371795654\n",
            "TOOK:  0.6065256595611572\n",
            "TOOK:  0.6084823608398438\n",
            "TOOK:  10.758119344711304\n",
            "TOOK:  0.8521213531494141\n",
            "TOOK:  0.9394166469573975\n",
            "TOOK:  0.6566977500915527\n",
            "TOOK:  0.614600419998169\n",
            "TOOK:  0.6535165309906006\n",
            "TOOK:  0.7640380859375\n",
            "TOOK:  0.6442904472351074\n",
            "TOOK:  0.5541527271270752\n",
            "TOOK:  0.5346643924713135\n",
            "TOOK:  0.6687955856323242\n",
            "TOOK:  0.5633888244628906\n",
            "TOOK:  0.6075160503387451\n",
            "TOOK:  0.6489009857177734\n",
            "TOOK:  10.757283926010132\n",
            "TOOK:  0.5345594882965088\n",
            "TOOK:  0.53639817237854\n",
            "TOOK:  0.5529956817626953\n",
            "TOOK:  0.5604488849639893\n",
            "TOOK:  0.6086149215698242\n",
            "TOOK:  0.5490460395812988\n",
            "TOOK:  0.5610744953155518\n",
            "TOOK:  0.6964151859283447\n",
            "TOOK:  0.6136102676391602\n",
            "TOOK:  0.8124749660491943\n",
            "TOOK:  0.7339122295379639\n",
            "TOOK:  1.1091742515563965\n",
            "TOOK:  0.8225750923156738\n",
            "TOOK:  1.0707035064697266\n",
            "TOOK:  1.0127830505371094\n",
            "TOOK:  0.6269557476043701\n",
            "TOOK:  0.543086051940918\n",
            "TOOK:  0.6520283222198486\n",
            "TOOK:  10.670530319213867\n",
            "TOOK:  0.8836684226989746\n",
            "TOOK:  0.9921650886535645\n",
            "TOOK:  0.614039421081543\n",
            "TOOK:  0.7812333106994629\n",
            "TOOK:  0.5588548183441162\n",
            "TOOK:  0.6084184646606445\n",
            "TOOK:  0.6457221508026123\n",
            "{\n",
            "  \"humaneval-x-bugs-cpp\": {\n",
            "    \"pass@1\": 0.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-cpp\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check buggy solutions are indeed all wrong ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-cpp \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyVrh2fR00oK"
      },
      "source": [
        "##### Go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlwEzi5J07V3",
        "outputId": "98f8cece-943a-402c-8008-e164d0bedaf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    75  100    75    0     0   1013      0 --:--:-- --:--:-- --:--:--  1000\n",
            "100  135M  100  135M    0     0  40.1M      0  0:00:03  0:00:03 --:--:-- 44.1M\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /workspace/download\n",
        "!curl -o /workspace/download/go.tar.gz -SL https://go.dev/dl/go1.18.4.linux-amd64.tar.gz \\\n",
        "    && tar -zxf /workspace/download/go.tar.gz -C /usr/local && rm /workspace/download/go.tar.gz\n",
        "\n",
        "import os\n",
        "os.environ['PATH'] = '/bin:/usr/local/go/bin:' + os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM7S21mX1qEH",
        "outputId": "685c6ca4-af70-41fd-dd59-50d7e450f3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing go.mod\n"
          ]
        }
      ],
      "source": [
        "%%writefile go.mod\n",
        "module humanEval\n",
        "\n",
        "go 1.18\n",
        "\n",
        "require (\n",
        "\tgithub.com/go-openapi/inflect v0.19.0\n",
        "\tgithub.com/stretchr/testify v1.8.0\n",
        ")\n",
        "\n",
        "require (\n",
        "\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n",
        "\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n",
        "\tgopkg.in/yaml.v3 v3.0.1 // indirect\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiZ-GPeG5Yw6",
        "outputId": "11be93df-626d-44b7-fef9-3db9b226dfc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-02 12:23:59--  https://github.com/THUDM/CodeGeeX/raw/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/THUDM/CodeGeeX/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz [following]\n",
            "--2023-04-02 12:23:59--  https://raw.githubusercontent.com/THUDM/CodeGeeX/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118261 (115K) [application/octet-stream]\n",
            "Saving to: ‘vendor.tar.gz’\n",
            "\n",
            "vendor.tar.gz       100%[===================>] 115.49K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-04-02 12:23:59 (34.9 MB/s) - ‘vendor.tar.gz’ saved [118261/118261]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Not required, but makes it faster I think\n",
        "!wget https://github.com/THUDM/CodeGeeX/raw/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz\n",
        "!tar -zxf vendor.tar.gz -C ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWHR8Uqb3Rc7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOFLAGS'] = '-mod=mod'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1s8ZNSPMkIe",
        "outputId": "d905580b-4d1a-4a2d-a699-5b44213de281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "go: downloading github.com/stretchr/testify v1.8.2\n",
            "go: downloading github.com/davecgh/go-spew v1.1.1\n",
            "go: downloading github.com/pmezard/go-difflib v1.0.0\n",
            "go: downloading gopkg.in/yaml.v3 v3.0.1\n",
            "go: upgraded github.com/stretchr/testify v1.8.0 => v1.8.2\n"
          ]
        }
      ],
      "source": [
        "# Sometimes test No 98 or so fails with the below error\n",
        "# \"failed: go: finding module for package github.com/stretchr/testify/assert\"\n",
        "# In that case run the below & then rerun tests\n",
        "!go get github.com/stretchr/testify/assert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqGEt5aNpy9a",
        "outputId": "e598ab9e-3b24-4fca-f6ff-e965e30cd8b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 12:24:02.999109: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-02 12:24:04.083692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-go']\n",
            "Loading the model and tokenizer\n",
            "Downloading and preparing dataset humaneval-x-bugs/go to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/go/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8...\n",
            "Downloading data: 100% 440k/440k [00:00<00:00, 29.8MB/s]\n",
            "Dataset humaneval-x-bugs downloaded and prepared to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/go/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 427.73it/s]\n",
            "100% 1/1 [00:00<00:00, 430.89it/s]\n",
            "TOOK:  7.287292242050171\n",
            "TOOK:  0.6981399059295654\n",
            "TOOK:  0.678199291229248\n",
            "TOOK:  0.6762852668762207\n",
            "TOOK:  0.6740796566009521\n",
            "TOOK:  0.6933579444885254\n",
            "TOOK:  0.6878418922424316\n",
            "TOOK:  1.1377544403076172\n",
            "TOOK:  1.2000911235809326\n",
            "TOOK:  1.1535437107086182\n",
            "TOOK:  1.091362476348877\n",
            "TOOK:  0.6586098670959473\n",
            "TOOK:  0.6943583488464355\n",
            "TOOK:  0.6870560646057129\n",
            "TOOK:  0.6876609325408936\n",
            "TOOK:  0.6783702373504639\n",
            "TOOK:  0.7133378982543945\n",
            "TOOK:  0.6662087440490723\n",
            "TOOK:  0.6703474521636963\n",
            "TOOK:  0.6760363578796387\n",
            "TOOK:  0.7259354591369629\n",
            "TOOK:  0.7075798511505127\n",
            "TOOK:  0.7303526401519775\n",
            "TOOK:  0.7265076637268066\n",
            "TOOK:  0.7131085395812988\n",
            "TOOK:  1.0282557010650635\n",
            "TOOK:  1.1763312816619873\n",
            "TOOK:  1.1237189769744873\n",
            "TOOK:  1.1038315296173096\n",
            "TOOK:  0.6800811290740967\n",
            "TOOK:  0.6809473037719727\n",
            "TOOK:  0.6921203136444092\n",
            "TOOK:  0.7124278545379639\n",
            "TOOK:  0.6851770877838135\n",
            "TOOK:  0.6632969379425049\n",
            "TOOK:  0.6784379482269287\n",
            "TOOK:  0.7080032825469971\n",
            "TOOK:  0.6877200603485107\n",
            "TOOK:  0.7759382724761963\n",
            "TOOK:  0.7072391510009766\n",
            "TOOK:  0.6802139282226562\n",
            "TOOK:  0.7209289073944092\n",
            "TOOK:  0.7079217433929443\n",
            "TOOK:  1.0126681327819824\n",
            "TOOK:  1.144946813583374\n",
            "TOOK:  1.1833035945892334\n",
            "TOOK:  1.108565330505371\n",
            "TOOK:  0.6935043334960938\n",
            "TOOK:  0.6888589859008789\n",
            "TOOK:  0.6854069232940674\n",
            "TOOK:  0.9043369293212891\n",
            "TOOK:  0.688683271408081\n",
            "TOOK:  0.6652178764343262\n",
            "TOOK:  0.6912634372711182\n",
            "TOOK:  0.7297723293304443\n",
            "TOOK:  0.6866531372070312\n",
            "TOOK:  0.6773507595062256\n",
            "TOOK:  0.6907851696014404\n",
            "TOOK:  0.6964950561523438\n",
            "TOOK:  0.7105574607849121\n",
            "TOOK:  0.7021875381469727\n",
            "TOOK:  1.044203519821167\n",
            "TOOK:  1.1924126148223877\n",
            "TOOK:  1.132666826248169\n",
            "TOOK:  1.0579092502593994\n",
            "TOOK:  0.6619868278503418\n",
            "TOOK:  0.6588964462280273\n",
            "TOOK:  0.6733760833740234\n",
            "TOOK:  0.6803250312805176\n",
            "TOOK:  0.7165861129760742\n",
            "TOOK:  0.668018102645874\n",
            "TOOK:  0.6636757850646973\n",
            "TOOK:  0.6737885475158691\n",
            "TOOK:  0.6706914901733398\n",
            "TOOK:  0.6877686977386475\n",
            "TOOK:  0.6893458366394043\n",
            "TOOK:  0.6801192760467529\n",
            "TOOK:  0.6680588722229004\n",
            "TOOK:  0.6729209423065186\n",
            "TOOK:  0.7820782661437988\n",
            "TOOK:  1.235668659210205\n",
            "TOOK:  1.2662694454193115\n",
            "TOOK:  1.1381607055664062\n",
            "TOOK:  0.75221848487854\n",
            "TOOK:  0.6808395385742188\n",
            "TOOK:  0.8069789409637451\n",
            "TOOK:  0.7941100597381592\n",
            "TOOK:  0.6752285957336426\n",
            "TOOK:  0.6896371841430664\n",
            "TOOK:  0.6845476627349854\n",
            "TOOK:  0.6595711708068848\n",
            "TOOK:  0.6696059703826904\n",
            "TOOK:  0.692136287689209\n",
            "TOOK:  0.6603107452392578\n",
            "TOOK:  0.7057178020477295\n",
            "TOOK:  0.6701943874359131\n",
            "TOOK:  0.6618938446044922\n",
            "TOOK:  0.872323751449585\n",
            "TOOK:  1.189457654953003\n",
            "TOOK:  1.2337825298309326\n",
            "TOOK:  1.0985608100891113\n",
            "TOOK:  0.8293490409851074\n",
            "TOOK:  0.6953272819519043\n",
            "TOOK:  0.6787850856781006\n",
            "TOOK:  0.7181737422943115\n",
            "TOOK:  0.6766881942749023\n",
            "TOOK:  0.6933023929595947\n",
            "TOOK:  0.689509391784668\n",
            "TOOK:  0.6692066192626953\n",
            "TOOK:  0.6920318603515625\n",
            "TOOK:  0.6716837882995605\n",
            "TOOK:  0.7032291889190674\n",
            "TOOK:  0.6785025596618652\n",
            "TOOK:  0.6808338165283203\n",
            "TOOK:  0.6867260932922363\n",
            "TOOK:  0.7924354076385498\n",
            "TOOK:  1.1936440467834473\n",
            "TOOK:  1.2263104915618896\n",
            "TOOK:  1.1361396312713623\n",
            "TOOK:  0.8050334453582764\n",
            "TOOK:  0.670215368270874\n",
            "TOOK:  0.6765697002410889\n",
            "TOOK:  0.6621880531311035\n",
            "TOOK:  0.6684062480926514\n",
            "TOOK:  0.713524580001831\n",
            "TOOK:  0.7003469467163086\n",
            "TOOK:  0.7312314510345459\n",
            "TOOK:  0.8793168067932129\n",
            "TOOK:  0.6810050010681152\n",
            "TOOK:  0.6870057582855225\n",
            "TOOK:  0.6818337440490723\n",
            "TOOK:  0.6846826076507568\n",
            "TOOK:  0.7278523445129395\n",
            "TOOK:  0.9150509834289551\n",
            "TOOK:  1.291769027709961\n",
            "TOOK:  1.1401126384735107\n",
            "TOOK:  1.1304547786712646\n",
            "TOOK:  0.6771194934844971\n",
            "TOOK:  0.6725220680236816\n",
            "TOOK:  0.6818966865539551\n",
            "TOOK:  0.7017021179199219\n",
            "TOOK:  0.6682717800140381\n",
            "TOOK:  0.6954903602600098\n",
            "TOOK:  0.6994366645812988\n",
            "TOOK:  0.6754634380340576\n",
            "TOOK:  0.6821796894073486\n",
            "TOOK:  0.6834912300109863\n",
            "TOOK:  0.6586558818817139\n",
            "TOOK:  0.7021377086639404\n",
            "TOOK:  0.6994712352752686\n",
            "TOOK:  0.6669552326202393\n",
            "TOOK:  0.8371427059173584\n",
            "TOOK:  1.2440998554229736\n",
            "TOOK:  1.270503044128418\n",
            "TOOK:  1.0910768508911133\n",
            "TOOK:  0.7693545818328857\n",
            "TOOK:  0.6960997581481934\n",
            "TOOK:  0.6850199699401855\n",
            "TOOK:  0.6793725490570068\n",
            "TOOK:  0.6751589775085449\n",
            "TOOK:  0.6950020790100098\n",
            "TOOK:  0.6618990898132324\n",
            "TOOK:  0.6802122592926025\n",
            "TOOK:  0.7222785949707031\n",
            "{\n",
            "  \"humaneval-x-bugs-go\": {\n",
            "    \"pass@1\": 1.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-go\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check canonical solutions are indeed all right ###\n",
        "# No 95 fails sometimes for unknown reasons; Just rerun and it might pass\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-go \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOvq1YgKGXwa",
        "outputId": "4e718f67-a32f-437a-a761-e7c757aac27d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 11:03:34.461824: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-02 11:03:35.885326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-go']\n",
            "Loading the model and tokenizer\n",
            "Downloading: 100% 903/903 [00:00<00:00, 606kB/s]\n",
            "Downloading: 100% 457M/457M [00:07<00:00, 57.3MB/s]\n",
            "Downloading: 100% 259/259 [00:00<00:00, 163kB/s]\n",
            "Downloading: 100% 497k/497k [00:00<00:00, 4.18MB/s]\n",
            "Downloading: 100% 277k/277k [00:00<00:00, 3.39MB/s]\n",
            "Downloading: 100% 840k/840k [00:00<00:00, 8.84MB/s]\n",
            "Downloading: 100% 90.0/90.0 [00:00<00:00, 44.9kB/s]\n",
            "Downloading builder script: 100% 6.30k/6.30k [00:00<00:00, 3.47MB/s]\n",
            "Downloading readme: 100% 6.00/6.00 [00:00<00:00, 3.16kB/s]\n",
            "Downloading and preparing dataset humaneval-x-bugs/go to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/go/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8...\n",
            "Downloading data: 100% 440k/440k [00:00<00:00, 4.63MB/s]\n",
            "Dataset humaneval-x-bugs downloaded and prepared to /root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/go/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 449.07it/s]\n",
            "100% 1/1 [00:00<00:00, 475.76it/s]\n",
            "Downloading builder script: 100% 9.60k/9.60k [00:00<00:00, 4.68MB/s]\n",
            "Downloading extra modules: 100% 13.4k/13.4k [00:00<00:00, 5.19MB/s]\n",
            "TOOK:  10.077833414077759\n",
            "TOOK:  0.845294713973999\n",
            "TOOK:  0.8053786754608154\n",
            "TOOK:  0.8137369155883789\n",
            "TOOK:  0.8288459777832031\n",
            "TOOK:  0.8106508255004883\n",
            "TOOK:  0.8006112575531006\n",
            "TOOK:  0.8153088092803955\n",
            "TOOK:  0.8375370502471924\n",
            "TOOK:  0.486954927444458\n",
            "TOOK:  0.5517337322235107\n",
            "TOOK:  0.842442512512207\n",
            "TOOK:  0.8406448364257812\n",
            "TOOK:  1.1648168563842773\n",
            "TOOK:  1.4799022674560547\n",
            "TOOK:  1.3867528438568115\n",
            "TOOK:  1.083202600479126\n",
            "TOOK:  0.8360793590545654\n",
            "TOOK:  0.8083672523498535\n",
            "TOOK:  0.8245298862457275\n",
            "TOOK:  0.8264424800872803\n",
            "TOOK:  0.8281185626983643\n",
            "TOOK:  0.806149959564209\n",
            "TOOK:  0.8033919334411621\n",
            "TOOK:  0.7883551120758057\n",
            "TOOK:  0.8129901885986328\n",
            "TOOK:  0.8002095222473145\n",
            "TOOK:  0.8119931221008301\n",
            "TOOK:  0.9868531227111816\n",
            "TOOK:  1.4465434551239014\n",
            "TOOK:  1.4785175323486328\n",
            "TOOK:  1.1691927909851074\n",
            "TOOK:  0.8697929382324219\n",
            "TOOK:  0.86586594581604\n",
            "TOOK:  0.8438389301300049\n",
            "TOOK:  0.8870947360992432\n",
            "TOOK:  0.8272309303283691\n",
            "TOOK:  0.8287298679351807\n",
            "TOOK:  0.8763210773468018\n",
            "TOOK:  0.8295350074768066\n",
            "TOOK:  0.8150556087493896\n",
            "TOOK:  0.8540225028991699\n",
            "TOOK:  0.8538880348205566\n",
            "TOOK:  1.2209126949310303\n",
            "TOOK:  1.4558064937591553\n",
            "TOOK:  1.3455820083618164\n",
            "TOOK:  0.9651434421539307\n",
            "TOOK:  0.8808910846710205\n",
            "TOOK:  0.8495001792907715\n",
            "TOOK:  0.8719286918640137\n",
            "TOOK:  3.1054797172546387\n",
            "TOOK:  0.8514282703399658\n",
            "TOOK:  0.831756591796875\n",
            "TOOK:  0.8353579044342041\n",
            "TOOK:  0.8217689990997314\n",
            "TOOK:  1.0820040702819824\n",
            "TOOK:  1.3638992309570312\n",
            "TOOK:  1.4324951171875\n",
            "TOOK:  1.0345282554626465\n",
            "TOOK:  0.8204431533813477\n",
            "TOOK:  0.8101856708526611\n",
            "TOOK:  0.8067595958709717\n",
            "TOOK:  0.8109979629516602\n",
            "TOOK:  0.8316555023193359\n",
            "TOOK:  0.838303804397583\n",
            "TOOK:  0.829702615737915\n",
            "TOOK:  0.8498327732086182\n",
            "TOOK:  0.831777811050415\n",
            "TOOK:  0.8580565452575684\n",
            "TOOK:  0.8933312892913818\n",
            "TOOK:  1.237938642501831\n",
            "TOOK:  1.4578895568847656\n",
            "TOOK:  1.357579231262207\n",
            "TOOK:  0.8994967937469482\n",
            "TOOK:  0.8114075660705566\n",
            "TOOK:  0.8096842765808105\n",
            "TOOK:  2.8237571716308594\n",
            "TOOK:  0.8671977519989014\n",
            "TOOK:  0.8100728988647461\n",
            "TOOK:  0.8382840156555176\n",
            "TOOK:  0.8482208251953125\n",
            "TOOK:  0.8591763973236084\n",
            "TOOK:  0.9732406139373779\n",
            "TOOK:  1.4877827167510986\n",
            "TOOK:  1.431136131286621\n",
            "TOOK:  1.2170004844665527\n",
            "TOOK:  0.8140871524810791\n",
            "TOOK:  0.8043766021728516\n",
            "TOOK:  1.7243282794952393\n",
            "TOOK:  0.9763250350952148\n",
            "TOOK:  0.7826180458068848\n",
            "TOOK:  0.9692280292510986\n",
            "TOOK:  0.8420326709747314\n",
            "TOOK:  0.799072265625\n",
            "TOOK:  0.8421926498413086\n",
            "TOOK:  0.8323118686676025\n",
            "TOOK:  1.2491698265075684\n",
            "TOOK:  1.428048849105835\n",
            "TOOK:  1.4656555652618408\n",
            "TOOK:  1.0038278102874756\n",
            "TOOK:  0.8495352268218994\n",
            "TOOK:  0.8524210453033447\n",
            "TOOK:  0.8366236686706543\n",
            "TOOK:  0.8281059265136719\n",
            "TOOK:  0.8379788398742676\n",
            "TOOK:  0.8218860626220703\n",
            "TOOK:  0.8025269508361816\n",
            "TOOK:  0.8022751808166504\n",
            "TOOK:  0.8321983814239502\n",
            "TOOK:  0.8116254806518555\n",
            "TOOK:  0.8070735931396484\n",
            "TOOK:  1.190617561340332\n",
            "TOOK:  1.4157907962799072\n",
            "TOOK:  1.3798422813415527\n",
            "TOOK:  1.0001182556152344\n",
            "TOOK:  0.8450837135314941\n",
            "TOOK:  0.8564560413360596\n",
            "TOOK:  0.8565309047698975\n",
            "TOOK:  0.8801474571228027\n",
            "TOOK:  0.8523664474487305\n",
            "TOOK:  0.8415095806121826\n",
            "TOOK:  0.8425135612487793\n",
            "TOOK:  0.7917196750640869\n",
            "TOOK:  0.8764810562133789\n",
            "TOOK:  0.900458812713623\n",
            "TOOK:  0.8113038539886475\n",
            "TOOK:  1.4231340885162354\n",
            "TOOK:  0.8968749046325684\n",
            "TOOK:  1.3998937606811523\n",
            "TOOK:  1.066026210784912\n",
            "TOOK:  0.47692108154296875\n",
            "TOOK:  0.826411247253418\n",
            "TOOK:  0.8417859077453613\n",
            "TOOK:  0.8555994033813477\n",
            "TOOK:  0.8451085090637207\n",
            "TOOK:  0.8320152759552002\n",
            "TOOK:  0.8470203876495361\n",
            "TOOK:  0.9065651893615723\n",
            "TOOK:  0.8727917671203613\n",
            "TOOK:  0.8626358509063721\n",
            "TOOK:  0.3514866828918457\n",
            "TOOK:  0.8282163143157959\n",
            "TOOK:  1.353027105331421\n",
            "TOOK:  1.3944799900054932\n",
            "TOOK:  0.6000969409942627\n",
            "TOOK:  1.2200281620025635\n",
            "TOOK:  0.8078615665435791\n",
            "TOOK:  0.8118183612823486\n",
            "TOOK:  0.8620753288269043\n",
            "TOOK:  0.8371517658233643\n",
            "TOOK:  0.7993969917297363\n",
            "TOOK:  0.8331127166748047\n",
            "TOOK:  0.8728997707366943\n",
            "TOOK:  0.9361405372619629\n",
            "TOOK:  0.8522417545318604\n",
            "TOOK:  0.8441691398620605\n",
            "TOOK:  0.8487255573272705\n",
            "TOOK:  1.1484012603759766\n",
            "TOOK:  0.8895773887634277\n",
            "TOOK:  1.4011433124542236\n",
            "TOOK:  1.2498400211334229\n",
            "TOOK:  0.7818901538848877\n",
            "TOOK:  0.7994885444641113\n",
            "TOOK:  0.8316447734832764\n",
            "{\n",
            "  \"humaneval-x-bugs-go\": {\n",
            "    \"pass@1\": 0.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-go\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check buggy solutions are indeed all wrong ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-go \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8kFZDykjCaF"
      },
      "source": [
        "##### Rust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUowgbGTjDjM",
        "outputId": "5496b5ec-0436-44fd-b242-f8dc6143521b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rustc 1.70.0 (90c541806 2023-05-31)\n"
          ]
        }
      ],
      "source": [
        "!rustc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2gdxIBnjDgD",
        "outputId": "dc2be877-0697-4360-d73e-6139be60f02d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1minfo:\u001b[0m downloading installer\n",
            "\u001b[1minfo: \u001b[mprofile set to 'minimal'\n",
            "\u001b[1minfo: \u001b[mdefault host triple is x86_64-unknown-linux-gnu\n",
            "\u001b[1minfo: \u001b[msyncing channel updates for 'stable-x86_64-unknown-linux-gnu'\n",
            "\u001b[1minfo: \u001b[mlatest update on 2023-06-01, rust version 1.70.0 (90c541806 2023-05-31)\n",
            "\u001b[1minfo: \u001b[mdownloading component 'cargo'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rust-std'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rustc'\n",
            " 64.3 MiB /  64.3 MiB (100 %)  27.6 MiB/s in  2s ETA:  0s\n",
            "\u001b[1minfo: \u001b[minstalling component 'cargo'\n",
            "\u001b[1minfo: \u001b[minstalling component 'rust-std'\n",
            " 27.3 MiB /  27.3 MiB (100 %)   8.3 MiB/s in  3s ETA:  0s\n",
            "\u001b[1minfo: \u001b[minstalling component 'rustc'\n",
            " 64.3 MiB /  64.3 MiB (100 %)   2.8 MiB/s in 12s ETA:  0s\n",
            "\u001b[1minfo: \u001b[mdefault toolchain set to 'stable-x86_64-unknown-linux-gnu'\n",
            "\n",
            "  \u001b[1m\u001b[32mstable-x86_64-unknown-linux-gnu installed\u001b[m - rustc 1.70.0 (90c541806 2023-05-31)\n",
            "\n",
            "\u001b[1m\n",
            "Rust is installed now. Great!\n",
            "\u001b[m\n",
            "To get started you may need to restart your current shell.\n",
            "This would reload your \u001b[1mPATH\u001b[m environment variable to include\n",
            "Cargo's bin directory ($HOME/.cargo/bin).\n",
            "\n",
            "To configure your current shell, run:\n",
            "source \"$HOME/.cargo/env\"\n"
          ]
        }
      ],
      "source": [
        "!curl https://sh.rustup.rs -sSf | sh -s -- --profile minimal --default-toolchain stable -y\n",
        "import os\n",
        "os.environ['PATH'] = '/root/.cargo/bin:' + os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkXEStPc6JOT",
        "outputId": "f959e30a-3f49-4da0-86ad-ec388036c46f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rustc 1.70.0 (90c541806 2023-05-31)\n"
          ]
        }
      ],
      "source": [
        "!rustc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLx2xsNVHi-5",
        "outputId": "4fbb0cdb-758f-4347-a98e-e984ad9567ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-05 12:26:44.917683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-generate-rust']\n",
            "Loading tokenizer and model (in fp32)\n",
            "100% 1/1 [00:00<00:00, 284.84it/s]\n",
            "100% 1/1 [00:00<00:00, 283.44it/s]\n",
            "Evaluating generations...\n",
            "fn main(){}\n",
            "use std::{slice::Iter, cmp::{max, self}, mem::replace, collections::{HashSet, HashMap}, ops::Index, ascii::AsciiExt};\n",
            "use rand::Rng;\n",
            "use regex::Regex;\n",
            "use md5;\n",
            "use std::any::{Any, TypeId};\n",
            "\n",
            "fn has_close_elements(numbers:Vec<f32>, threshold: f32) -> bool{\n",
            "\n",
            "/*\n",
            " Check if in given list of numbers, are any two numbers closer to each other than\n",
            "    given threshold.\n",
            "    \n",
            "*/\n",
            "\n",
            "    for i in 0..numbers.len(){\n",
            "        for j in 1..numbers.len(){\n",
            "\n",
            "            if i != j {\n",
            "                let distance:f32 = numbers[i] - numbers[j];\n",
            "\n",
            "            if distance.abs() < threshold{\n",
            "                return true;\n",
            "            }\n",
            "\n",
            "            }\n",
            "            \n",
            "        }\n",
            "    }\n",
            "\n",
            "    return false;\n",
            "\n",
            "}\n",
            "\n",
            "TOOK:  1.410621166229248\n",
            "{\n",
            "  \"humaneval-x-generate-rust\": {\n",
            "    \"pass@1\": 1.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"modeltype\": \"causal\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-generate-rust\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"precision\": \"fp32\",\n",
            "    \"limit\": 1,\n",
            "    \"limit_start\": 0,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"load_generations_path\": null,\n",
            "    \"load_data_path\": null,\n",
            "    \"metric_output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_generations_path\": \"generations.json\",\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"max_memory_per_gpu\": null,\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check canonical solutions are indeed all right ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-generate-rust \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --limit 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PwK9B0ap9d7",
        "outputId": "1d9b674a-9337-42a0-9212-2ae9a651f76c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 11:15:49.907543: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-02 11:15:51.155453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-rust']\n",
            "Loading the model and tokenizer\n",
            "100% 1/1 [00:00<00:00, 395.99it/s]\n",
            "100% 1/1 [00:00<00:00, 496.43it/s]\n",
            "TOOK:  169.37540411949158\n",
            "TOOK:  1.325986385345459\n",
            "TOOK:  0.9727067947387695\n",
            "TOOK:  1.0621345043182373\n",
            "TOOK:  1.0460882186889648\n",
            "TOOK:  1.2206754684448242\n",
            "TOOK:  1.6908128261566162\n",
            "TOOK:  2.069699287414551\n",
            "TOOK:  1.4072210788726807\n",
            "TOOK:  1.0577800273895264\n",
            "TOOK:  1.0775716304779053\n",
            "TOOK:  1.0174474716186523\n",
            "TOOK:  1.2328391075134277\n",
            "TOOK:  0.9563636779785156\n",
            "TOOK:  1.3347980976104736\n",
            "TOOK:  1.081488847732544\n",
            "TOOK:  1.343287467956543\n",
            "TOOK:  1.5364480018615723\n",
            "TOOK:  1.5997369289398193\n",
            "TOOK:  1.7382559776306152\n",
            "TOOK:  1.0655031204223633\n",
            "TOOK:  1.1531751155853271\n",
            "TOOK:  1.1540396213531494\n",
            "TOOK:  0.9754526615142822\n",
            "TOOK:  1.0298378467559814\n",
            "TOOK:  1.1113159656524658\n",
            "TOOK:  1.4099507331848145\n",
            "TOOK:  1.0383086204528809\n",
            "TOOK:  1.5294058322906494\n",
            "TOOK:  2.149854898452759\n",
            "TOOK:  1.5175776481628418\n",
            "TOOK:  0.9972851276397705\n",
            "TOOK:  1.159679889678955\n",
            "TOOK:  1.2084338665008545\n",
            "TOOK:  1.142878770828247\n",
            "TOOK:  1.0465869903564453\n",
            "TOOK:  1.111013412475586\n",
            "TOOK:  1.169431447982788\n",
            "TOOK:  1.0705394744873047\n",
            "TOOK:  1.6668798923492432\n",
            "TOOK:  1.6520423889160156\n",
            "TOOK:  1.4516637325286865\n",
            "TOOK:  1.171776533126831\n",
            "TOOK:  1.0523293018341064\n",
            "TOOK:  1.0213727951049805\n",
            "TOOK:  0.967918872833252\n",
            "TOOK:  1.0898106098175049\n",
            "TOOK:  1.1391685009002686\n",
            "TOOK:  1.0607819557189941\n",
            "TOOK:  0.966118574142456\n",
            "TOOK:  1.3886902332305908\n",
            "TOOK:  1.404752492904663\n",
            "TOOK:  1.5652320384979248\n",
            "TOOK:  1.5030205249786377\n",
            "TOOK:  1.1824960708618164\n",
            "TOOK:  0.9683578014373779\n",
            "TOOK:  1.0222904682159424\n",
            "TOOK:  1.1755657196044922\n",
            "TOOK:  1.1825451850891113\n",
            "TOOK:  1.029313087463379\n",
            "TOOK:  0.9596762657165527\n",
            "TOOK:  1.0308647155761719\n",
            "TOOK:  1.0977048873901367\n",
            "TOOK:  1.2677979469299316\n",
            "TOOK:  1.5556719303131104\n",
            "TOOK:  1.6403343677520752\n",
            "TOOK:  1.0364105701446533\n",
            "TOOK:  1.0848679542541504\n",
            "TOOK:  1.0579540729522705\n",
            "TOOK:  1.0688464641571045\n",
            "TOOK:  1.1682782173156738\n",
            "TOOK:  0.9862408638000488\n",
            "TOOK:  1.0692851543426514\n",
            "TOOK:  0.9946708679199219\n",
            "TOOK:  1.4031598567962646\n",
            "TOOK:  1.5287582874298096\n",
            "TOOK:  1.5503723621368408\n",
            "TOOK:  1.3856916427612305\n",
            "TOOK:  1.2536919116973877\n",
            "TOOK:  1.0312550067901611\n",
            "TOOK:  1.0758416652679443\n",
            "TOOK:  1.3048713207244873\n",
            "TOOK:  1.013230323791504\n",
            "TOOK:  0.9637584686279297\n",
            "TOOK:  1.0679168701171875\n",
            "TOOK:  1.0525462627410889\n",
            "TOOK:  1.6762821674346924\n",
            "TOOK:  3.0079586505889893\n",
            "TOOK:  3.2590036392211914\n",
            "TOOK:  1.29801607131958\n",
            "TOOK:  1.1199378967285156\n",
            "TOOK:  1.4418649673461914\n",
            "TOOK:  0.9537155628204346\n",
            "TOOK:  1.2775883674621582\n",
            "TOOK:  1.0580673217773438\n",
            "TOOK:  1.329887866973877\n",
            "TOOK:  1.1101641654968262\n",
            "TOOK:  1.4682672023773193\n",
            "TOOK:  1.4693613052368164\n",
            "TOOK:  1.4625403881072998\n",
            "TOOK:  1.0718669891357422\n",
            "TOOK:  1.3513836860656738\n",
            "TOOK:  0.9403650760650635\n",
            "TOOK:  0.9866552352905273\n",
            "TOOK:  1.1613473892211914\n",
            "TOOK:  1.4915637969970703\n",
            "TOOK:  1.0936102867126465\n",
            "TOOK:  1.084233045578003\n",
            "TOOK:  1.2496280670166016\n",
            "TOOK:  1.532191276550293\n",
            "TOOK:  1.5173730850219727\n",
            "TOOK:  1.610642910003662\n",
            "TOOK:  1.2894744873046875\n",
            "TOOK:  1.2668206691741943\n",
            "TOOK:  1.0375304222106934\n",
            "TOOK:  1.0161457061767578\n",
            "TOOK:  1.132181167602539\n",
            "TOOK:  1.331451654434204\n",
            "TOOK:  1.0393073558807373\n",
            "TOOK:  1.2716293334960938\n",
            "TOOK:  1.8786916732788086\n",
            "TOOK:  1.5054314136505127\n",
            "TOOK:  1.0244364738464355\n",
            "TOOK:  1.1040396690368652\n",
            "TOOK:  1.0401196479797363\n",
            "TOOK:  1.5069165229797363\n",
            "TOOK:  1.0453271865844727\n",
            "TOOK:  1.0450623035430908\n",
            "TOOK:  1.0659396648406982\n",
            "TOOK:  1.1298213005065918\n",
            "TOOK:  1.0735020637512207\n",
            "TOOK:  1.5624146461486816\n",
            "TOOK:  1.5658016204833984\n",
            "TOOK:  1.432213544845581\n",
            "TOOK:  1.0103979110717773\n",
            "TOOK:  1.0147340297698975\n",
            "TOOK:  1.064232587814331\n",
            "TOOK:  1.139937400817871\n",
            "TOOK:  0.9874238967895508\n",
            "TOOK:  1.0094921588897705\n",
            "TOOK:  1.0398495197296143\n",
            "TOOK:  1.0535173416137695\n",
            "TOOK:  1.0328142642974854\n",
            "TOOK:  1.3775646686553955\n",
            "TOOK:  1.600938320159912\n",
            "TOOK:  1.6786308288574219\n",
            "TOOK:  1.0998599529266357\n",
            "TOOK:  1.1620004177093506\n",
            "TOOK:  1.2752268314361572\n",
            "TOOK:  1.3211889266967773\n",
            "TOOK:  0.9945042133331299\n",
            "TOOK:  1.093156337738037\n",
            "TOOK:  1.085782527923584\n",
            "TOOK:  1.088977336883545\n",
            "TOOK:  1.266136646270752\n",
            "TOOK:  1.6651391983032227\n",
            "TOOK:  1.5708212852478027\n",
            "TOOK:  1.071418046951294\n",
            "TOOK:  1.1041984558105469\n",
            "TOOK:  1.0537703037261963\n",
            "TOOK:  1.150804042816162\n",
            "TOOK:  1.0724027156829834\n",
            "TOOK:  1.0241732597351074\n",
            "TOOK:  1.0739638805389404\n",
            "{\n",
            "  \"humaneval-x-bugs-rust\": {\n",
            "    \"pass@1\": 1.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-rust\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check canonical solutions are indeed all right ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-rust \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU2lnx6M6Kgc",
        "outputId": "0ce8b6ad-9b07-4850-8b15-6625d76ab877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-02 10:22:25.205110: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-02 10:22:26.291170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Selected Tasks: ['humaneval-x-bugs-rust']\n",
            "Loading the model and tokenizer\n",
            "100% 1/1 [00:00<00:00, 434.64it/s]\n",
            "100% 1/1 [00:00<00:00, 613.47it/s]\n",
            "TOOK:  0.784912109375\n",
            "TOOK:  0.911719799041748\n",
            "TOOK:  0.6549711227416992\n",
            "TOOK:  0.7150988578796387\n",
            "TOOK:  0.7085232734680176\n",
            "TOOK:  0.8178060054779053\n",
            "TOOK:  0.7417387962341309\n",
            "TOOK:  0.9099762439727783\n",
            "TOOK:  0.8957834243774414\n",
            "TOOK:  0.9932425022125244\n",
            "TOOK:  1.0598468780517578\n",
            "TOOK:  0.7660164833068848\n",
            "TOOK:  0.826153039932251\n",
            "TOOK:  0.630150556564331\n",
            "TOOK:  0.8756558895111084\n",
            "TOOK:  0.7031106948852539\n",
            "TOOK:  0.8632667064666748\n",
            "TOOK:  0.7633161544799805\n",
            "TOOK:  0.6865575313568115\n",
            "TOOK:  0.7866415977478027\n",
            "TOOK:  0.7253401279449463\n",
            "TOOK:  0.767996072769165\n",
            "TOOK:  0.7697768211364746\n",
            "TOOK:  0.6527249813079834\n",
            "TOOK:  0.7939419746398926\n",
            "TOOK:  1.0970420837402344\n",
            "TOOK:  1.3959863185882568\n",
            "TOOK:  0.687065839767456\n",
            "TOOK:  0.6754591464996338\n",
            "TOOK:  0.888953447341919\n",
            "TOOK:  0.7687408924102783\n",
            "TOOK:  0.6485724449157715\n",
            "TOOK:  0.7334115505218506\n",
            "TOOK:  0.7442128658294678\n",
            "TOOK:  0.7377157211303711\n",
            "TOOK:  0.6905155181884766\n",
            "TOOK:  0.7314703464508057\n",
            "TOOK:  0.8234350681304932\n",
            "TOOK:  0.7079048156738281\n",
            "TOOK:  0.7037007808685303\n",
            "TOOK:  0.8190467357635498\n",
            "TOOK:  0.9144017696380615\n",
            "TOOK:  1.0774834156036377\n",
            "TOOK:  1.1650176048278809\n",
            "TOOK:  0.6959741115570068\n",
            "TOOK:  0.6268172264099121\n",
            "TOOK:  0.7225849628448486\n",
            "TOOK:  0.8028674125671387\n",
            "TOOK:  0.7238702774047852\n",
            "TOOK:  0.6520440578460693\n",
            "TOOK:  0.9519829750061035\n",
            "TOOK:  0.665114164352417\n",
            "TOOK:  0.6912174224853516\n",
            "TOOK:  0.666161298751831\n",
            "TOOK:  0.7732293605804443\n",
            "TOOK:  0.6397428512573242\n",
            "TOOK:  0.6805319786071777\n",
            "TOOK:  0.9925565719604492\n",
            "TOOK:  1.0551631450653076\n",
            "TOOK:  0.9448509216308594\n",
            "TOOK:  0.660581111907959\n",
            "TOOK:  0.6902759075164795\n",
            "TOOK:  0.732750654220581\n",
            "TOOK:  0.6451563835144043\n",
            "TOOK:  0.6849589347839355\n",
            "TOOK:  0.7650187015533447\n",
            "TOOK:  0.6564691066741943\n",
            "TOOK:  0.7140545845031738\n",
            "TOOK:  0.6973798274993896\n",
            "TOOK:  0.7218015193939209\n",
            "TOOK:  0.7787740230560303\n",
            "TOOK:  0.6496038436889648\n",
            "TOOK:  0.703972339630127\n",
            "TOOK:  0.6844854354858398\n",
            "TOOK:  1.1568100452423096\n",
            "TOOK:  0.9961433410644531\n",
            "TOOK:  0.9220211505889893\n",
            "TOOK:  0.7594749927520752\n",
            "TOOK:  0.8359785079956055\n",
            "TOOK:  0.6824526786804199\n",
            "TOOK:  0.7171978950500488\n",
            "TOOK:  0.8619077205657959\n",
            "TOOK:  0.6692731380462646\n",
            "TOOK:  0.6493082046508789\n",
            "TOOK:  0.7043066024780273\n",
            "TOOK:  0.6902074813842773\n",
            "TOOK:  0.8291449546813965\n",
            "TOOK:  0.7864587306976318\n",
            "TOOK:  0.8473379611968994\n",
            "TOOK:  0.7543447017669678\n",
            "TOOK:  0.9118545055389404\n",
            "TOOK:  2.007122755050659\n",
            "TOOK:  0.8876137733459473\n",
            "TOOK:  0.8825764656066895\n",
            "TOOK:  0.7443175315856934\n",
            "TOOK:  0.9326627254486084\n",
            "TOOK:  0.7226147651672363\n",
            "TOOK:  0.6544561386108398\n",
            "TOOK:  0.6725955009460449\n",
            "TOOK:  0.7278130054473877\n",
            "TOOK:  0.7310223579406738\n",
            "TOOK:  0.909599781036377\n",
            "TOOK:  0.6465315818786621\n",
            "TOOK:  0.6911449432373047\n",
            "TOOK:  0.7879059314727783\n",
            "TOOK:  1.0255341529846191\n",
            "TOOK:  1.0475456714630127\n",
            "TOOK:  1.07088303565979\n",
            "TOOK:  0.8640389442443848\n",
            "TOOK:  0.6745688915252686\n",
            "TOOK:  0.6982266902923584\n",
            "TOOK:  0.9986715316772461\n",
            "TOOK:  0.9065134525299072\n",
            "TOOK:  0.8702752590179443\n",
            "TOOK:  0.7143669128417969\n",
            "TOOK:  0.6993703842163086\n",
            "TOOK:  0.7471411228179932\n",
            "TOOK:  0.8962540626525879\n",
            "TOOK:  0.7207202911376953\n",
            "TOOK:  0.7403068542480469\n",
            "TOOK:  0.8312039375305176\n",
            "TOOK:  0.9372692108154297\n",
            "TOOK:  0.9862215518951416\n",
            "TOOK:  1.0623860359191895\n",
            "TOOK:  0.7297401428222656\n",
            "TOOK:  1.0067920684814453\n",
            "TOOK:  0.7189130783081055\n",
            "TOOK:  0.7115797996520996\n",
            "TOOK:  0.7074599266052246\n",
            "TOOK:  0.7994635105133057\n",
            "TOOK:  0.7429056167602539\n",
            "TOOK:  0.716214656829834\n",
            "TOOK:  0.7051761150360107\n",
            "TOOK:  0.7268154621124268\n",
            "TOOK:  0.6832525730133057\n",
            "TOOK:  0.7080700397491455\n",
            "TOOK:  0.7408301830291748\n",
            "TOOK:  0.9971334934234619\n",
            "TOOK:  0.9227426052093506\n",
            "TOOK:  0.9430263042449951\n",
            "TOOK:  0.8168737888336182\n",
            "TOOK:  0.7143251895904541\n",
            "TOOK:  0.7182378768920898\n",
            "TOOK:  0.7202003002166748\n",
            "TOOK:  0.7406196594238281\n",
            "TOOK:  0.7960705757141113\n",
            "TOOK:  0.741450309753418\n",
            "TOOK:  0.9413304328918457\n",
            "TOOK:  1.2650630474090576\n",
            "TOOK:  1.2325828075408936\n",
            "TOOK:  0.6955876350402832\n",
            "TOOK:  0.7548894882202148\n",
            "TOOK:  0.9671943187713623\n",
            "TOOK:  1.0593397617340088\n",
            "TOOK:  1.030672550201416\n",
            "TOOK:  0.7558412551879883\n",
            "Process Process-314:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/root/.cache/huggingface/modules/evaluate_modules/metrics/Muennighoff--code_eval/2c6407cda0c81350498c9e1eb18f5063d0b27be9c41e8c7a2d287ee4707e29cd/execute.py\", line 260, in unsafe_execute_rust\n",
            "    exec_result = subprocess.run([\"cargo\", \"test\", \"--bin\", \"test\", \"--message-format\", \"json\"], timeout=timeout, capture_output=True)\n",
            "  File \"/usr/lib/python3.9/subprocess.py\", line 507, in run\n",
            "    stdout, stderr = process.communicate(input, timeout=timeout)\n",
            "  File \"/usr/lib/python3.9/subprocess.py\", line 1134, in communicate\n",
            "    stdout, stderr = self._communicate(input, endtime, timeout)\n",
            "  File \"/usr/lib/python3.9/subprocess.py\", line 1980, in _communicate\n",
            "    self._check_timeout(endtime, orig_timeout, stdout, stderr)\n",
            "  File \"/usr/lib/python3.9/subprocess.py\", line 1178, in _check_timeout\n",
            "    raise TimeoutExpired(\n",
            "subprocess.TimeoutExpired: Command '['cargo', 'test', '--bin', 'test', '--message-format', 'json']' timed out after 300 seconds\n",
            "TOOK:  300.4256682395935\n",
            "TOOK:  1.771552324295044\n",
            "TOOK:  1.1792783737182617\n",
            "TOOK:  0.95912766456604\n",
            "TOOK:  1.0011842250823975\n",
            "TOOK:  0.9683806896209717\n",
            "TOOK:  0.9278683662414551\n",
            "TOOK:  0.9954278469085693\n",
            "{\n",
            "  \"humaneval-x-bugs-rust\": {\n",
            "    \"pass@1\": 0.0\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"prefix\": \"\",\n",
            "    \"do_sample\": true,\n",
            "    \"temperature\": 0.2,\n",
            "    \"top_k\": 0,\n",
            "    \"top_p\": 0.95,\n",
            "    \"n_samples\": 1,\n",
            "    \"eos\": \"<|endoftext|>\",\n",
            "    \"seed\": 0,\n",
            "    \"model\": \"codeparrot/codeparrot-small\",\n",
            "    \"revision\": null,\n",
            "    \"use_auth_token\": false,\n",
            "    \"trust_remote_code\": true,\n",
            "    \"tasks\": \"humaneval-x-bugs-rust\",\n",
            "    \"batch_size\": 1,\n",
            "    \"max_length_generation\": 512,\n",
            "    \"limit\": null,\n",
            "    \"postprocess\": true,\n",
            "    \"allow_code_execution\": true,\n",
            "    \"generation_only\": false,\n",
            "    \"generations_path\": \"generations.json\",\n",
            "    \"output_path\": \"evaluation_results.json\",\n",
            "    \"save_generations\": false,\n",
            "    \"save_references\": false,\n",
            "    \"mutate_method\": \"edit\",\n",
            "    \"check_references\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "### Check buggy solutions are indeed all wrong ###\n",
        "!python main.py \\\n",
        "  --model codeparrot/codeparrot-small \\\n",
        "  --tasks humaneval-x-bugs-rust \\\n",
        "  --do_sample True \\\n",
        "  --n_samples 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --allow_code_execution \\\n",
        "  --trust_remote_code \\\n",
        "  --mutate_method edit \\\n",
        "  --check_references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP1KYPm1Eur5"
      },
      "source": [
        "#### Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3K9T9U8sfnz",
        "outputId": "edcb965e-37bd-4fe6-e10d-63384b89f4b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q evaluate\n",
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7FDZr6QtBhQ"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "eval = load(\"Muennighoff/code_eval\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWXedCM8tIaT"
      },
      "source": [
        "##### Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjDGAkVctIMB",
        "outputId": "3bbd8b99-dab6-45ec-cf5a-d0dd199b0f97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pass@1': 0.5, 'pass@2': 1.0}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"HF_ALLOW_CODE_EVAL\"] = \"1\"\n",
        "test_cases = [\"assert add(2,3)==5\"]\n",
        "candidates = [[\"def add(a,b): return a*b\", \"def add(a, b): return a+b\"]]\n",
        "pass_at_k, results = eval.compute(references=test_cases, predictions=candidates, k=[1, 2])\n",
        "pass_at_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eHvXy3XtJeR"
      },
      "source": [
        "##### CPP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "74480d2838bb4093927fdac2a25f1974",
            "e419c5b80f6f46749d89830798f1bbbc",
            "0b1b09d561934a3cb49ec0a4b86d02aa",
            "ff8dc9882d9f4feaaea3babdd28b5394",
            "a5295cbf725c43babcd9f99bf90ee049",
            "d47abbaa8cfc42f7a6b2b687adf5a4c0",
            "34614f24f55c424da5a71a2b1b13e877",
            "f983308187464fea8982245f395c4467",
            "6b7d9fe6800c4eedae89f510aaef0152",
            "940d4e0101c64704a317b36148941b54",
            "64311d384d464e23959d3411d2b93219"
          ]
        },
        "id": "ZLsQa_mZtKUe",
        "outputId": "ce063622-af8e-477f-cdac-4820585be544"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset humaneval-x-bugs (/root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/cpp/1.0.0/af7a71881b1fc378edefa4b2c3ddc510933ed90c46b7081ea1843bab250d706b)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74480d2838bb4093927fdac2a25f1974",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'pass@1': 1.0}\n",
            "{'pass@1': 0.0}\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "ds = datasets.load_dataset(\"bigcode/humaneval-x-bugs\", \"cpp\")[\"test\"]\n",
        "\n",
        "IDX = 14\n",
        "\n",
        "import os\n",
        "os.environ[\"HF_ALLOW_CODE_EVAL\"] = \"1\"\n",
        "\n",
        "test_cases = [ds[\"test\"][IDX]]\n",
        "candidates = [[ds[\"prompt\"][IDX] + ds[\"canonical_solution\"][IDX]]]\n",
        "\n",
        "pass_at_k, results = eval.compute(references=test_cases, predictions=candidates, k=[1, 2], language=\"cpp\")\n",
        "print(pass_at_k)\n",
        "\n",
        "test_cases = [ds[\"test\"][IDX]]\n",
        "candidates = [[ds[\"prompt\"][IDX] + BS]]\n",
        "               #ds[\"buggy_solution\"][IDX]]]\n",
        "\n",
        "pass_at_k, results = eval.compute(references=test_cases, predictions=candidates, k=[1, 2], language=\"cpp\")\n",
        "print(pass_at_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7clTuQ2uT452",
        "outputId": "52e270f3-9db5-4f45-cbaa-91d8c40743c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "849"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "open(f\"test.cpp\", 'w').write(\n",
        "  candidates[0][0] + test_cases[0]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9rpbmbbVFVv",
        "outputId": "3b6ea86f-2205-448b-bd91-6c9a5f5a3734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    vector<string> out;\n",
            "    string current=\"\";\n",
            "    for (int i=0;i<str.length()-1;i++)\n",
            "    {\n",
            "        current=current+str[i];\n",
            "        out.push_back(current);\n",
            "    }\n",
            "    return out;\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(ds[\"buggy_solution\"][IDX])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO9-WJYwVGhI"
      },
      "outputs": [],
      "source": [
        "BS = \"    vector<string> out;\\n    string current=\\\"\\\";\\n    for (int i=0;i<str.length();i++)\\n    {\\n        current=current+str[i];\\n        out.push_back(current);\\n    }\\n    out.push_back(current);\\n    return out;\\n}\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eYjMO7_UCMJ"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "compilation_result = subprocess.run(\n",
        "    [\"/usr/bin/g++\", \"-std=c++11\", \"test.cpp\", \"-lcrypto\", \"-lssl\"],\n",
        "    timeout=10,\n",
        "    capture_output=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncRSkD6XUHGG"
      },
      "outputs": [],
      "source": [
        "exec_result = subprocess.run([\"./a.out\"], timeout=10, capture_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc5CXCj5UKnS",
        "outputId": "39a50fab-2968-402f-b1e5-c163cc18594c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['./a.out'], returncode=-11, stdout=b'', stderr=b'')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exec_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bR2DJVVTqDa",
        "outputId": "e7e1d60e-c911-4dfe-c0b9-a794317304ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {0: [(0,\n",
              "               {'task_id': 0,\n",
              "                'passed': False,\n",
              "                'result': 'failed: a.out: test.cpp:33: int main(): Assertion `issame(all_prefixes(\"\"),{})\\' failed.\\n',\n",
              "                'completion_id': 0})]})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RL8JH9nU0PH",
        "outputId": "0c2b3f12-ca1a-464d-91af-88cfd2a42e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#undef NDEBUG\n",
            "#include<assert.h>\n",
            "bool issame(vector<string> a,vector<string>b){\n",
            "    if (a.size()!=b.size()) return false;\n",
            "    for (int i=0;i<a.size();i++)\n",
            "    {\n",
            "    if (a[i]!=b[i]) return false;\n",
            "    }\n",
            "    return true;\n",
            "}\n",
            "int main(){\n",
            "    assert (issame(all_prefixes(\"\"),{}));\n",
            "    assert (issame(all_prefixes(\"asdfgh\") ,{\"a\", \"as\", \"asd\", \"asdf\", \"asdfg\", \"asdfgh\"}));\n",
            "     assert (issame(all_prefixes(\"WWW\") ,{\"W\", \"WW\", \"WWW\"}));\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(test_cases[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oX5MEjZuThEt",
        "outputId": "fe304323-4a95-4500-e870-6d9cce08d04f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'    vector<string> out;\\n    string current=\"\";\\n    for (int i=0;i<str.length()-1;i++)\\n    {\\n        current=current+str[i];\\n        out.push_back(current);\\n    }\\n    return out;\\n}\\n'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds[\"buggy_solution\"][14]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONGvx8njtKtB"
      },
      "source": [
        "##### JS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "8c7d7bc531714104a741c8557139d875",
            "b9f7b350be0f4338914d0089053147f2",
            "37d2809f9aeb420f8b28180b5d51ad6f",
            "154b1ac6dec24e31bdf7dedab0d030d0",
            "d49d85cbc4e34dab8d8de108c5f69c04",
            "6e419cb8669245eab12e928b82fba7a3",
            "20b0c88ab54f4c81bcc8ecad5f316d50",
            "92655b7478fe4456b7604d0008f7e029",
            "1274237bedfe4ffebdd6ea26104d766c",
            "bb2a4937d0a24bbd9ad1101bf6acca9f",
            "83dbe04bd512434e9de694a94cdd6278"
          ]
        },
        "id": "-i3V3930tLhk",
        "outputId": "13c50bf1-06e7-433f-cede-ffb70aa38d73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset humaneval-x-bugs (/root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/js/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c7d7bc531714104a741c8557139d875",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'pass@1': 0.0}\n",
            "{'pass@1': 1.0}\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "ds = datasets.load_dataset(\"bigcode/humaneval-x-bugs\", \"js\")[\"test\"]\n",
        "\n",
        "import os\n",
        "os.environ[\"HF_ALLOW_CODE_EVAL\"] = \"1\"\n",
        "\n",
        "idx = 112\n",
        "\n",
        "\n",
        "test_cases = [ds[\"test\"][idx]]\n",
        "candidates = [[ds[\"prompt\"][idx] + ds[\"canonical_solution\"][idx]]]\n",
        "\n",
        "pass_at_k, results = eval.compute(references=test_cases, predictions=candidates, k=[1, 2], language=\"javascript\")\n",
        "print(pass_at_k)\n",
        "\n",
        "test_cases = [ds[\"test\"][idx]]\n",
        "candidates = [[ (ds[\"prompt\"][idx] + ds[\"canonical_solution\"][idx]).replace(\"return (z, false)\", \"return [z, false];\").replace(\"return (z, true)\", \"return [z, true];\") ]]\n",
        "candidates = [[can]]\n",
        "pass_at_k, results = eval.compute(references=test_cases, predictions=candidates, k=[1, 2], language=\"javascript\")\n",
        "print(pass_at_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T1LlyXC3jDF",
        "outputId": "3715467c-23ce-4774-e7be-2d1ce3e98028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'pass@1': 1.0}\n"
          ]
        }
      ],
      "source": [
        "task_fixed = {\"task_id\": \"JavaScript/112\", \"prompt\": \"/*Task\\n  We are given two strings s and c, you have to deleted all the characters in s that are equal to any character in c\\n  then check if the result string is palindrome.\\n  A string is called palindrome if it reads the same backward as forward.\\n  You should return a tuple containing the result string and true/false for the check.\\n  Example\\n  For s = \\\"abcde\\\", c = \\\"ae\\\", the result should be ('bcd',false)\\n  For s = \\\"abcdef\\\", c = \\\"b\\\"  the result should be ('acdef',false)\\n  For s = \\\"abcdedcba\\\", c = \\\"ab\\\", the result should be ('cdedc',true)\\n  */\\nconst reverseDelete = (s, c) => {\\n\", \"canonical_solution\": \"  let t = ''\\n  for (let i = 0; i < s.length; i++) {\\n    let y = 1\\n    for (let j = 0; j < c.length; j++) {\\n      if (s[i] == c[j]) {\\n        y = 0\\n      }\\n    }\\n    if (y == 1) {\\n      t += s[i]\\n    }\\n  }\\n  let isPalindrome = true\\n  for (let i = 0; i < Math.floor(t.length / 2); i++) {\\n    if (t[i] != t[t.length - i - 1]) {\\n      isPalindrome = false\\n      break\\n    }\\n  }\\n  return [t, isPalindrome];\\n}\\n\\n\", \"test\": \"const testReverseDelete = () => {\\n  console.assert(JSON.stringify(reverseDelete('abcde', 'ae')) ===\\n    JSON.stringify(['bcd', false]))\\n  console.assert(JSON.stringify(reverseDelete('abcdef', 'b')) ===\\n    JSON.stringify(['acdef', false]))\\n  console.assert(JSON.stringify(reverseDelete('abcdedcba', 'ab')) ===\\n    JSON.stringify(['cdedc', true]))\\n  console.assert(JSON.stringify(reverseDelete('dwik', 'w')) ===\\n    JSON.stringify(['dik', false]))\\n  console.assert(JSON.stringify(reverseDelete('a', 'a')) ===\\n    JSON.stringify(['', true]))\\n  console.assert(JSON.stringify(reverseDelete('abcdedcba', '')) ===\\n    JSON.stringify(['abcdedcba', true]))\\n  console.assert(JSON.stringify(reverseDelete('abcdedcba', 'v')) ===\\n    JSON.stringify(['abcdedcba', true]))\\n  console.assert(JSON.stringify(reverseDelete('vabba', 'v')) ===\\n    JSON.stringify(['abba', true]))\\n  console.assert(JSON.stringify(reverseDelete('mamma', 'mia')) ===\\n    JSON.stringify(['', true]))\\n}\\n\\ntestReverseDelete()\\n\", \"declaration\": \"\\nconst reverseDelete = (s, c) => {\\n\", \"example_test\": \"const testReverseDelete = () => {\\n  console.assert(JSON.stringify(reverseDelete('abcde', 'ae'))) ===\\n    JSON.stringify(['bcd', false])\\n  console.assert(JSON.stringify(reverseDelete('abcdef', 'b'))) ===\\n    JSON.stringify(['acdef', false])\\n  console.assert(JSON.stringify(reverseDelete('abcdedcba', 'ab'))) ===\\n    JSON.stringify(['cdedc', true])\\n}\\ntestReverseDelete()\\n\"}\n",
        "\n",
        "test_cases = [task_fixed[\"test\"]]\n",
        "candidates = [[(task_fixed[\"prompt\"] + task_fixed[\"canonical_solution\"])]]\n",
        "\n",
        "pass_at_k, results = eval.compute(references=test_cases, predictions=candidates, k=[1, 2], language=\"javascript\")\n",
        "print(pass_at_k)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgtPtJ5z4FUM",
        "outputId": "eecefc7f-473c-4675-f996-720947e0ddc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"  let t = ''\\n  for (let i = 0; i < s.length; i++) {\\n    let y = 1\\n    for (let j = 0; j < c.length; j++) {\\n      if (s[i] == c[j]) {\\n        y = 0\\n      }\\n    }\\n    if (y == 1) {\\n      t += s[i]\\n    }\\n  }\\n  let isPalindrome = true\\n  for (let i = 0; i < Math.floor(t.length / 2); i++) {\\n    if (t[i] != t[t.length - i - 1]) {\\n      isPalindrome = false\\n      break\\n    }\\n  }\\n  return [t, isPalindrome];\\n}\\n\\n\"\n"
          ]
        }
      ],
      "source": [
        "print(repr(task_fixed[\"canonical_solution\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlEvrde81cBr",
        "outputId": "00367a50-5d83-441f-fd85-eefed34ba779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/*Task\n",
            "  We are given two strings s and c, you have to deleted all the characters in s that are equal to any character in c\n",
            "  then check if the result string is palindrome.\n",
            "  A string is called palindrome if it reads the same backward as forward.\n",
            "  You should return a tuple containing the result string and true/false for the check.\n",
            "  Example\n",
            "  For s = \"abcde\", c = \"ae\", the result should be ('bcd',false)\n",
            "  For s = \"abcdef\", c = \"b\"  the result should be ('acdef',false)\n",
            "  For s = \"abcdedcba\", c = \"ab\", the result should be ('cdedc',true)\n",
            "  */\n",
            "const reverseDelete = (s, c) => {\n",
            "  let t = ''\n",
            "  for (let i = 0; i < s.length; i++) {\n",
            "    let y = 1\n",
            "    for (let j = 0; j < c.length; j++) {\n",
            "      if (s[i] == c[j]) {\n",
            "        y = 0\n",
            "      }\n",
            "    }\n",
            "    if (y == 1) {\n",
            "      t += s[i]\n",
            "    }\n",
            "  }\n",
            "  let z = 1\n",
            "  for (let i = 0; i < t.length; i++) {\n",
            "    if (t[i] != t[t.length - i - 1]) {\n",
            "      z = 0\n",
            "    }\n",
            "  }\n",
            "  if (z == 0) {\n",
            "    return [z, false];\n",
            "  }\n",
            "  return [z, true];\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(candidates[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnTgs8ry0I0P",
        "outputId": "dd280bd9-8c0e-4b03-b6de-0d0b56489f2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/*Task\n",
            "  We are given two strings s and c, you have to deleted all the characters in s that are equal to any character in c\n",
            "  then check if the result string is palindrome.\n",
            "  A string is called palindrome if it reads the same backward as forward.\n",
            "  You should return a tuple containing the result string and true/false for the check.\n",
            "  Example\n",
            "  For s = \"abcde\", c = \"ae\", the result should be ('bcd',false)\n",
            "  For s = \"abcdef\", c = \"b\"  the result should be ('acdef',false)\n",
            "  For s = \"abcdedcba\", c = \"ab\", the result should be ('cdedc',true)\n",
            "  */\n",
            "const reverseDelete = (s, c) => {\n",
            "  let t = ''\n",
            "  for (let i = 0; i < s.length; i++) {\n",
            "    let y = 1\n",
            "    for (let j = 0; j < c.length; j++) {\n",
            "      if (s[i] == c[j]) {\n",
            "        y = 0\n",
            "      }\n",
            "    }\n",
            "    if (y == 1) {\n",
            "      t += s[i]\n",
            "    }\n",
            "  }\n",
            "  let z = 1\n",
            "  for (let i = 0; i < t.length; i++) {\n",
            "    if (t[i] != t[t.length - i - 1]) {\n",
            "      z = 0\n",
            "    }\n",
            "  }\n",
            "  if (z == 0) {\n",
            "    return (z, false)\n",
            "  }\n",
            "  return (z, true)\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(ds[\"prompt\"][idx] + ds[\"canonical_solution\"][idx])\n",
        "print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtMSU72kKhBV"
      },
      "outputs": [],
      "source": [
        "prompt=\"\"\"const reverseDelete = (s, c) => {\n",
        "  let t = ''\n",
        "  for (let i = 0; i < s.length; i++) {\n",
        "    let y = 1\n",
        "    for (let j = 0; j < c.length; j++) {\n",
        "      if (s[i] == c[j]) {\n",
        "        y = 0\n",
        "      }\n",
        "    }\n",
        "    if (y == 1) {\n",
        "      t += s[i]\n",
        "    }\n",
        "  }\n",
        "  let z = 1\n",
        "  for (let i = 0; i < t.length; i++) {\n",
        "    if (t[i] != t[t.length - i - 1]) {\n",
        "      z = 0\n",
        "    }\n",
        "  }\n",
        "  if (z == 0) {\n",
        "    return (z, false)\n",
        "  }\n",
        "  return (z, true)\n",
        "}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZxPJJTOK8xU",
        "outputId": "725eeb9e-b8f5-4064-e9e2-afb4250a4883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "const testReverseDelete = () => {\n",
            "  console.assert(JSON.stringify(reverseDelete('abcde', 'ae'))) ===\n",
            "    JSON.stringify(['bcd', false])\n",
            "  console.assert(JSON.stringify(reverseDelete('abcdef', 'b'))) ===\n",
            "    JSON.stringify(['acdef', false])\n",
            "  console.assert(JSON.stringify(reverseDelete('abcdedcba', 'ab'))) ===\n",
            "    JSON.stringify(['cdedc', true])\n",
            "  console.assert(JSON.stringify(reverseDelete('dwik', 'w'))) ===\n",
            "    JSON.stringify(['dik', false])\n",
            "  console.assert(JSON.stringify(reverseDelete('a', 'a'))) ===\n",
            "    JSON.stringify(['', true])\n",
            "  console.assert(JSON.stringify(reverseDelete('abcdedcba', ''))) ===\n",
            "    JSON.stringify(['abcdedcba', true])\n",
            "  console.assert(JSON.stringify(reverseDelete('abcdedcba', 'v'))) ===\n",
            "    JSON.stringify(['abcdedcba', true])\n",
            "  console.assert(JSON.stringify(reverseDelete('vabba', 'v'))) ===\n",
            "    JSON.stringify(['abba', true])\n",
            "  console.assert(JSON.stringify(reverseDelete('mamma', 'mia'))) ===\n",
            "    JSON.stringify(['', true])\n",
            "}\n",
            "\n",
            "testReverseDelete()\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(ds[\"test\"][idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYh5XgLBHOtq",
        "outputId": "545915d6-2d87-4c20-8dec-e12dc688f0e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/*Task\n",
            "  We are given two strings s and c, you have to deleted all the characters in s that are equal to any character in c\n",
            "  then check if the result string is palindrome.\n",
            "  A string is called palindrome if it reads the same backward as forward.\n",
            "  You should return a tuple containing the result string and true/false for the check.\n",
            "  Example\n",
            "  For s = \"abcde\", c = \"ae\", the result should be ('bcd',false)\n",
            "  For s = \"abcdef\", c = \"b\"  the result should be ('acdef',false)\n",
            "  For s = \"abcdedcba\", c = \"ab\", the result should be ('cdedc',true)\n",
            "  */\n",
            "const reverseDelete = (s, c) => {\n",
            "  let t = ''\n",
            "  for (let i = 0; i < s.length; i++) {\n",
            "    let y = 1\n",
            "    for (let j = 0; j < c.length; j++) {\n",
            "      if (s[i] == c[j]) {\n",
            "        y = 0\n",
            "      }\n",
            "    }\n",
            "    if (y == 1) {\n",
            "      t += s[i]\n",
            "    }\n",
            "  }\n",
            "  let z = 1\n",
            "  for (let i = 0; i < t.length; i++) {\n",
            "    if (t[i] != t[t.length - i - 1]) {\n",
            "      z = 0\n",
            "    }\n",
            "  }\n",
            "  if (z == 0) {\n",
            "    return (z, false)\n",
            "  }\n",
            "  return (z, true)\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print([[ds[\"prompt\"][idx] + ds[\"canonical_solution\"][idx]]][0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4JzVl7ntLx_"
      },
      "source": [
        "##### Java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "50f3b4a9f6014f60969efe5d5ff549bf",
            "61657564a9a546609accb626eb41268e",
            "251d6da853d3448ea8a141335fab2e6b",
            "02c9e2a791ed43b88f632df22d129965",
            "195c5cdb8f9a4aa487d0dc67f4dabeec",
            "6536128ba0cc410daf361ba9f1c3bbe4",
            "6ddbc11ccaf944918db90aa5176f18ec",
            "843181eaa98d410bacb72bd9142db5ab",
            "8d749c450b89443c900815a0489aef39",
            "4ef1e6cb98254301b51ab3702e4cc959",
            "81d66f6a5bc2465da785a9d900194b71"
          ]
        },
        "id": "XtyeaWJjtMY3",
        "outputId": "2d12c2d3-3339-45da-888f-d5271cd3c26a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset humaneval-x-bugs (/root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/java/1.0.0/af7a71881b1fc378edefa4b2c3ddc510933ed90c46b7081ea1843bab250d706b)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50f3b4a9f6014f60969efe5d5ff549bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'pass@1': 0.0}\n",
            "{'pass@1': 0.0}\n"
          ]
        }
      ],
      "source": [
        "LANGUAGE = \"java\"\n",
        "idx = 17\n",
        "\n",
        "import datasets\n",
        "ds = datasets.load_dataset(\"bigcode/humaneval-x-bugs\", LANGUAGE)[\"test\"]\n",
        "\n",
        "import os\n",
        "os.environ[\"HF_ALLOW_CODE_EVAL\"] = \"1\"\n",
        "\n",
        "test_cases = [ds[\"test\"][idx]]\n",
        "candidates = [[ds[\"prompt\"][idx] + ds[\"canonical_solution\"][idx]]]\n",
        "\n",
        "pass_at_k, results = eval.compute(references=test_cases, predictions=candidates, k=[1, 2], language=LANGUAGE)\n",
        "print(pass_at_k)\n",
        "\n",
        "\n",
        "test_cases = [ds[\"test\"][idx].replace(\"false\", \"true\")]\n",
        "candidates = [[ds[\"prompt\"][idx] + ds[\"canonical_solution\"][idx]]]\n",
        "\n",
        "pass_at_k, results = eval.compute(references=test_cases, predictions=candidates, k=[1, 2], language=LANGUAGE)\n",
        "print(pass_at_k)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVVTqSO9Rtjn",
        "outputId": "035ba6fb-a091-4b81-c002-0971dd174353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.18\" 2023-01-17\n",
            "OpenJDK Runtime Environment (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCTg2I7VRWvK",
        "outputId": "3e181c26-04b2-4c59-ccca-51129308115f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'list'>, {0: [(0, {'task_id': 0, 'passed': False, 'result': 'failed: compilation error', 'completion_id': 0})]})\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St3cwQQVRAht",
        "outputId": "e888e6c8-9392-4c46-c346-f585c8956798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "import java.util.*;\n",
            "import java.lang.*;\n",
            "\n",
            "class Solution {\n",
            "    /**\n",
            "    Input to this function is a string representing musical notes in a special ASCII format.\n",
            "    Your task is to parse this string and return list of integers corresponding to how many beats does each\n",
            "    not last.\n",
            "\n",
            "    Here is a legend:\n",
            "    \"o\" - whole note, lasts four beats\n",
            "    \"o|\" - half note, lasts two beats\n",
            "    \".|\" - quater note, lasts one beat\n",
            "\n",
            "    >>> parseMusic(\"o o| .| o| o| .| .| .| .| o o\")\n",
            "    [4, 2, 1, 2, 2, 1, 1, 1, 1, 4, 4]\n",
            "     */\n",
            "    public List<Integer> parseMusic(String string) {\n",
            "        String[] notes = string.split(\" \");\n",
            "        List<Integer> result = new ArrayList<>();\n",
            "        for (String s : notes) {\n",
            "            switch (s) {\n",
            "                case \"o\" -> result.add(4);\n",
            "                case \"o|\" -> result.add(2);\n",
            "                case \".|\" -> result.add(1);\n",
            "            }\n",
            "        }\n",
            "        return result;\n",
            "    }\n",
            "}\n",
            "public class Main {\n",
            "    public static void main(String[] args) {\n",
            "        Solution s = new Solution();\n",
            "        List<Boolean> correct = Arrays.asList(\n",
            "                s.parseMusic(\"\").equals(List.of()),\n",
            "                s.parseMusic(\"o o o o\").equals(Arrays.asList(4, 4, 4, 4)),\n",
            "                s.parseMusic(\".| .| .| .|\").equals(Arrays.asList(1, 1, 1, 1)),\n",
            "                s.parseMusic(\"o| o| .| .| o o o o\").equals(Arrays.asList(2, 2, 1, 1, 4, 4, 4, 4)),\n",
            "                s.parseMusic(\"o| .| o| .| o o| o o|\").equals(Arrays.asList(2, 1, 2, 1, 4, 2, 4, 2))\n",
            "        );\n",
            "        if (correct.contains(true)) {\n",
            "            throw new AssertionError();\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(candidates[0][0])\n",
        "print(test_cases[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F4NhnxGRF0e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Sdt7_ttMwr"
      },
      "source": [
        "##### Go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFw6dEAmtNXj"
      },
      "outputs": [],
      "source": [
        "IMPORT_HELPER = {\n",
        "    \"python\": [\n",
        "        \"import math\",\n",
        "        \"import re\",\n",
        "        \"import sys\",\n",
        "        \"import copy\",\n",
        "        \"import datetime\",\n",
        "        \"import itertools\",\n",
        "        \"import collections\",\n",
        "        \"import heapq\",\n",
        "        \"import statistics\",\n",
        "        \"import functools\",\n",
        "        \"import hashlib\",\n",
        "        \"import numpy\",\n",
        "        \"import numpy as np\",\n",
        "        \"import string\",\n",
        "        \"from typing import *\",\n",
        "        \"from collections import *\",\n",
        "    ],\n",
        "    \"go\"    : [\n",
        "        \"math\",\n",
        "        \"strings\",\n",
        "        \"fmt\",\n",
        "        \"strconv\",\n",
        "        \"time\",\n",
        "        \"bytes\",\n",
        "        \"regexp\",\n",
        "        \"sort\",\n",
        "        \"math/rand\",\n",
        "        \"crypto/md5\",\n",
        "    ],\n",
        "    \"cpp\"   : [\n",
        "        \"#include<stdlib.h>\",\n",
        "        \"#include<algorithm>\",\n",
        "        \"#include<math.h>\",\n",
        "        \"#include<stdio.h>\",\n",
        "        \"#include<vector>\",\n",
        "        \"#include<string>\",\n",
        "        \"#include<climits>\",\n",
        "        \"#include<cstring>\",\n",
        "        \"#include<iostream>\",\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQgCqyb8t2Bz",
        "outputId": "416351dc-061f-434a-94be-65418b18547c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [969 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,027 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,198 kB]\n",
            "Get:14 http://ppa.launchpad.net/longsleep/golang-backports/ubuntu focal InRelease [17.5 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,590 kB]\n",
            "Hit:16 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,069 kB]\n",
            "Get:18 http://ppa.launchpad.net/longsleep/golang-backports/ubuntu focal/main amd64 Packages [5,099 B]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,323 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [84.9 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [32.7 kB]\n",
            "Fetched 11.7 MB in 3s (3,783 kB/s)\n",
            "Reading package lists... Done\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/longsleep/golang-backports/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "25 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  golang-1.20-go golang-1.20-src golang-src\n",
            "Suggested packages:\n",
            "  bzr | brz mercurial subversion\n",
            "The following NEW packages will be installed:\n",
            "  golang-1.20-go golang-1.20-src golang-go golang-src\n",
            "0 upgraded, 4 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 40.7 MB of archives.\n",
            "After this operation, 213 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/longsleep/golang-backports/ubuntu focal/main amd64 golang-1.20-src all 1.20.2-1longsleep1+focal [17.8 MB]\n",
            "Get:2 http://ppa.launchpad.net/longsleep/golang-backports/ubuntu focal/main amd64 golang-1.20-go amd64 1.20.2-1longsleep1+focal [22.9 MB]\n",
            "Get:3 http://ppa.launchpad.net/longsleep/golang-backports/ubuntu focal/main amd64 golang-src amd64 2:1.20~1longsleep1 [5,128 B]\n",
            "Get:4 http://ppa.launchpad.net/longsleep/golang-backports/ubuntu focal/main amd64 golang-go amd64 2:1.20~1longsleep1 [24.2 kB]\n",
            "Fetched 40.7 MB in 6s (7,317 kB/s)\n",
            "Selecting previously unselected package golang-1.20-src.\n",
            "(Reading database ... 128288 files and directories currently installed.)\n",
            "Preparing to unpack .../golang-1.20-src_1.20.2-1longsleep1+focal_all.deb ...\n",
            "Unpacking golang-1.20-src (1.20.2-1longsleep1+focal) ...\n",
            "Selecting previously unselected package golang-1.20-go.\n",
            "Preparing to unpack .../golang-1.20-go_1.20.2-1longsleep1+focal_amd64.deb ...\n",
            "Unpacking golang-1.20-go (1.20.2-1longsleep1+focal) ...\n",
            "Selecting previously unselected package golang-src:amd64.\n",
            "Preparing to unpack .../golang-src_2%3a1.20~1longsleep1_amd64.deb ...\n",
            "Unpacking golang-src:amd64 (2:1.20~1longsleep1) ...\n",
            "Selecting previously unselected package golang-go.\n",
            "Preparing to unpack .../golang-go_2%3a1.20~1longsleep1_amd64.deb ...\n",
            "Unpacking golang-go (2:1.20~1longsleep1) ...\n",
            "Setting up golang-1.20-src (1.20.2-1longsleep1+focal) ...\n",
            "Setting up golang-1.20-go (1.20.2-1longsleep1+focal) ...\n",
            "Setting up golang-src:amd64 (2:1.20~1longsleep1) ...\n",
            "Setting up golang-go (2:1.20~1longsleep1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ],
      "source": [
        "# https://colab.research.google.com/github/vistec-AI/colab/blob/master/golang.ipynb\n",
        "!add-apt-repository ppa:longsleep/golang-backports -y\n",
        "!apt update\n",
        "!apt install golang-go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mTSAOC4vqmr",
        "outputId": "b34439d0-8612-4643-80d2-9a961ceacd44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-03-31 18:08:29--  https://github.com/THUDM/CodeGeeX/raw/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/THUDM/CodeGeeX/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz [following]\n",
            "--2023-03-31 18:08:29--  https://raw.githubusercontent.com/THUDM/CodeGeeX/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118261 (115K) [application/octet-stream]\n",
            "Saving to: ‘vendor.tar.gz’\n",
            "\n",
            "vendor.tar.gz       100%[===================>] 115.49K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-03-31 18:08:29 (5.10 MB/s) - ‘vendor.tar.gz’ saved [118261/118261]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 37s with this ; 45s without on the first execution\n",
        "!wget https://github.com/THUDM/CodeGeeX/raw/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/vendor.tar.gz\n",
        "!tar -zxf vendor.tar.gz -C ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYhzbLaOz9gy"
      },
      "outputs": [],
      "source": [
        "# From https://github.com/THUDM/CodeGeeX/blob/07b8d7f10fe544890f9e665473998aed4e831314/codegeex/benchmark/humaneval-x/go/evaluation/go.mod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dqVCA6suIbF",
        "outputId": "237be6a3-7de1-4e77-b13a-323eae54f0ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing go.mod\n"
          ]
        }
      ],
      "source": [
        "%%writefile go.mod\n",
        "module humanEval\n",
        "\n",
        "go 1.18\n",
        "\n",
        "require (\n",
        "\tgithub.com/go-openapi/inflect v0.19.0\n",
        "\tgithub.com/stretchr/testify v1.8.0\n",
        ")\n",
        "\n",
        "require (\n",
        "\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n",
        "\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n",
        "\tgopkg.in/yaml.v3 v3.0.1 // indirect\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKi2XyT63Dkt"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['GOFLAGS'] = '-mod=vendor'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVk0yfY_3KK9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOFLAGS'] = '-mod=mod'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "c66d8124a5a54adeaecb5bb422b2fc96",
            "d7c30c664f7e454ab5369cd5e2a3967e",
            "9f0986fa2e844031a6678d092be119eb",
            "18a7fed72cd94ad0bb1acf9125d39286",
            "b175eaafa823475a91bfaede6ebd4e27",
            "fd9abd11d76643848d180523aa79999c",
            "d8942a95f388438d8f78c2850e3acad1",
            "92fed70ac8f841b9b1e0239c39baed95",
            "4036f0d4bca84bae86384da268ca2b9f",
            "747da425acef48409c453d956cd0dbbf",
            "94cd42ec09a344aaa50cc1238cca63a8"
          ]
        },
        "id": "0PQZ4Uk1ttxT",
        "outputId": "e3f3c633-8d6f-4e16-d424-2a1d37371599"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset humaneval-x-bugs (/root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/go/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c66d8124a5a54adeaecb5bb422b2fc96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'pass@1': 0.0}\n",
            "defaultdict(<class 'list'>, {0: [(0, {'task_id': 0, 'passed': False, 'result': 'failed: go: finding module for package github.com/stretchr/testify/assert\\n', 'completion_id': 0})]})\n",
            "{'pass@1': 0.0}\n",
            "defaultdict(<class 'list'>, {0: [(0, {'task_id': 0, 'passed': False, 'result': 'failed: go: finding module for package github.com/stretchr/testify/assert\\n# command-line-arguments\\n./main_test.go:48:12: suspect and: state == \"upper\" && state == \"lower\"\\n', 'completion_id': 0})]})\n"
          ]
        }
      ],
      "source": [
        "LANGUAGE = \"go\"\n",
        "\n",
        "import datasets\n",
        "ds = datasets.load_dataset(\"bigcode/humaneval-x-bugs\", LANGUAGE)[\"test\"]\n",
        "\n",
        "import os\n",
        "os.environ[\"HF_ALLOW_CODE_EVAL\"] = \"1\"\n",
        "\n",
        "IDX = 95\n",
        "\n",
        "prompt = ds[\"prompt\"][IDX]\n",
        "import_string = ds[\"import\"][IDX]\n",
        "prompt = prompt.replace(import_string, \"\")\n",
        "code = ds[\"canonical_solution\"][IDX]\n",
        "test_setup = ds[\"test_setup\"][IDX]\n",
        "test = ds[\"test\"][IDX]\n",
        "\n",
        "other_pkgs = []\n",
        "for pkg in IMPORT_HELPER[\"go\"]:\n",
        "    if pkg not in test_setup:\n",
        "        p = pkg.split(\"/\")[-1]\n",
        "        if p + \".\" in code:\n",
        "            other_pkgs.append(f\"\\\"{pkg}\\\"\")\n",
        "if other_pkgs:\n",
        "    import_other_pkgs = \"import (\\n\" + \"    \".join([p + \"\\n\" for p in other_pkgs]) + \")\"\n",
        "    candidate = test_setup + \"\\n\" +  import_other_pkgs + \"\\n\" + prompt + code + \"\\n\"\n",
        "else:\n",
        "    candidate = test_setup + \"\\n\" + prompt + code + \"\\n\"\n",
        "\n",
        "test_case = test\n",
        "\n",
        "test_cases = [test_case]\n",
        "candidates = [[candidate]]\n",
        "\n",
        "# Takes very long the first time to build modules I think, hence need to increase timeout\n",
        "pass_at_k, results = eval.compute(\n",
        "    references=test_cases, predictions=candidates, k=[1, 2], language=LANGUAGE, timeout=60\n",
        ")\n",
        "print(pass_at_k)\n",
        "print(results)\n",
        "\n",
        "test_cases = [test_case]\n",
        "candidates = [[candidate.replace(\"||\", \"&&\")]]\n",
        "\n",
        "pass_at_k, results = eval.compute(\n",
        "    references=test_cases, predictions=candidates, k=[1, 2], language=LANGUAGE, timeout=60\n",
        ")\n",
        "print(pass_at_k)\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTHmCm43tWlF",
        "outputId": "4e8096de-6b98-4414-ece9-8d4a1d1e4d5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "package main\n",
            "\n",
            "import (\n",
            "    \"testing\"\n",
            "    \"github.com/stretchr/testify/assert\"\n",
            ")\n",
            "\n",
            "import (\n",
            "\"strings\"\n",
            ")\n",
            "\n",
            "// Given a dictionary, return true if all keys are strings in lower\n",
            "// case or all keys are strings in upper case, else return false.\n",
            "// The function should return false is the given dictionary is empty.\n",
            "// Examples:\n",
            "// CheckDictCase({\"a\":\"apple\", \"b\":\"banana\"}) should return true.\n",
            "// CheckDictCase({\"a\":\"apple\", \"A\":\"banana\", \"B\":\"banana\"}) should return false.\n",
            "// CheckDictCase({\"a\":\"apple\", 8:\"banana\", \"a\":\"apple\"}) should return false.\n",
            "// CheckDictCase({\"Name\":\"John\", \"Age\":\"36\", \"City\":\"Houston\"}) should return false.\n",
            "// CheckDictCase({\"STATE\":\"NC\", \"ZIP\":\"12345\" }) should return true.\n",
            "func CheckDictCase(dict map[interface{}]interface{}) bool {\n",
            "    if len(dict) == 0 {\n",
            "        return false\n",
            "    }\n",
            "    state := \"start\"\n",
            "    key := \"\"\n",
            "    ok := false\n",
            "    for k := range dict {\n",
            "        if key, ok = k.(string); !ok {\n",
            "            state = \"mixed\"\n",
            "            break\n",
            "        }\n",
            "        if state == \"start\" {\n",
            "            if key == strings.ToUpper(key) {\n",
            "                state = \"upper\"\n",
            "            } else if key == strings.ToLower(key) {\n",
            "                state = \"lower\"\n",
            "            } else {\n",
            "                break\n",
            "            }\n",
            "        } else if (state == \"upper\" && key != strings.ToUpper(key)) || (state == \"lower\" && key != strings.ToLower(key)) {\n",
            "            state = \"mixed\"\n",
            "            break\n",
            "        } else {\n",
            "            break\n",
            "        }\n",
            "    }\n",
            "    return state == \"upper\" || state == \"lower\"\n",
            "}\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(candidate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "11c0TYVInJzB",
        "outputId": "f9f35087-3b5c-425b-ac57-6ccb80b8b574"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'package main\\n\\nimport (\\n    \"testing\"\\n    \"math/rand\"\\n    \"time\"\\n    \"github.com/stretchr/testify/assert\"\\n)\\n\\n// returns encoded string by shifting every character by 5 in the alphabet.\\nfunc EncodeShift(s string) string {\\n    runes := []rune(s)\\n    newRunes := make([]rune, 0)\\n    for _, ch := range runes {\\n        newRunes = append(newRunes, (ch+5-\\'a\\')%26+\\'a\\')\\n    }\\n    return string(runes)\\n}\\n\\n// takes as input string encoded with EncodeShift function. Returns decoded string.\\nfunc DecodeShift(s string) string {\\n    runes := []rune(s)\\n    newRunes := make([]rune, 0)\\n    for _, ch := range runes {\\n        newRunes = append(newRunes, (ch-5-\\'a\\')%26+\\'a\\')\\n    }\\n    return string(runes)\\n}\\n\\n\\n'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "candidates[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4xu9Lupmeyz",
        "outputId": "f0f858c3-e21b-437d-b7d1-f1aeccaf71f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "package main\n",
            "\n",
            "import (\n",
            "    \"testing\"\n",
            "    \"math/rand\"\n",
            "    \"time\"\n",
            "    \"github.com/stretchr/testify/assert\"\n",
            ")\n",
            "\n",
            "// returns encoded string by shifting every character by 5 in the alphabet.\n",
            "func EncodeShift(s string) string {\n",
            "    runes := []rune(s)\n",
            "    newRunes := make([]rune, 0)\n",
            "    for _, ch := range runes {\n",
            "        newRunes = append(newRunes, (ch+5-'a')%26+'a')\n",
            "    }\n",
            "    return EncodeShift(string(runes))\n",
            "\n",
            "// takes as input string encoded with EncodeShift function. Returns decoded string.\n",
            "func DecodeShift(s string) string {\n",
            "    runes := []rune(s)\n",
            "    newRunes := make([]rune, 0)\n",
            "    for _, ch := range runes {\n",
            "        newRunes = append(newRunes, (ch-5-'a')%26+'a')\n",
            "    }\n",
            "    return EncodeShift(string(runes))\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(candidates[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G31jEnc8mV6C",
        "outputId": "3551d803-ab89-4f8c-c951-b6de1f5fe7fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "func TestDecodeShift(t *testing.T) {\n",
            "    assert := assert.New(t)\n",
            "    randInt := func(min, max int) int {\n",
            "        rng := rand.New(rand.NewSource(time.Now().UnixNano()))\n",
            "        if min >= max || min == 0 || max == 0 {\n",
            "            return max\n",
            "        }\n",
            "        return rng.Intn(max-min) + min\n",
            "    }\n",
            "    for i := 0; i <100 ; i++ {\n",
            "        runes := make([]rune, 0)\n",
            "        for j := 0; j < randInt(10,20); j++ {\n",
            "            runes = append(runes, int32(randInt('a','z')))\n",
            "        }\n",
            "        encoded_str := EncodeShift(string(runes))\n",
            "        assert.Equal(DecodeShift(encoded_str), string(runes))\n",
            "    }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(test_cases[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vDuF6_8yQpx"
      },
      "source": [
        "##### Rust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCjtcOr3w_xe",
        "outputId": "2d837bbe-2a8c-4433-c767-bdfd34f7bbeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: rustc: command not found\n"
          ]
        }
      ],
      "source": [
        "!rustc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcR0XfibqQCg",
        "outputId": "d236277c-42bf-4996-a26b-60869146b830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1minfo:\u001b[0m downloading installer\n",
            "\u001b[1minfo: \u001b[mprofile set to 'minimal'\n",
            "\u001b[1minfo: \u001b[mdefault host triple is x86_64-unknown-linux-gnu\n",
            "\u001b[1minfo: \u001b[msyncing channel updates for 'stable-x86_64-unknown-linux-gnu'\n",
            "\u001b[1minfo: \u001b[mlatest update on 2023-03-28, rust version 1.68.2 (9eb3afe9e 2023-03-27)\n",
            "\u001b[1minfo: \u001b[mdownloading component 'cargo'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rust-std'\n",
            "\u001b[1minfo: \u001b[mdownloading component 'rustc'\n",
            "\u001b[1minfo: \u001b[minstalling component 'cargo'\n",
            "\u001b[1minfo: \u001b[minstalling component 'rust-std'\n",
            " 29.9 MiB /  29.9 MiB (100 %)  11.8 MiB/s in  2s ETA:  0s\n",
            "\u001b[1minfo: \u001b[minstalling component 'rustc'\n",
            " 68.1 MiB /  68.1 MiB (100 %)  11.6 MiB/s in  6s ETA:  0s\n",
            "\u001b[1minfo: \u001b[mdefault toolchain set to 'stable-x86_64-unknown-linux-gnu'\n",
            "\n",
            "  \u001b[1m\u001b[32mstable-x86_64-unknown-linux-gnu installed\u001b[m - rustc 1.68.2 (9eb3afe9e 2023-03-27)\n",
            "\n",
            "\u001b[1m\n",
            "Rust is installed now. Great!\n",
            "\u001b[m\n",
            "To get started you may need to restart your current shell.\n",
            "This would reload your \u001b[1mPATH\u001b[m environment variable to include\n",
            "Cargo's bin directory ($HOME/.cargo/bin).\n",
            "\n",
            "To configure your current shell, run:\n",
            "source \"$HOME/.cargo/env\"\n"
          ]
        }
      ],
      "source": [
        "!curl https://sh.rustup.rs -sSf | sh -s -- --profile minimal --default-toolchain stable -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3W2fZUaxkTU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PATH'] = '/root/.cargo/bin:' + os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CDep5W98gfp",
        "outputId": "513cf923-3dcb-4d30-c135-5052576a8ef9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rustc 1.68.2 (9eb3afe9e 2023-03-27)\n"
          ]
        }
      ],
      "source": [
        "!rustc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzUmxcEgxBD5"
      },
      "outputs": [],
      "source": [
        "BASE_CARGO = '''[package]\n",
        "name = \"rust\"\n",
        "version = \"0.1.0\"\n",
        "edition = \"2021\"\n",
        "\n",
        "# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n",
        "\n",
        "[dependencies]\n",
        "rand = \"0.4\"\n",
        "regex = \"1\"\n",
        "md5 = \"0.7.0\"\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "9340b6103b7648dea2431558d1a1de95",
            "a65f9a137ebe4dc79555dec22a7c985f",
            "068a571b284448c18912fa90fcf0511b",
            "ff4d83c558a94b339dbc80fab3b98dc8",
            "2995c036b065491ba0c3b78c26e216f4",
            "5e87450db00c4ad3a9936978f51c42d5",
            "1b84f0e2b8f54fe1b8fc7687f9cd1a5d",
            "61f549286077445f9038885bc90303b0",
            "5147fa2e797e4cf89f211b9d92467ce7",
            "874482b838d34a5d9b94bf152b170827",
            "a536db9810634b5a96a2c20c9c2fa7f0"
          ]
        },
        "id": "gk989fBGxBBe",
        "outputId": "24f55622-4457-4f60-9934-b1686d89a333"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset humaneval-x-bugs (/root/.cache/huggingface/datasets/bigcode___humaneval-x-bugs/rust/1.0.0/83d9fc34e82e439d7810e7c3062c4e0c1dd45ef2b52183751ab2ccf208d95fc8)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9340b6103b7648dea2431558d1a1de95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'pass@1': 1.0}\n",
            "defaultdict(<class 'list'>, {0: [(0, {'task_id': 0, 'passed': True, 'result': 'passed', 'completion_id': 0})]})\n",
            "{'pass@1': 0.0}\n",
            "defaultdict(<class 'list'>, {0: [(0, {'task_id': 0, 'passed': False, 'result': 'failed: execution error:    Compiling memchr v2.5.0\\n   Compiling libc v0.2.140\\n   Compiling aho-corasick v0.7.20\\n   Compiling regex-syntax v0.6.29\\n   Compiling rand v0.4.6\\n   Compiling regex v1.7.3\\n   Compiling md5 v0.7.0\\n   Compiling rust v0.1.0 (/tmp/tmp90jbvbvq/rust)\\n    Finished test [unoptimized + debuginfo] target(s) in 8.74s\\n     Running unittests src/bin/test.rs (target/debug/deps/test-600d3f046606559c)\\nerror: test failed, to rerun pass `--bin test`\\n', 'completion_id': 0})]})\n"
          ]
        }
      ],
      "source": [
        "LANGUAGE = \"rust\"\n",
        "\n",
        "import datasets\n",
        "ds = datasets.load_dataset(\"bigcode/humaneval-x-bugs\", LANGUAGE)[\"test\"]\n",
        "\n",
        "import os\n",
        "os.environ[\"HF_ALLOW_CODE_EVAL\"] = \"1\"\n",
        "\n",
        "prompt = ds[\"prompt\"][0]\n",
        "declaration = ds[\"declaration\"][0]\n",
        "code = ds[\"canonical_solution\"][0]\n",
        "test_setup = ds[\"test_setup\"][0]\n",
        "test = ds[\"test\"][0]\n",
        "\n",
        "main = \"\\nfn main(){ \\n } \\n\"\n",
        "\n",
        "candidate = main + declaration + prompt + code\n",
        "test_case = test\n",
        "\n",
        "test_cases = [test_case]\n",
        "candidates = [[candidate]]\n",
        "\n",
        "# Takes very long the first time to build modules I think, hence need to increase timeout\n",
        "pass_at_k, results = eval.compute(\n",
        "    references=test_cases, predictions=candidates, k=[1, 2], language=LANGUAGE, timeout=350, cargo_string=BASE_CARGO\n",
        ")\n",
        "print(pass_at_k)\n",
        "print(results)\n",
        "\n",
        "test_cases = [test_case.replace(\"false\", \"true\")]\n",
        "candidates = [[candidate]]\n",
        "\n",
        "pass_at_k, results = eval.compute(\n",
        "    references=test_cases, predictions=candidates, k=[1, 2], language=LANGUAGE, timeout=350, cargo_string=BASE_CARGO\n",
        ")\n",
        "print(pass_at_k)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQjHIGvVsba5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "WD: str = os.path.dirname(os.getcwd())\n",
        "RUST_DIR: str = os.path.join(WD, \"rust\")\n",
        "RUST_SRC: str = os.path.join(RUST_DIR, \"src\")\n",
        "RUST_BIN: str = os.path.join(RUST_SRC, \"bin\")\n",
        "RUST_TMP_DIR: str = os.path.join(RUST_DIR, \"tmp\")\n",
        "RUST_LOGS: str = os.path.join(RUST_TMP_DIR, \"logs\")\n",
        "RUST_EXT: str = \".rs\"\n",
        "\n",
        "# Create mandatory tmp directories\n",
        "os.makedirs(RUST_TMP_DIR, exist_ok=True)\n",
        "os.makedirs(RUST_LOGS, exist_ok=True)\n",
        "os.makedirs(RUST_SRC, exist_ok=True)\n",
        "os.makedirs(RUST_BIN, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MeHwvuaUujbW",
        "outputId": "b8d08024-de56-47d6-eddc-026d955ea9fa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/rust'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMxAUeqwsl5h",
        "outputId": "98ecf8b0-c7e4-42d1-bd1e-89bcf33722b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/rust\n"
          ]
        }
      ],
      "source": [
        "%cd {RUST_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIj9bhT4s7-l"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "with tempfile.NamedTemporaryFile(dir = RUST_BIN, delete=False) as f:\n",
        "    #temporal file name\n",
        "    file_prefix = \"xxx\"\n",
        "    file_name:str =  file_prefix +RUST_EXT\n",
        "\n",
        "    os.rename(f.name, os.path.join(RUST_BIN, file_name))\n",
        "\n",
        "    # Sample to pure Rust function\n",
        "    rust_code: str = candidates[0][0] + test_case#sample[\"test_code\"]\n",
        "\n",
        "    # dump the rust source code in the target temporal file\n",
        "    f.write(rust_code.encode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyXCsBSVsqnL"
      },
      "outputs": [],
      "source": [
        "file_prefix = \"xxx\"\n",
        "log_filename: str = file_prefix + \".jsonl\"\n",
        "log_path: str = os.path.join(RUST_LOGS, log_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp6U5L9CtDMt"
      },
      "outputs": [],
      "source": [
        "cargo_check: str = \"cargo check --bin \" + file_prefix + \" --message-format json >> \" + log_path\n",
        "returned_val_compilation = os.system(cargo_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YnNO5DmtPLl"
      },
      "outputs": [],
      "source": [
        "!cp /content/Cargo.toml /rust/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozYpXEeRtMPT"
      },
      "outputs": [],
      "source": [
        "out = subprocess.run([\"cargo\", \"check\", \"--bin\", \"xxx\", \"--message-format\", \"json\"], capture_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bOyS2HfwEm8",
        "outputId": "41c0206d-6074-4965-bbd9-952d732b342a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out.returncode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU3UP_hitUTt"
      },
      "outputs": [],
      "source": [
        "cargo_test: str = \"cargo test --bin \" +file_prefix+ \" --message-format json >> \" + log_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbF1ozlqtURA"
      },
      "outputs": [],
      "source": [
        "out = subprocess.run([\"cargo\", \"test\", \"--bin\", \"xxx\", \"--message-format\", \"json\"], capture_output=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4KstF0CMd_RH",
        "2vHV9WxBd89I",
        "o4ksawk5VWW9",
        "6P8XUxM9VX1k",
        "MGIJ2alLVZie",
        "seGAn7anVbSA",
        "CsGUfTthEwdc",
        "c01wL_UkQ1Qo",
        "wx_GboyTwmml",
        "-FancJ8MuCVA",
        "nXlXzNu3w4SD",
        "HqODYde00yRG",
        "DyVrh2fR00oK",
        "h8kFZDykjCaF",
        "fP1KYPm1Eur5",
        "KWXedCM8tIaT",
        "0eHvXy3XtJeR",
        "ONGvx8njtKtB"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02c9e2a791ed43b88f632df22d129965": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ef1e6cb98254301b51ab3702e4cc959",
            "placeholder": "​",
            "style": "IPY_MODEL_81d66f6a5bc2465da785a9d900194b71",
            "value": " 1/1 [00:00&lt;00:00, 44.11it/s]"
          }
        },
        "068a571b284448c18912fa90fcf0511b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61f549286077445f9038885bc90303b0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5147fa2e797e4cf89f211b9d92467ce7",
            "value": 1
          }
        },
        "0b1b09d561934a3cb49ec0a4b86d02aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f983308187464fea8982245f395c4467",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b7d9fe6800c4eedae89f510aaef0152",
            "value": 1
          }
        },
        "1274237bedfe4ffebdd6ea26104d766c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "154b1ac6dec24e31bdf7dedab0d030d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb2a4937d0a24bbd9ad1101bf6acca9f",
            "placeholder": "​",
            "style": "IPY_MODEL_83dbe04bd512434e9de694a94cdd6278",
            "value": " 1/1 [00:00&lt;00:00, 27.31it/s]"
          }
        },
        "18a7fed72cd94ad0bb1acf9125d39286": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_747da425acef48409c453d956cd0dbbf",
            "placeholder": "​",
            "style": "IPY_MODEL_94cd42ec09a344aaa50cc1238cca63a8",
            "value": " 1/1 [00:00&lt;00:00, 16.62it/s]"
          }
        },
        "195c5cdb8f9a4aa487d0dc67f4dabeec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b84f0e2b8f54fe1b8fc7687f9cd1a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20b0c88ab54f4c81bcc8ecad5f316d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "251d6da853d3448ea8a141335fab2e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_843181eaa98d410bacb72bd9142db5ab",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d749c450b89443c900815a0489aef39",
            "value": 1
          }
        },
        "2995c036b065491ba0c3b78c26e216f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34614f24f55c424da5a71a2b1b13e877": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37d2809f9aeb420f8b28180b5d51ad6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92655b7478fe4456b7604d0008f7e029",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1274237bedfe4ffebdd6ea26104d766c",
            "value": 1
          }
        },
        "4036f0d4bca84bae86384da268ca2b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ef1e6cb98254301b51ab3702e4cc959": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f3b4a9f6014f60969efe5d5ff549bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61657564a9a546609accb626eb41268e",
              "IPY_MODEL_251d6da853d3448ea8a141335fab2e6b",
              "IPY_MODEL_02c9e2a791ed43b88f632df22d129965"
            ],
            "layout": "IPY_MODEL_195c5cdb8f9a4aa487d0dc67f4dabeec"
          }
        },
        "5147fa2e797e4cf89f211b9d92467ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e87450db00c4ad3a9936978f51c42d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61657564a9a546609accb626eb41268e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6536128ba0cc410daf361ba9f1c3bbe4",
            "placeholder": "​",
            "style": "IPY_MODEL_6ddbc11ccaf944918db90aa5176f18ec",
            "value": "100%"
          }
        },
        "61f549286077445f9038885bc90303b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64311d384d464e23959d3411d2b93219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6536128ba0cc410daf361ba9f1c3bbe4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b7d9fe6800c4eedae89f510aaef0152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ddbc11ccaf944918db90aa5176f18ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e419cb8669245eab12e928b82fba7a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74480d2838bb4093927fdac2a25f1974": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e419c5b80f6f46749d89830798f1bbbc",
              "IPY_MODEL_0b1b09d561934a3cb49ec0a4b86d02aa",
              "IPY_MODEL_ff8dc9882d9f4feaaea3babdd28b5394"
            ],
            "layout": "IPY_MODEL_a5295cbf725c43babcd9f99bf90ee049"
          }
        },
        "747da425acef48409c453d956cd0dbbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81d66f6a5bc2465da785a9d900194b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83dbe04bd512434e9de694a94cdd6278": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "843181eaa98d410bacb72bd9142db5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "874482b838d34a5d9b94bf152b170827": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c7d7bc531714104a741c8557139d875": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9f7b350be0f4338914d0089053147f2",
              "IPY_MODEL_37d2809f9aeb420f8b28180b5d51ad6f",
              "IPY_MODEL_154b1ac6dec24e31bdf7dedab0d030d0"
            ],
            "layout": "IPY_MODEL_d49d85cbc4e34dab8d8de108c5f69c04"
          }
        },
        "8d749c450b89443c900815a0489aef39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92655b7478fe4456b7604d0008f7e029": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92fed70ac8f841b9b1e0239c39baed95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9340b6103b7648dea2431558d1a1de95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a65f9a137ebe4dc79555dec22a7c985f",
              "IPY_MODEL_068a571b284448c18912fa90fcf0511b",
              "IPY_MODEL_ff4d83c558a94b339dbc80fab3b98dc8"
            ],
            "layout": "IPY_MODEL_2995c036b065491ba0c3b78c26e216f4"
          }
        },
        "940d4e0101c64704a317b36148941b54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94cd42ec09a344aaa50cc1238cca63a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f0986fa2e844031a6678d092be119eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92fed70ac8f841b9b1e0239c39baed95",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4036f0d4bca84bae86384da268ca2b9f",
            "value": 1
          }
        },
        "a5295cbf725c43babcd9f99bf90ee049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a536db9810634b5a96a2c20c9c2fa7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a65f9a137ebe4dc79555dec22a7c985f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e87450db00c4ad3a9936978f51c42d5",
            "placeholder": "​",
            "style": "IPY_MODEL_1b84f0e2b8f54fe1b8fc7687f9cd1a5d",
            "value": "100%"
          }
        },
        "b175eaafa823475a91bfaede6ebd4e27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f7b350be0f4338914d0089053147f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e419cb8669245eab12e928b82fba7a3",
            "placeholder": "​",
            "style": "IPY_MODEL_20b0c88ab54f4c81bcc8ecad5f316d50",
            "value": "100%"
          }
        },
        "bb2a4937d0a24bbd9ad1101bf6acca9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c66d8124a5a54adeaecb5bb422b2fc96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7c30c664f7e454ab5369cd5e2a3967e",
              "IPY_MODEL_9f0986fa2e844031a6678d092be119eb",
              "IPY_MODEL_18a7fed72cd94ad0bb1acf9125d39286"
            ],
            "layout": "IPY_MODEL_b175eaafa823475a91bfaede6ebd4e27"
          }
        },
        "d47abbaa8cfc42f7a6b2b687adf5a4c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d49d85cbc4e34dab8d8de108c5f69c04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7c30c664f7e454ab5369cd5e2a3967e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd9abd11d76643848d180523aa79999c",
            "placeholder": "​",
            "style": "IPY_MODEL_d8942a95f388438d8f78c2850e3acad1",
            "value": "100%"
          }
        },
        "d8942a95f388438d8f78c2850e3acad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e419c5b80f6f46749d89830798f1bbbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d47abbaa8cfc42f7a6b2b687adf5a4c0",
            "placeholder": "​",
            "style": "IPY_MODEL_34614f24f55c424da5a71a2b1b13e877",
            "value": "100%"
          }
        },
        "f983308187464fea8982245f395c4467": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9abd11d76643848d180523aa79999c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff4d83c558a94b339dbc80fab3b98dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_874482b838d34a5d9b94bf152b170827",
            "placeholder": "​",
            "style": "IPY_MODEL_a536db9810634b5a96a2c20c9c2fa7f0",
            "value": " 1/1 [00:00&lt;00:00, 44.27it/s]"
          }
        },
        "ff8dc9882d9f4feaaea3babdd28b5394": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_940d4e0101c64704a317b36148941b54",
            "placeholder": "​",
            "style": "IPY_MODEL_64311d384d464e23959d3411d2b93219",
            "value": " 1/1 [00:00&lt;00:00, 42.97it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}